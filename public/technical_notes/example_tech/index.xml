<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Technical Notes Overview | Paul Apivat</title>
    <link>/technical_notes/example_tech/</link>
      <atom:link href="/technical_notes/example_tech/index.xml" rel="self" type="application/rss+xml" />
    <description>Technical Notes Overview</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020 Paul Apivat Hanvongse. All Rights Reserved.</copyright><lastBuildDate>Sun, 09 Sep 2018 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Technical Notes Overview</title>
      <link>/technical_notes/example_tech/</link>
    </image>
    
    <item>
      <title>Use string interpolation to query GraphQL</title>
      <link>/technical_notes/example_tech/python_string_interpolation_graphql/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_string_interpolation_graphql/</guid>
      <description>&lt;h2 id=&#34;use-pythons-string-interpolation-to-query-graphql&#34;&gt;Use Python&amp;rsquo;s string interpolation to query GraphQL&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: For this project, I had previously grabbed the latest timestamp in a data table, assigned it to a variable and now want to use it as input for a GraphQL query:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# Run separate request to GraphQL endpoint
# use max_tx_timestamp in parameter &#39;where: {timestamp_gte: max_tx_timestamp}&#39;
# this will return on-chain tx since latest timestamp (i.e., max_tx_timestamp)

variables = {&#39;input&#39;: max_tx_timestamp}

query = f&amp;quot;&amp;quot;&amp;quot;
{{
  transferBanks(first: 1000, where: {{timestamp_gte:{max_tx_timestamp}}}, orderBy: timestamp, orderDirection: asc, subgraphError: allow) {{
    id
    from_address
    to_address
    amount
    amount_display
    timestamp
    timestamp_display
  }}
}}
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then to make sure this &lt;em&gt;string interpolation&lt;/em&gt; actually works, we need to make a post request to the GraphQL API endpoint, query it, save that query into a data frame.&lt;/p&gt;
&lt;p&gt;(NOTE: This requies toggling back and forth between the database client like pgAdmin and your ipython environment)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# note: &#39;variables&#39; defined above


def run_query(q):
    request = requests.post(&#39;https://api.studio.thegraph.com/query/1121/bankv1/v0.0.5&#39;
                            &#39;&#39;,
                            json={&#39;query&#39;: query, &#39;variables&#39;: variables})
    if request.status_code == 200:
        return request.json()
    else:
        raise Exception(&#39;Query failed. return code is {}.     {}&#39;.format(
            request.status_code, query))


result = run_query(query)

# print results
print(&#39;Print Bank Subgraph Result - {}&#39;.format(result))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Python to query GraphQL</title>
      <link>/technical_notes/example_tech/python_query_graphql/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_query_graphql/</guid>
      <description>&lt;h2 id=&#34;using-python-to-query-graphql&#34;&gt;Using Python to query GraphQL&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: We need to query GraphQL, in JSON format, to convert to dataframe.&lt;/p&gt;
&lt;p&gt;There are several ways to go about this. The simplest way is to use the &lt;code&gt;requests&lt;/code&gt; library to make HTTP requests to the API endpoint, then the &lt;code&gt;json&lt;/code&gt; library to convert those requests into JSON format:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;import requests
import json
import pandas as pd

def run_query(q):
    request = requests.post(&#39;https://api-endpoint&#39;
                            &#39;&#39;,
                            json={&#39;query&#39;: query})
    if request.status_code == 200:
        return request.json()
    else:
        raise Exception(&#39;Query failed. return code is {}.     {}&#39;.format(
            request.status_code, query))

# basic query first
query = &amp;quot;&amp;quot;&amp;quot;
{
    transferBanks(first: 1000, orderBy: timestamp, orderDirection: asc, subgraphError: allow) {
    id
    from_address
    to_address
    amount
    amount_display
    timestamp
    timestamp_display
  }
}
&amp;quot;&amp;quot;&amp;quot;

# returns JSON
result = run_query(query)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An alternative way is to use the &lt;code&gt;gql&lt;/code&gt; and the &lt;code&gt;gql.transport.aiohttp&lt;/code&gt; libraries:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;from gql import gql, Client
from gql.transport.aiohttp import AIOHTTPTransport

# Select transport with url endpoint
transport = AIOHTTPTransport(
    url=&amp;quot;https://api.studio.thegraph.com/query/1121/bankv1/v0.0.5&amp;quot;)

# create GraphQL client using defined transport
client = Client(transport=transport, fetch_schema_from_transport=True)

# GraphQL query
query = gql(&amp;quot;&amp;quot;&amp;quot;
{
    transferBanks(first: 1000, where: {timestamp_gte: &amp;quot;1635403557&amp;quot;}, orderBy: timestamp, orderDirection: asc, subgraphError: allow) {
    id
    from_address
    to_address
    amount
    amount_display
    timestamp
    timestamp_display
    }
}
&amp;quot;&amp;quot;&amp;quot;)

# run query on transport
result = client.execute(query)
print(result)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Pandas to Convert JSON to Dataframes</title>
      <link>/technical_notes/example_tech/python_json_to_df/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_json_to_df/</guid>
      <description>&lt;h2 id=&#34;using-pandas-to-convert-json-to-dataframes&#34;&gt;Using Pandas to Convert JSON to Dataframes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: We are pulling in JSON data and need to convert it to a dataframe to load to a relational database or for further analysis.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s likely the JSON is nested with at least two levels. Here the &lt;code&gt;requests&lt;/code&gt; library makes an http request to an API endpoint. A function &lt;code&gt;run_query(q)&lt;/code&gt; is written to return the request in JSON data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;import requests
import json
import pandas as pd

def run_query(q):
    request = requests.post(&#39;https://api-endpoint&#39;
                            &#39;&#39;,
                            json={&#39;query&#39;: query})
    if request.status_code == 200:
        return request.json()
    else:
        raise Exception(&#39;Query failed. return code is {}.     {}&#39;.format(
            request.status_code, query))

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we need to unnest the JSON into a list of dictionaries before converting into dataframe. THe flow is JSON -&amp;gt; get Items -&amp;gt; turn into List -&amp;gt; dig down into List of Dictionaries -&amp;gt; convert to dataframe:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# returns JSON
result = run_query(query)

# get Items
result_items = result.items()
# turn into List
result_list = list(result_items)
# dig down into List of Dictionaries (2 levels)
lst_of_dict = result_list[0][1].get(&#39;transferBanks&#39;)
# convert to data frame
df = pd.json_normalize(lst_of_dict)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating a Github Repo</title>
      <link>/technical_notes/example_tech/github_make_repo/</link>
      <pubDate>Wed, 21 Jul 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/github_make_repo/</guid>
      <description>&lt;h2 id=&#34;guide-for-creating-a-github-repo-and-cloning-locally&#34;&gt;Guide for Creating a GitHub Repo and Cloning Locally&lt;/h2&gt;
&lt;p&gt;This guide can help you setup a fresh new GitHub Repo, then clone it locally to begin working in your local environment, then pushing changes up to your GitHub Repo.&lt;/p&gt;
&lt;p&gt;This guide assumes you have a Text Editor like VSCode installed and that you can use the &lt;strong&gt;Terminal&lt;/strong&gt; to navigate through various folders.&lt;/p&gt;
&lt;h2 id=&#34;creating-repo&#34;&gt;Creating Repo&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Sign-up for a GitHub Account&lt;/li&gt;
&lt;li&gt;Navigate to Your Profile&lt;/li&gt;
&lt;li&gt;Click on Repositories&lt;/li&gt;
&lt;li&gt;Click on green button &amp;ldquo;New&amp;rdquo; (for New Repo)&lt;/li&gt;
&lt;li&gt;In the Repository Name field, give your new repo a name*&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Names should have no spaces, use underscore _ to separate words (ie., special_project)&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;Description is optional&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Default is Public (a Private Repo requires a monthly fee)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tick Add a README and Choose license (if applicable, if not just go with a README)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A .gitignore file is recommended if your project has sensitive info associated with it that you&amp;rsquo;d like to keep OUT of GitHub&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click &amp;ldquo;Create Repository&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;cloning-locally&#34;&gt;Cloning Locally&lt;/h2&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;Navigate to your newly created repository (still on GitHub)&lt;/li&gt;
&lt;li&gt;Click on the Green Button &amp;ldquo;Code&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Select the HTTPS (default) option and &lt;strong&gt;copy&lt;/strong&gt; the &lt;a href=&#34;https://github.com/YourName/special_project&#34;&gt;https://github.com/YourName/special_project&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Once you&amp;rsquo;ve copied the &lt;code&gt;https&lt;/code&gt; address, you&amp;rsquo;ll use the &lt;strong&gt;terminal&lt;/strong&gt; in your text editor (i.e., VSCode) to navigate to a folder on your local machine (desktop or laptop) where you&amp;rsquo;ve &lt;em&gt;already&lt;/em&gt; created a folder just for coding projects (i.e., coding_projects)&lt;/p&gt;
&lt;ol start=&#34;14&#34;&gt;
&lt;li&gt;Open the text editor (i.e., VS Code), click on Terminal in the menu bar, &amp;ldquo;New Terminal&amp;rdquo;, this will open your terminal to have you start at a level &lt;em&gt;above&lt;/em&gt; the Desktop. Suppose you have a folder &lt;em&gt;on&lt;/em&gt; your Desktop that says &amp;ldquo;coding_projects&amp;rdquo; you&amp;rsquo;ll want to &lt;strong&gt;clone&lt;/strong&gt; your newly-created github repo &lt;em&gt;in&lt;/em&gt; this folder. But you have to navigate to &lt;em&gt;coding_projects&lt;/em&gt; folder first. Here&amp;rsquo;s the command to navigate in Terminal:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;cd Desktop/coding_projects&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;15&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cd&lt;/code&gt; means change directory; here, you&amp;rsquo;ll change directory into your Desktop, then into coding_projects folder (two steps) to &lt;strong&gt;clone&lt;/strong&gt; your github repository (special_project)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(in Terminal), you&amp;rsquo;re now inside the &lt;code&gt;coding_projects&lt;/code&gt; folder, you&amp;rsquo;ll run this command, pasting the &lt;code&gt;https&lt;/code&gt; address that you copied from your GitHub Repo:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;git clone https://github.com/YourName/special_project&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will initialize your repo locally. From here, try making a minor change to the README file.&lt;/p&gt;
&lt;ol start=&#34;17&#34;&gt;
&lt;li&gt;
&lt;p&gt;Make a small change to your README file on your Text Editor, then save the changes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Back in Terminal, you&amp;rsquo;ll add the changes, then commit, then push back up to GitHub. You&amp;rsquo;ll run these commands:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;code&gt;git status&lt;/code&gt;   (this should indicate in red that you have new changes)
&lt;code&gt;git add .&lt;/code&gt;    (you&amp;rsquo;ll add those changes)
&lt;code&gt;git push&lt;/code&gt;     (you&amp;rsquo;re pushing those changes to your GitHub Repo)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: you might see a prompt to do &lt;code&gt;git push --upstream origin&lt;/code&gt;, which happens if this is the first push you&amp;rsquo;re making to the repo.&lt;/p&gt;
&lt;p&gt;Now you&amp;rsquo;ve cloned your repo locally, made some changes, then pushed it back up to GitHub. Its important to &lt;strong&gt;note&lt;/strong&gt; that the process described here is to allow you to track changes for your personal coding projects, &lt;strong&gt;NOT&lt;/strong&gt; any code for production or development environment.&lt;/p&gt;
&lt;p&gt;In those cases, the team may have it&amp;rsquo;s own protocol for version control and you&amp;rsquo;ll want to get familiar and follow those protocols.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making a Pull Request on a GitHub Repo</title>
      <link>/technical_notes/example_tech/github_make_pr/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/github_make_pr/</guid>
      <description>&lt;h2 id=&#34;guide-for-contributing-to-another-code-base-by-making-a-pull-request&#34;&gt;Guide for contributing to another code base by making a pull request&lt;/h2&gt;
&lt;h2 id=&#34;public-repo&#34;&gt;Public Repo&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Identify a project you want to contribute to on GitHub&lt;/li&gt;
&lt;li&gt;Fork that project&lt;/li&gt;
&lt;li&gt;Clone it to your local machine*&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt; : Do not clone in another directory that was &lt;em&gt;already&lt;/em&gt; cloned from another repo. For example, when I cloned 
&lt;a href=&#34;https://github.com/PaulApivat/pytalentsolution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pytalentsolution&lt;/a&gt; on my local machine, I initially cloned it &lt;em&gt;inside&lt;/em&gt; Saku directory, which was &lt;em&gt;itself&lt;/em&gt; a clone of an already-existing-repo. The correct way was to create a &lt;em&gt;new&lt;/em&gt; directory for pytalentsolution.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Make a new branch&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;4a: &lt;code&gt;cd&lt;/code&gt; into directory of the cloned repo&lt;/li&gt;
&lt;li&gt;4b: use &lt;code&gt;git branch&lt;/code&gt; to confirm you&amp;rsquo;re on the &lt;code&gt;*master&lt;/code&gt; branch&lt;/li&gt;
&lt;li&gt;4c: use &lt;code&gt;git checkout -b name_of_new_branch&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;4d: use &lt;code&gt;git branch&lt;/code&gt; to check that you&amp;rsquo;re on &lt;code&gt;name_of_new_branch&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;
&lt;p&gt;Make changes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Push it back to your repo&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt; : You&amp;rsquo;ll get a message &lt;code&gt;git push remote --&lt;/code&gt; use this instead of the traditional &lt;code&gt;git push&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;(Go back to the forked repo in GitHub) Click the &lt;strong&gt;Compare &amp;amp; Pull Request&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;add a description to changes made in the pull request&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;Click &lt;strong&gt;Create pull request&lt;/strong&gt; to open a new pull request&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;private-repo&#34;&gt;Private Repo&lt;/h2&gt;
&lt;p&gt;1-3. You cannot fork a private repo&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;Clone directly to local machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;git branch -a&lt;/code&gt; to see all branches in the project&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;git branch&lt;/code&gt; to confirm you&amp;rsquo;re on master branch&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[important] &lt;code&gt;git status&lt;/code&gt; to check if ahead or behind (if behind, use &lt;code&gt;git pull&lt;/code&gt; to fetch and download content from a remote repository)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;[from git master] create a &lt;strong&gt;new&lt;/strong&gt; branch use &lt;code&gt;git checkout -b name_of_new_branch&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;git branch&lt;/code&gt; to make sure you&amp;rsquo;re on new branch&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make changes, then normal: git add, git commit -m &amp;ldquo;message&amp;rdquo;, git push&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt; : You&amp;rsquo;ll get a message &lt;code&gt;git push remote --&lt;/code&gt; use this instead of the traditional &lt;code&gt;git push&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;10&#34;&gt;
&lt;li&gt;(Go back to the forked repo in GitHub) Click the &lt;strong&gt;Compare &amp;amp; Pull Request&lt;/strong&gt; button.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Add good PR description, 
&lt;a href=&#34;https://www.pullrequest.com/blog/writing-a-great-pull-request-description/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;see here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;11&#34;&gt;
&lt;li&gt;Click &lt;strong&gt;Create pull request&lt;/strong&gt; to open a new pull request&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;production-vs-development&#34;&gt;Production vs Development&lt;/h2&gt;
&lt;p&gt;Ongoing projects with several contributors will generally separate the &lt;strong&gt;main&lt;/strong&gt; from &lt;strong&gt;develop&lt;/strong&gt; branch. Making a PR in this context is &lt;em&gt;slighty&lt;/em&gt; different:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In the command line, switch to development branch &lt;code&gt;git checkout develop&lt;/code&gt; (even if you don&amp;rsquo;t see the &lt;code&gt;develop&lt;/code&gt; branch locally, you may just see &lt;code&gt;main&lt;/code&gt; or a new branch you created &lt;code&gt;new_branch&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now that you&amp;rsquo;re &lt;em&gt;starting&lt;/em&gt; on &lt;code&gt;develop&lt;/code&gt; branch, do &lt;code&gt;git pull origin develop&lt;/code&gt; to make sure that any prior changes from the &lt;code&gt;develop&lt;/code&gt; branch is pulled in locally, and you&amp;rsquo;re up-to-date.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then from &lt;code&gt;develop&lt;/code&gt;, create a new &lt;code&gt;feature&lt;/code&gt; branch like so: &lt;code&gt;git checkout feature/new-branch&lt;/code&gt;. (note: &lt;code&gt;feature/new-branch&lt;/code&gt; is a naming convention that explicitly says you&amp;rsquo;re creating a new feature branch).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then make your changes or add new code.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, &lt;code&gt;git push origin&lt;/code&gt; (in this case, origin will be develop)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once you go back to github, if you see &lt;code&gt;compare and pull request&lt;/code&gt;, make sure it is being merged into &lt;code&gt;develop&lt;/code&gt; and &lt;strong&gt;not&lt;/strong&gt; &lt;code&gt;main&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;when-feature-branch-goes-out-of-sync-with-development&#34;&gt;When Feature branch goes out of sync with Development&lt;/h2&gt;
&lt;p&gt;Sometimes you&amp;rsquo;ve already pushed a pull request, but the development branch goes ahead of your proposed changes. Here&amp;rsquo;s how to handle:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Switch to a specific feature branch (no need to go back to develop): &lt;code&gt;git checkout branch_name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;git pull origin develop&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Then &lt;code&gt;git push origin&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;3a. If there&amp;rsquo;s an &lt;code&gt;Index Error&lt;/code&gt;, run&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git reset --hard&lt;/code&gt; *&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git clean -df&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git reset&lt;/code&gt; is to take the current branch and reset it to point somewhere else, also bringing the index and working tree along. Here&amp;rsquo;s a more visual explanation (
&lt;a href=&#34;https://stackoverflow.com/questions/2530060/in-plain-english-what-does-git-reset-d&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If your main branch is &lt;code&gt;C&lt;/code&gt; and you want to point your current branch somewhere else:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- A - B - C (HEAD, main branch)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and you want to point to &lt;code&gt;B&lt;/code&gt;, not &lt;code&gt;C&lt;/code&gt;, then you use &lt;code&gt;git reset B&lt;/code&gt; to move it there:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- A - B (HEAD, main branch)  # - C is still here, but there&#39;s no branch pointing to it anymore
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;vim&#34;&gt;VIM&lt;/h2&gt;
&lt;p&gt;If for whatever reason you find yourself on VIM, you can escape by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Press &lt;code&gt;esc&lt;/code&gt; (escape)&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;:&lt;/code&gt; (colon)&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;wq&lt;/code&gt; (write and quit)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Or one-line command to get out of VIM&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Press &lt;code&gt;:wq!&lt;/code&gt; (colon, write and quit)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Using Faker to simulate fake data with Python</title>
      <link>/technical_notes/example_tech/python_faker/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_faker/</guid>
      <description>&lt;h2 id=&#34;creating-mock-data-in-python-with-the-faker-library&#34;&gt;Creating mock data in Python with the Faker library&lt;/h2&gt;
&lt;p&gt;If you need to simulate mock data, the &lt;code&gt;Faker&lt;/code&gt; 
&lt;a href=&#34;https://github.com/joke2k/faker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;library&lt;/a&gt; is a great resource. Shout out to 
&lt;a href=&#34;https://twitter.com/joke2k&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@joke2k&lt;/a&gt; for maintaining this project.&lt;/p&gt;
&lt;p&gt;The full code for a recent project is below, with breakdown of each section to follow. Project context: Utilizing MongoDB as our NoSQL database. I&amp;rsquo;ve created a basic document (json) and now need to replicate multiple documents to simulate data once it&amp;rsquo;s populated with data from the frontend (or a Bot for this project specifically).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from json import dumps
from faker import Faker
import collections

database = []
filename = &#39;testing_bounty&#39;
length = 5
fake = Faker()

# fake.word(ext_word_list=)
random_currencies = [&#39;BANK&#39;, &#39;ETH&#39;, &#39;BTC&#39;]

random_guilds = [&amp;quot;Marketing Guild&amp;quot;, &amp;quot;Treasury Guild&amp;quot;,
                 &amp;quot;Developer&#39;s Guild&amp;quot;, &amp;quot;Analytics Guild&amp;quot;, &amp;quot;Writer&#39;s Guild&amp;quot;]

discord_handle = [&amp;quot;@bob#8888&amp;quot;, &amp;quot;@alice#1234&amp;quot;,
                  &amp;quot;@carol#5555&amp;quot;, &amp;quot;@delta#2222&amp;quot;, &amp;quot;@lambda#3333&amp;quot;]

bounty_status = [&#39;Open&#39;, &#39;Draft&#39;, &#39;In-Progress&#39;,
                 &#39;In-Review&#39;, &#39;Completed&#39;, &#39;Deleted&#39;]

skills = [&amp;quot;writing&amp;quot;,
          &amp;quot;design&amp;quot;,
          &amp;quot;software development&amp;quot;,
          &amp;quot;strategic planning&amp;quot;,
          &amp;quot;data analysis&amp;quot;,
          &amp;quot;grant writing&amp;quot;,
          &amp;quot;proposal development&amp;quot;,
          &amp;quot;team building&amp;quot;,
          &amp;quot;marketing&amp;quot;]

for x in range(length):
    database.append(collections.OrderedDict([
        (&#39;season&#39;, fake.random_int(0, 10)),
        (&#39;bounty&#39;, fake.sentence()),
        (&#39;bountyDescription&#39;, fake.sentence()),
        (&#39;doneCriteria&#39;, fake.sentence()),
        (&#39;bountyReward&#39;, collections.OrderedDict([
            (&#39;currency&#39;, fake.word(ext_word_list=random_currencies)),
            (&#39;amount&#39;, fake.random_int(0, 50000))
        ])),
        # list of dictionaries
        (&#39;applicableGuilds&#39;, [collections.OrderedDict(
            [(&#39;guildName&#39;, fake.word(ext_word_list=random_guilds))]), collections.OrderedDict([(&#39;guildName&#39;, fake.word(ext_word_list=random_guilds))])]),
        (&#39;bountyCreatedBy&#39;, collections.OrderedDict([
            (&#39;isDaoMember&#39;, fake.pybool()),
            (&#39;guildName&#39;, fake.word(ext_word_list=random_guilds)),
            (&#39;discordHandle&#39;, fake.word(ext_word_list=discord_handle)),
            (&#39;publicAddress&#39;, &amp;quot;0x2d94aa3e47d9d5024503ca8&amp;quot; + fake.pystr())
        ])),
        (&#39;bountyCreatedAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+3m&#39;)),
        (&#39;bountyDueAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+1y&#39;)),
        (&#39;bountyActivatedAt&#39;, fake.date_between(
            start_date=&#39;today&#39;, end_date=&#39;+6m&#39;)),
        (&#39;bountyClaimedBy&#39;, collections.OrderedDict([
            (&#39;guildName&#39;, fake.word(ext_word_list=random_guilds)),
            (&#39;discordHandle&#39;, fake.word(ext_word_list=discord_handle)),
            (&#39;publicAddress&#39;, &amp;quot;0x2d94aa3e47d9d5024503ca8&amp;quot; + fake.pystr())
        ])),
        (&#39;bountyClaimedAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+4m&#39;)),
        (&#39;bountySubmittedBy&#39;, fake.word(ext_word_list=random_guilds)),
        (&#39;bountySubmittedAt&#39;, fake.date_between(
            start_date=&#39;today&#39;, end_date=&#39;+11m&#39;)),
        (&#39;bountySubmissionLink&#39;, &amp;quot;www.&amp;quot; + fake.safe_domain_name()),
        # list of dictionaries
        (&#39;bountyStatus&#39;, [collections.OrderedDict([
            (&#39;status&#39;, fake.word(ext_word_list=bounty_status)),
            (&#39;bountyStatusTime&#39;, fake.date_between(
                start_date=&#39;today&#39;, end_date=&#39;+1y&#39;))
        ])]),
        (&#39;bountyHash&#39;, fake.md5(raw_output=False)),
        # list of words
        (&#39;skillsRequired&#39;, [fake.word(ext_word_list=skills),
                            fake.word(ext_word_list=skills)])
    ]))

with open(&#39;%s.json&#39; % filename, &#39;w&#39;) as output:
    # turns date_between into string, circumvent json serialization
    output.write(dumps(database, indent=4, sort_keys=False, default=str))
print(&amp;quot;Done.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s a breakdown, section-by-section:&lt;/p&gt;
&lt;p&gt;Since we&amp;rsquo;ll be creating mock json data, the &lt;code&gt;json&lt;/code&gt; built-in library is imported (specifically &lt;code&gt;dumps&lt;/code&gt;), the &lt;code&gt;Faker&lt;/code&gt; library is the main tool and we&amp;rsquo;ll also be using &lt;code&gt;OrderedDict&lt;/code&gt; from &lt;code&gt;collections&lt;/code&gt; to create document objects.&lt;/p&gt;
&lt;p&gt;Database is set to an empty array which will store the json object (&lt;code&gt;OrderedDict&lt;/code&gt;). We&amp;rsquo;ll save the file that we eventually write as &lt;code&gt;testing_bounty&lt;/code&gt; and keep it a short length (5), while we&amp;rsquo;re still testing.&lt;/p&gt;
&lt;p&gt;Finally, we initialize the &lt;code&gt;Faker&lt;/code&gt; library by calling the Faker function and setting to &lt;code&gt;fake&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from json import dumps
from faker import Faker
import collections

database = []
filename = &#39;testing_bounty&#39;
length = 5
fake = Faker()   &amp;lt;--- important
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This next section save a list of words that pertinent to our project in lists. As we create mock json objects, for certain fields, we&amp;rsquo;ll want to populate from a sample of &lt;strong&gt;keywords&lt;/strong&gt; that&amp;rsquo;s important for our project.&lt;/p&gt;
&lt;p&gt;Without these keywords, we&amp;rsquo;ll need to rely on random words/sentences that comes with the &lt;code&gt;Faker&lt;/code&gt; library and that may not always be appropriate for our context.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# fake.word(ext_word_list=)
random_currencies = [&#39;BANK&#39;, &#39;ETH&#39;, &#39;BTC&#39;]

random_guilds = [&amp;quot;Marketing Guild&amp;quot;, &amp;quot;Treasury Guild&amp;quot;,
                 &amp;quot;Developer&#39;s Guild&amp;quot;, &amp;quot;Analytics Guild&amp;quot;, &amp;quot;Writer&#39;s Guild&amp;quot;]

discord_handle = [&amp;quot;@bob#8888&amp;quot;, &amp;quot;@alice#1234&amp;quot;,
                  &amp;quot;@carol#5555&amp;quot;, &amp;quot;@delta#2222&amp;quot;, &amp;quot;@lambda#3333&amp;quot;]

bounty_status = [&#39;Open&#39;, &#39;Draft&#39;, &#39;In-Progress&#39;,
                 &#39;In-Review&#39;, &#39;Completed&#39;, &#39;Deleted&#39;]

skills = [&amp;quot;writing&amp;quot;,
          &amp;quot;design&amp;quot;,
          &amp;quot;software development&amp;quot;,
          &amp;quot;strategic planning&amp;quot;,
          &amp;quot;data analysis&amp;quot;,
          &amp;quot;grant writing&amp;quot;,
          &amp;quot;proposal development&amp;quot;,
          &amp;quot;team building&amp;quot;,
          &amp;quot;marketing&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This next section is where we create a number of json objects, specified by length. Everything is pushed into an &lt;code&gt;collections.OrderedDict&lt;/code&gt; and in some cases, we have nested data.&lt;/p&gt;
&lt;p&gt;Most of the fields are typical &lt;code&gt;key-value&lt;/code&gt; pairs. There are variations in the &lt;code&gt;values&lt;/code&gt;, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;strings (&lt;code&gt;fake.sentence()&lt;/code&gt;, &lt;code&gt;fake.word()&lt;/code&gt;, &lt;code&gt;fake.pystr()&lt;/code&gt;); you can sample from list of words created above&lt;/li&gt;
&lt;li&gt;integers (&lt;code&gt;fake.random_int()&lt;/code&gt;); you can randomize within a range of integers&lt;/li&gt;
&lt;li&gt;dates (&lt;code&gt;fake.date_between&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;boolean (&lt;code&gt;fake.pybool&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;dictionaries / json object (&lt;code&gt;collections.OrderedDict&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;list of dictionaries, enclose within &lt;code&gt;[]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;list of strings&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;
for x in range(length):
    database.append(collections.OrderedDict([
        (&#39;season&#39;, fake.random_int(0, 10)),
        (&#39;bounty&#39;, fake.sentence()),
        (&#39;bountyDescription&#39;, fake.sentence()),
        (&#39;doneCriteria&#39;, fake.sentence()),
        (&#39;bountyReward&#39;, collections.OrderedDict([
            (&#39;currency&#39;, fake.word(ext_word_list=random_currencies)),
            (&#39;amount&#39;, fake.random_int(0, 50000))
        ])),
        # list of dictionaries
        (&#39;applicableGuilds&#39;, [collections.OrderedDict(
            [(&#39;guildName&#39;, fake.word(ext_word_list=random_guilds))]), collections.OrderedDict([(&#39;guildName&#39;, fake.word(ext_word_list=random_guilds))])]),
        (&#39;bountyCreatedBy&#39;, collections.OrderedDict([
            (&#39;isDaoMember&#39;, fake.pybool()),
            (&#39;guildName&#39;, fake.word(ext_word_list=random_guilds)),
            (&#39;discordHandle&#39;, fake.word(ext_word_list=discord_handle)),
            (&#39;publicAddress&#39;, &amp;quot;0x2d94aa3e47d9d5024503ca8&amp;quot; + fake.pystr())
        ])),
        (&#39;bountyCreatedAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+3m&#39;)),
        (&#39;bountyDueAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+1y&#39;)),
        (&#39;bountyActivatedAt&#39;, fake.date_between(
            start_date=&#39;today&#39;, end_date=&#39;+6m&#39;)),
        (&#39;bountyClaimedBy&#39;, collections.OrderedDict([
            (&#39;guildName&#39;, fake.word(ext_word_list=random_guilds)),
            (&#39;discordHandle&#39;, fake.word(ext_word_list=discord_handle)),
            (&#39;publicAddress&#39;, &amp;quot;0x2d94aa3e47d9d5024503ca8&amp;quot; + fake.pystr())
        ])),
        (&#39;bountyClaimedAt&#39;, fake.date_between(start_date=&#39;today&#39;, end_date=&#39;+4m&#39;)),
        (&#39;bountySubmittedBy&#39;, fake.word(ext_word_list=random_guilds)),
        (&#39;bountySubmittedAt&#39;, fake.date_between(
            start_date=&#39;today&#39;, end_date=&#39;+11m&#39;)),
        (&#39;bountySubmissionLink&#39;, &amp;quot;www.&amp;quot; + fake.safe_domain_name()),
        # list of dictionaries
        (&#39;bountyStatus&#39;, [collections.OrderedDict([
            (&#39;status&#39;, fake.word(ext_word_list=bounty_status)),
            (&#39;bountyStatusTime&#39;, fake.date_between(
                start_date=&#39;today&#39;, end_date=&#39;+1y&#39;))
        ])]),
        (&#39;bountyHash&#39;, fake.md5(raw_output=False)),
        # list of words
        (&#39;skillsRequired&#39;, [fake.word(ext_word_list=skills),
                            fake.word(ext_word_list=skills)])
    ]))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we run our script, we&amp;rsquo;ll want to save and serialize the &lt;code&gt;OrderedDict&lt;/code&gt; in a json file. We also want to enclose our dates in strings to avoid getting a &lt;code&gt;json serialization error&lt;/code&gt;; this is done by setting the parameters of &lt;code&gt;output.write()&lt;/code&gt; to &lt;code&gt;default=str&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with open(&#39;%s.json&#39; % filename, &#39;w&#39;) as output:
    # turns date_between into string, circumvent json serialization
    output.write(dumps(database, indent=4, sort_keys=False, default=str))
print(&amp;quot;Done.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Setting dotenv to Access Sensitive API Keys</title>
      <link>/technical_notes/example_tech/python_dotenv/</link>
      <pubDate>Thu, 07 Jan 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_dotenv/</guid>
      <description>&lt;h2 id=&#34;setting-up-dotenv-files&#34;&gt;Setting up dotenv Files&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Use Case&lt;/strong&gt;: We have sensitive API Keys and Secret Keys we don&amp;rsquo;t want to put into version control, but we need to access.&lt;/p&gt;
&lt;p&gt;The best practice is to create a &lt;code&gt;.env&lt;/code&gt; file at the root of your project and store the keys in there, and &lt;strong&gt;most importantly&lt;/strong&gt;, making sure to include &lt;code&gt;.env&lt;/code&gt; in a &lt;code&gt;.gitignore&lt;/code&gt; file so it &lt;em&gt;does not&lt;/em&gt; get included in versioning.&lt;/p&gt;
&lt;p&gt;The challenge is to install the &lt;code&gt;dotenv&lt;/code&gt; module to access the &lt;code&gt;load_dotenv&lt;/code&gt; function in order to access the data in the environment variable (&lt;code&gt;.env&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;First, here&amp;rsquo;s how the structure of the directory &lt;em&gt;could&lt;/em&gt; look like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.
├── .env
└── settings.py
└── .gitignore
└── project_directory_1
        └── file.py
└── project_directory_2
        └── another_file.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The key things to pay attention here are &lt;code&gt;.env&lt;/code&gt;, &lt;code&gt;settings.py&lt;/code&gt; and &lt;code&gt;.gitignore&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For the present hypothetical project, here&amp;rsquo;s what needs to be in the &lt;code&gt;.gitignore&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#.gitignore

# Environents
.env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s what needs to be in &lt;code&gt;.env&lt;/code&gt;. The example here is accessing Twitter API. The first time you&amp;rsquo;re setting this up, I&amp;rsquo;d recommend using a &amp;ldquo;fake&amp;rdquo; CONSUMER_KEY (aka API Key) and CONSUMER_SECRET (API Secret Key) just to test it out and make sure that it doesn&amp;rsquo;t get inadvertently added to version control (&lt;strong&gt;note&lt;/strong&gt;: see setting up &lt;code&gt;.gitignore&lt;/code&gt; above).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# you&#39;ll put your actual API Keys and Secrete Keys here

TWITTER_CONSUMER_KEY=fakeconsumerkey
TWITTER_CONSUMER_SECRET=fakeconsumersecret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Within the &lt;code&gt;settings.py&lt;/code&gt; file, you&amp;rsquo;ll have:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from dotenv import load_dotenv
load_dotenv()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there you&amp;rsquo;ll go into &lt;code&gt;file.py&lt;/code&gt; and use the dotenv module to access environment variables (sensitive API Keys). The example below accesses Twitter API.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#file.py

# for python-dotenv method of access environment variables
from twython import Twython
import webbrowser
import os
import dotenv
from dotenv import load_dotenv
load_dotenv()

###### TWITTER API ######

# IMPORTANT: PLUG YOUR KEY AND SECRET IN DIRECTLY (without os.environ.get())
CONSUMER_KEY = os.environ.get(&amp;quot;TWITTER_CONSUMER_KEY&amp;quot;)         # API Key
CONSUMER_SECRET = os.environ.get(&amp;quot;TWITTER_CONSUMER_SECRET&amp;quot;)   # API Secret Key
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Assuming everything is setup properly, you should be able to run the following code within &lt;code&gt;IPython&lt;/code&gt; and have &lt;code&gt;CONSUMER_KEY&lt;/code&gt; return a string:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os
import dotenv
from dotenv import load_dotenv

load_dotenv() # True
CONSUMER_KEY = os.environ.get(&amp;quot;TWITTER_CONSUMER_KEY&amp;quot;)

CONSUMER_KEY  # &#39;fakeconsumerkey&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;installing-dotenv-module&#34;&gt;Installing dotenv module&lt;/h2&gt;
&lt;p&gt;This is the challenging part. I had installed &lt;code&gt;dotenv&lt;/code&gt; but was unable to access it within &lt;code&gt;settings.py&lt;/code&gt; and &lt;code&gt;file.py&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;First, because we&amp;rsquo;re using Python3, anything that involves &lt;code&gt;pip install&lt;/code&gt; should  be &lt;code&gt;pip3 install&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I had to uninstall, then re-install &lt;code&gt;dotenv&lt;/code&gt;, and what worked was following this 
&lt;a href=&#34;https://stackoverflow.com/questions/58943578/i-have-installed-python-dotenv-but-python-cannot-find-it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow answer&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conda install -c conda-forge python-dotenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sometimes having both &lt;code&gt;dotenv&lt;/code&gt; and &lt;code&gt;python-dotenv&lt;/code&gt; install can cause conflict. In which case, in your virtual environment, try below. Based on 
&lt;a href=&#34;https://stackoverflow.com/questions/58943578/i-have-installed-python-dotenv-but-python-cannot-find-it&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this answer&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip3 uninstall dotenv
pip3 uninstall python-dotenv
pip3 install python-dotenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&amp;rsquo;ll know you have something working when you run the following code in the command line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dotenv --version   # dotenv, version 0.15.0
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Setting up Poetry for Dependency Management</title>
      <link>/technical_notes/example_tech/python_poetry/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_poetry/</guid>
      <description>&lt;h2 id=&#34;setting-up-poetry-for-dependency-management&#34;&gt;Setting up Poetry for Dependency Management&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://python-poetry.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Poetry&lt;/a&gt; is python packaging and dependency management made easy.&lt;/p&gt;
&lt;h4 id=&#34;poetry-install-script&#34;&gt;Poetry Install Script&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | python3
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sample-project&#34;&gt;Sample Project&lt;/h2&gt;
&lt;h4 id=&#34;create-sample-project&#34;&gt;Create Sample Project&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ poetry new how-long
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;creating-virtual-environment&#34;&gt;Creating virtual environment&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; This is done only &lt;strong&gt;once&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ poetry config virtualenvs.in-project true
$ poetry install
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;launch-virtual-environment&#34;&gt;Launch virtual environment&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ poetry shell 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;uninstall-virtual-environment&#34;&gt;Uninstall virtual environment&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ poetry env remove 3.x
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;existing-project&#34;&gt;Existing Project&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Switch to master branch (if not already on)&lt;/li&gt;
&lt;li&gt;git status&lt;/li&gt;
&lt;li&gt;git pull&lt;/li&gt;
&lt;li&gt;git checkout -b new_branch_name&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Assume that &lt;code&gt;poetry config virtualenvs.in-project true&lt;/code&gt; has been run.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;$ poetry install
$ poetry shell 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check &lt;code&gt;python&lt;/code&gt; environment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing a git commit message</title>
      <link>/technical_notes/example_tech/git_commit_message/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/git_commit_message/</guid>
      <description>&lt;h2 id=&#34;git-commit-messages&#34;&gt;Git commit messages&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: You&amp;rsquo;ve merged a branch to master/main and you get this message. See 
&lt;a href=&#34;https://stackoverflow.com/questions/19085807/please-enter-a-commit-message-to-explain-why-this-merge-is-necessary-especially&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;original stackoverflow&lt;/a&gt; question for more context:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Please enter a commit message to explain why this merge is necessary,
especially if it merges an updated upstream into a topic branch.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You try typing a message or hitting enter or escaping and &lt;strong&gt;nothing&lt;/strong&gt; happens.
This is &lt;strong&gt;not&lt;/strong&gt; an error message. Git is using your default editor. Here&amp;rsquo;s what to do:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;press &amp;ldquo;i&amp;rdquo; (i for insert)&lt;/li&gt;
&lt;li&gt;write your merge message&lt;/li&gt;
&lt;li&gt;press &amp;ldquo;esc&amp;rdquo; (escape)&lt;/li&gt;
&lt;li&gt;write &amp;ldquo;:wq&amp;rdquo; (write &amp;amp; quite)&lt;/li&gt;
&lt;li&gt;then press enter&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Setting up Conda Virtual Env and IPython</title>
      <link>/technical_notes/example_tech/python_virtualenv/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_virtualenv/</guid>
      <description>&lt;h2 id=&#34;virtual-environment-best-practices&#34;&gt;Virtual Environment Best Practices&lt;/h2&gt;
&lt;p&gt;NOTE: This is from chapter 2 of Joel Grus&#39; &amp;lsquo;Data Science from Scratch&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;Joel&amp;rsquo;s a known 
&lt;a href=&#34;https://www.youtube.com/watch?v=7jiPeIFXb6U&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;opponent of notebooks&lt;/a&gt; and recommends operating in IPython instead.&lt;/p&gt;
&lt;p&gt;I was pleasantly surprised that the process of setting up a virtual environment and IPython was relatively painless. Here&amp;rsquo;s my process, taken from the book with some tweaks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# create a Python 3.6 environment named &#39;dsfs&#39;
conda create -n dsfs python=3.6

# update conda to latest version (4.9.0)
conda update -n base -c defaults conda

# to activate virtual environment (named it &#39;dsfs&#39; to keep it simple)
source activate dsfs

# install pip (note: currently using Python 3.8.5)
python3 get-pip.py

# install IPython 
python3 -m pip install ipython

# save IPython session
# save lines 1-21 in session to file initial_ipython_session.py
%save initial_ipython_session 1-21

# exit IPython
ctrl + D

# exit conda virtual environment
conda deactivate

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;pulling-up-a-saved-ipython-session-in-vscode&#34;&gt;Pulling up a saved IPython session in VSCode&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;: I am using VSCode as my main python IDE outside of &lt;code&gt;jupyter notebooks&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After you&amp;rsquo;ve saved an IPython session (see above), you may want to pull up the &lt;code&gt;.py&lt;/code&gt; file for further edits at a later time. To do this, you&amp;rsquo;ll need to ensure that the &lt;code&gt;code&lt;/code&gt; command for VSCode is installed.&lt;/p&gt;
&lt;p&gt;Assuming you&amp;rsquo;re already &lt;em&gt;in&lt;/em&gt; VSCode, 
&lt;a href=&#34;https://stackoverflow.com/questions/30065227/run-open-vscode-from-mac-terminal&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;press&lt;/a&gt; (I&amp;rsquo;m using macOS):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Command + Shift + P
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then select &lt;code&gt;Shell Command: Install code in PATH&lt;/code&gt;. That&amp;rsquo;s it.&lt;/p&gt;
&lt;p&gt;To open a previously saved &lt;code&gt;IPython&lt;/code&gt; session in VSCode from the VSCode terminal, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% code name_of_file.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that this can be done from (base) or from a previously configured virtual environment session, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(base) paulapivat@Pauls-MacBook dsfs % code function_session.py
(base) paulapivat@Pauls-MacBook dsfs % source activate dsfs
(dsfs) paulapivat@Pauls-MacBook dsfs % code function_session.py
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Creating and Looping through DataFrames</title>
      <link>/technical_notes/example_tech/python_tip2/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_tip2/</guid>
      <description>&lt;h2 id=&#34;creating-and-looping-through-list-of-tuples&#34;&gt;Creating and Looping through List of Tuples&lt;/h2&gt;
&lt;p&gt;If you come to Python from R, it&amp;rsquo;s not immediately obvious how Lists, Dictionaries, Tuples, Series, then Loops help you do the things you can do in R.&lt;/p&gt;
&lt;p&gt;You can begin to connect the dots when you see that Lists of Tuples are the building blocks of DataFrames - available in both languages to handle tidy (tabular) data.&lt;/p&gt;
&lt;h1 id=&#34;lists&#34;&gt;Lists&lt;/h1&gt;
&lt;p&gt;Lists are ordered and mutable collection of data. Below are lists of strings and integers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name_list = [&#39;paul&#39;, &#39;apivat&#39;, &#39;marvin&#39;, &#39;pim&#39;, &#39;milin&#39;]
int_list = [3,4,5,2,5,6,7,5]
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;tuples&#34;&gt;Tuples&lt;/h1&gt;
&lt;p&gt;Tuples, also collections, are ordered and immutable. But more related to the handling of data, tuples can be converted to DataFrames (using the Pandas library). Below, the List of Tuples (data) is converted into a DataFrame.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import pandas as pd

data = [
    (&#39;r1&#39;, &#39;c1&#39;, 11, 11),
    (&#39;r1&#39;, &#39;c2&#39;, 12, 12),
    (&#39;r2&#39;, &#39;c1&#39;, 21, 21),
    (&#39;r2&#39;, &#39;c2&#39;, 22, 22)
]

df = pd.DataFrame(data, columns=[&#39;R_Number&#39;, &#39;C_Number&#39;, &#39;Avg&#39;, &#39;Std&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;loops&#34;&gt;Loops&lt;/h1&gt;
&lt;p&gt;You can loop through lists of strings and integers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int_list = [3,4,5,2,5,6,7,5]

for num in int_list:
    print(num)
    
name_list = [&#39;paul&#39;, &#39;apivat&#39;, &#39;marvin&#39;, &#39;pim&#39;, &#39;milin&#39;]

for name in name_list:
    print(name)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;looping-through-list-of-tuples-dataframe&#34;&gt;Looping through List of Tuples (DataFrame)&lt;/h1&gt;
&lt;p&gt;Just like you can loop through &lt;em&gt;any&lt;/em&gt; collection, you can loop through a list of tuples - which means you can loop through DataFrames.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Looping through column names
df = pd.DataFrame(data, columns=[&#39;R_Number&#39;, &#39;C_Number&#39;, &#39;Avg&#39;, &#39;Std&#39;])

for col_names in df:
    print(col_names)
    
# Looping through a specific column
for items in df[&#39;R_Number&#39;]:
    print(items)
    
# Looping through a specific row
for items in df.iloc[1]:
    print(items)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s the basic connection between python fundamental data structures and for-loop operations and data science.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Random Numbers &amp; Reproducibility in Python</title>
      <link>/technical_notes/example_tech/python_reproducibility/</link>
      <pubDate>Thu, 10 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_reproducibility/</guid>
      <description>&lt;h2 id=&#34;random-numbers-with-numpy&#34;&gt;Random Numbers with Numpy&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Numpy&lt;/code&gt; has a sub-module called &lt;code&gt;random&lt;/code&gt;. Technically both are of the &amp;lsquo;module&amp;rsquo; class. &lt;code&gt;numpy.random&lt;/code&gt; contains other methods like: &lt;code&gt;seed&lt;/code&gt;, &lt;code&gt;set_state&lt;/code&gt;, &lt;code&gt;standard_t&lt;/code&gt; etc.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Submodules

import numpy

print(&amp;quot;numpy.random is a&amp;quot;, type(numpy.random))
print(&amp;quot;numpy is a&amp;quot;, type(numpy))
print(&amp;quot;it contains names such as...&amp;quot;, dir(numpy.random)[-15:])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reproducibility&#34;&gt;Reproducibility&lt;/h2&gt;
&lt;p&gt;When using &lt;code&gt;numpy.random&lt;/code&gt;, you can ensure reproducibility by accessing &lt;code&gt;numpy.random.seed(30)&lt;/code&gt;, which mirrors #Rstats&#39; &lt;code&gt;set.seed(30)&lt;/code&gt; behavior.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import random

numpy.random.seed(30)
rolls = numpy.random.randint(low=1, high=6, size=10)
rolls
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Connecting BigQuery to Google Data Studio [Basic Setup]</title>
      <link>/technical_notes/example_tech/google_cloud_tip1/</link>
      <pubDate>Sat, 05 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/google_cloud_tip1/</guid>
      <description>&lt;h2 id=&#34;steps-for-connecting-bigquery-to-data-studio&#34;&gt;Steps for Connecting BigQuery to Data Studio&lt;/h2&gt;
&lt;p&gt;This note outlines the basic steps required to generate charts in Google Data Studio, specifically pulling data from BigQuery.&lt;/p&gt;
&lt;h1 id=&#34;bigquery&#34;&gt;BigQuery&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;The starting point is to generate a query in BigQuery&lt;/li&gt;
&lt;li&gt;Once a query is created, click &lt;strong&gt;Save Results&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;In the pop-up window, a prompt: &amp;ldquo;choose where to save the results data from the query&amp;rdquo;, save result as BigQuery Table&lt;/li&gt;
&lt;li&gt;Set project name (i.e., jobsbot)&lt;/li&gt;
&lt;li&gt;Set dataset name (i.e., internalmongo)&lt;/li&gt;
&lt;li&gt;Create table name, for the specific query (i.e., jobfieldname_ranking)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;google-data-studio&#34;&gt;Google Data Studio&lt;/h1&gt;
&lt;ol start=&#34;7&#34;&gt;
&lt;li&gt;Click Add Data&lt;/li&gt;
&lt;li&gt;Find BigQuery in Google Connectors&lt;/li&gt;
&lt;li&gt;Locate saved query table (see above) (i.e., My Projects &amp;gt; jobsbot (project) &amp;gt; internalmongo (dataset) &amp;gt; jobfieldname_ranking (table/specific query))&lt;/li&gt;
&lt;li&gt;Click Add&lt;/li&gt;
&lt;li&gt;Select &amp;lsquo;Add a Chart&amp;rsquo; (note: could be Table or Chart style)&lt;/li&gt;
&lt;li&gt;Optional: copy/paste Table to create a companion Chart for table&lt;/li&gt;
&lt;li&gt;Select Table; in Data Menu, select Metric, &amp;lsquo;Add Metric&amp;rsquo; to swap out generic default Report Count (for more informative data generated from the query)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Python Setup Options</title>
      <link>/technical_notes/example_tech/python_tip1/</link>
      <pubDate>Fri, 04 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/python_tip1/</guid>
      <description>&lt;h2 id=&#34;setting-up-python-for-r-users&#34;&gt;Setting up Python for R Users&lt;/h2&gt;
&lt;p&gt;I&amp;rsquo;ve recently started #66DaysOfData and will be using this opportunity to make some headway into the world of Python. It&amp;rsquo;s reputation for having a complex, at times frustrating, setup process precedes itself and is probably warranted. That said, here are some tips to minimize that.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s my current OS environment. Mac users will have an older version of Python that comes with the computer, you can type &lt;code&gt;python --version&lt;/code&gt; into your terminal to find out. Here&amp;rsquo;s mine:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;macOS Catalina version 10.15.5
Python 2.7.16
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;python-2-vs-python-3&#34;&gt;Python 2 vs Python 3&lt;/h1&gt;
&lt;p&gt;There appears to be general consensus for anyone starting out in Python that you&amp;rsquo;ll want Python 3. There&amp;rsquo;s no debate here. Just get Python 3. I found the easiest way to go to Python Release for Mac OS X, which as of this writing is Python 3.8.5 and use the 
&lt;a href=&#34;https://www.python.org/downloads/release/python-385/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;macOS 64-bit installer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once installed, you&amp;rsquo;ll want to check.&lt;/p&gt;
&lt;p&gt;Instead of &lt;code&gt;python --version&lt;/code&gt;, which checks Python 2, you&amp;rsquo;ll use &lt;code&gt;python3 --version&lt;/code&gt;. This implies that Python 3 isn&amp;rsquo;t merely a &amp;ldquo;newer&amp;rdquo; version of Python, but that they are completely different categories.&lt;/p&gt;
&lt;h1 id=&#34;anaconda&#34;&gt;Anaconda&lt;/h1&gt;
&lt;p&gt;While this isn&amp;rsquo;t my first choice of development environment, it is the first option that allowed me to get coding in Python the fastest.&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ll download the 
&lt;a href=&#34;https://www.anaconda.com/products/individual&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Individual Edition&lt;/a&gt; of the Anaconda, open-source platform. You&amp;rsquo;ll download the application for your desktop and you&amp;rsquo;ll find &lt;code&gt;Anaconda-Navigator&lt;/code&gt; in your list of applications (or where ever you chose to place your newly installed application).&lt;/p&gt;
&lt;p&gt;NOTE: Shortly after installing and using, the Desktop version of Anaconda froze and I had a difficult time even &amp;ldquo;Force Quitting&amp;rdquo; it, so my preferred method of launching Anaconda Navigator is to open the mac terminal and type in the command &lt;code&gt;anaconda-navigator&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The navigator supports &lt;code&gt;Jupyter Notebooks&lt;/code&gt;, &lt;code&gt;PyCharm&lt;/code&gt; and even &lt;code&gt;RStudio&lt;/code&gt; among other environments.&lt;/p&gt;
&lt;p&gt;I will be using &lt;code&gt;Jupyter Notebooks&lt;/code&gt; while I get acclimated to Python, but ultimately i&amp;rsquo;m looking for interoperability with #Rstats.&lt;/p&gt;
&lt;h1 id=&#34;reticulate&#34;&gt;Reticulate&lt;/h1&gt;
&lt;p&gt;This is an &lt;code&gt;R package&lt;/code&gt; that allows you to run &lt;code&gt;Python&lt;/code&gt; code in &lt;code&gt;R&lt;/code&gt; environments. The feature I am looking forward to using is the &lt;code&gt;R Markdown&lt;/code&gt; document that allows me to run chunks of python code.&lt;/p&gt;
&lt;p&gt;Work-in-Progress: TBD&lt;/p&gt;
&lt;h1 id=&#34;vscode&#34;&gt;VSCode&lt;/h1&gt;
&lt;p&gt;This is another popular IDE with widely used Python Extension.&lt;/p&gt;
&lt;p&gt;Work-in-Progress: TBD&lt;/p&gt;
&lt;h1 id=&#34;pycharm&#34;&gt;PyCharm&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;ve heard this IDE most closely resembles RStudio in ease of use.&lt;/p&gt;
&lt;p&gt;Work-in-Progress: TBD&lt;/p&gt;
&lt;h1 id=&#34;spyder&#34;&gt;Spyder&lt;/h1&gt;
&lt;p&gt;This appears to be close approximation of the functionality in RStudio.&lt;/p&gt;
&lt;p&gt;Work-in-Progress: TBD&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Technical Notes Page 1</title>
      <link>/technical_notes/example_tech/technical_notes1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/technical_notes1/</guid>
      <description>&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;technical-tip-1&#34;&gt;Technical Tip 1&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;technical-tip-2&#34;&gt;Technical Tip 2&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CRUD Operations in Mongo (Shell)</title>
      <link>/technical_notes/example_tech/mongodb_crud/</link>
      <pubDate>Thu, 11 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/mongodb_crud/</guid>
      <description>&lt;h2 id=&#34;create-read-update-delete-in-mongo-shell&#34;&gt;Create, Read, Update, Delete in Mongo (Shell)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: This is a summary of basic Mongo operations in shell. These commands can be used in create, seed test databases outside of the production database.&lt;/p&gt;
&lt;h3 id=&#34;basic-commands&#34;&gt;Basic commands&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# show available databases
show dbs

# use a database
use db_name

# show collections within database
show collections
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;delete-an-entire-collection&#34;&gt;Delete an entire collection&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.collectionName.drop()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;insert-one-document-into-a-collection&#34;&gt;Insert one document into a collection&lt;/h3&gt;
&lt;p&gt;Create a collection &lt;em&gt;and&lt;/em&gt; insert one document. Copy a document (i.e., an object or python dictionary) and paste in argument of &lt;code&gt;.insertOne()&lt;/code&gt;. What&amp;rsquo;s inserted is a single object.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.newCollectionName.insertOne({})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;: &lt;code&gt;MongoServerError: _id fields may not contain &#39;$&#39;-prefixed fields: $oid is not valid for storage.&lt;/code&gt; Because mongo shell automatically inserted ids:&lt;/p&gt;
&lt;p&gt;Example of two ObjectIds being inserted:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;{
  acknowledged: true,
  insertedIds: {
    &#39;0&#39;: ObjectId(&amp;quot;618d1fb2f5975b1a2ed10b91&amp;quot;),
    &#39;1&#39;: ObjectId(&amp;quot;618d1fb2f5975b1a2ed10b92&amp;quot;)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;insert-many-documents-into-a-collection&#34;&gt;Insert many documents into a collection&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;: to avoid &lt;code&gt;MongoServerError&lt;/code&gt; with &lt;code&gt;&#39;$&#39;oid is not valid for storage&lt;/code&gt; error, edit in VSCode before pasting in mongo shell.&lt;/p&gt;
&lt;p&gt;Note, parameter is an &lt;em&gt;array of objects&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.newCollectionName.insertMany([{}, {}])
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;count-documents-inside-a-collection&#34;&gt;Count document(s) inside a collection&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.collection.countDocuments()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;find-document-where-integer-value--9000&#34;&gt;Find document where integer value &amp;gt; 9000&lt;/h3&gt;
&lt;p&gt;Using &lt;code&gt;$gt&lt;/code&gt; (greater than) as an example from the Bounty Board project.&lt;/p&gt;
&lt;p&gt;Alternatives:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;$lt&lt;/code&gt; less than&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$gte&lt;/code&gt; greater than or equal to&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.bounties2.find({&amp;quot;reward.amount&amp;quot;: {$gt: 9000} }).pretty()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;update-one-document&#34;&gt;Update one document&lt;/h3&gt;
&lt;p&gt;Updating &lt;code&gt;season&lt;/code&gt; from 1 to 2:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.bounties2.updateOne({_id: ObjectId(&amp;quot;618d2585f5975b1a2ed10b93&amp;quot;)}, {$set: {season: 2}})
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;replaceone-instead-update&#34;&gt;ReplaceOne instead update&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This is more tedious than updating just one field; with &lt;code&gt;replaceOne()&lt;/code&gt; you have to update &lt;strong&gt;all&lt;/strong&gt; fields otherwise, they get deleted. Arguably, this makes it more explicit (and safe) way to update.&lt;/p&gt;
&lt;p&gt;This replaces key-value pairs in the document with a specific &lt;code&gt;_id&lt;/code&gt; to only have 2 key-value pairs (erasing all others).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.bounties2.replaceOne({_id: ObjectId(&amp;quot;618d1cddf5975b1a2ed10b8f&amp;quot;)}, {season: 2, &amp;quot;title&amp;quot;: &amp;quot;Implement Changes&amp;quot;})
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;print-more-than-just-20-documents&#34;&gt;Print more than just 20 documents&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;bountyboard&amp;gt; db.bounties2.find().forEach((bounties2Data) =&amp;gt; {printjson(bounties2Data)})
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;return-only-one-field-in-a-document&#34;&gt;Return only one field in a document&lt;/h3&gt;
&lt;p&gt;Here we&amp;rsquo;re returning &amp;ldquo;title&amp;rdquo;, then &amp;ldquo;reward.amount&amp;rdquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# return title
db.bounties2.find({}, {title: 1, _id: 0}).pretty()

# return reward.amount
db.bounties2.find({}, {&amp;quot;reward.amount&amp;quot;: 1, _id: 0}).pretty()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;joining-two-collections&#34;&gt;Joining two collections&lt;/h3&gt;
&lt;p&gt;Note: Join two collections by &lt;code&gt;customerId&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.bounties2.aggregate([{ $lookup: { from: &amp;quot;customers&amp;quot;, localField: &amp;quot;customerId&amp;quot;, foreignField: &amp;quot;customerId&amp;quot;, as: &amp;quot;customerId&amp;quot; } }])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Create a table to established connection with SQLAlchemy</title>
      <link>/technical_notes/example_tech/postgresql_create_table/</link>
      <pubDate>Tue, 09 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_create_table/</guid>
      <description>&lt;h2 id=&#34;create-a-test-table-then-insert-data-to-establish-a-connection&#34;&gt;Create a Test Table then Insert data to establish a connection&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: You want to create a quick &amp;lsquo;test&amp;rsquo; table via the &lt;code&gt;sqlalchemy&lt;/code&gt; library in Python to establish a connection with your postgres db.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# Create TEST table to confirm connection
db.execute(
    &amp;quot;CREATE TABLE IF NOT EXISTS films (title text, director text, year text)&amp;quot;)

# Insert data
db.execute(
    &amp;quot;INSERT INTO films (title, director, year) VALUES (&#39;Dune&#39;, &#39;Denis Villeneuve&#39;, &#39;2021&#39;)&amp;quot;)

# Read data
result_set = db.execute(&amp;quot;SELECT * FROM films&amp;quot;)
for r in result_set:
    print(r)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Testing databases in a Docker Container</title>
      <link>/technical_notes/example_tech/database_install_docker/</link>
      <pubDate>Tue, 09 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/database_install_docker/</guid>
      <description>&lt;h2 id=&#34;setting-up-docker-locally&#34;&gt;Setting up Docker locally&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: We need have an separate frontend-backend work environment instead of spinning up a test database in our &lt;em&gt;actual&lt;/em&gt; database.&lt;/p&gt;
&lt;p&gt;We need to separate &lt;code&gt;test environment&lt;/code&gt; from &lt;code&gt;dev/prod environment&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For demonstration, I&amp;rsquo;m pulling a docker container into my local machine to test a database for the bounty board project.&lt;/p&gt;
&lt;p&gt;Enter Docker. Assuming a dev has &lt;strong&gt;already setup&lt;/strong&gt; the docker container in a specific feature branch &lt;code&gt;feature/docker-compose-mongo&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# clone repo that contains docker container (bountyboard-docker directory is installed locally)
git clone https://github.com/jordaniza/bounty-board.git bountyboard-docker

# change directory into that directory&#39;s root
cd bountyboard-docker

# create new feature branch to match branch you want to pull locally (containing the docker container) 
git checkout -b feature/docker-compose-mongo

# pull container to your local environment
git pull origin feature/docker-compose-mongo

# change directory to folder with &amp;quot;Dockerfile&amp;quot;
cd mongo

# run command to start Docker up
docker-compose up --build

# start up (frontend) App
# install first
yarn &amp;amp;&amp;amp; yarn dev

## OPEN LOCALHOST:3000 http://localhost:3000

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;environment-variables&#34;&gt;ENVIRONMENT VARIABLES&lt;/h2&gt;
&lt;p&gt;We have to change directory into &lt;code&gt;packages/react-app/.env.local&lt;/code&gt; to create the &lt;code&gt;.env.local&lt;/code&gt; file (changed for security)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# terminal
$ code .env.local

# paste this into the newly opened file

BUILD_ENV=development
MONGODB_DB=bountyboard
#PROD_MONGODB_URI=
MONGODB_URI=mongodb://localhost:27017/bountyboard
NEXT_PUBLIC_DISCORD_SERVER_ID=8******************0
NEXT_PUBLIC_DISCORD_CHANNEL_BOUNTY_BOARD_ID=8******************0

# Public Environments
NEXT_PUBLIC_DAO_CURRENT_SEASON=1
NEXT_PUBLIC_DAO_CURRENT_SEASON_END_DATE=2021-08-31T04:00:00.000Z

# URLs
NEXT_PUBLIC_DAO_BOUNTY_BOARD_URL=https://bountyboard.bankless.community
DISCORD_BOUNTY_BOARD_WEBHOOK=

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;what-happens-when-you-pull-a-docker-container-locally&#34;&gt;What happens when you pull a Docker container locally&lt;/h2&gt;
&lt;p&gt;We are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pulling a folder for MongoDB with the latest scripts, schema, and Dockerfiles&lt;/li&gt;
&lt;li&gt;Using the docker-compose utility, &lt;code&gt;docker-compose up --build&lt;/code&gt; to fire up a Mongo container, and a temporary seeding container&lt;/li&gt;
&lt;li&gt;The seeding container runs a set of bash scripts to populate the DB
you can see this in &lt;code&gt;mongo/seed.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;opening-additional-terminal-windows-mongo&#34;&gt;Opening Additional Terminal windows: Mongo&lt;/h2&gt;
&lt;p&gt;Once, I ran &lt;code&gt;yarn dev&lt;/code&gt; I got the Application to fire up, &lt;code&gt;ready - started server on 0.0.0.0:3000, url: http://localhost:3000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;but &lt;code&gt;Mongo&lt;/code&gt; wasn&amp;rsquo;t turned on.&lt;/p&gt;
&lt;p&gt;First, open up a new terminal, then:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;docker exec -it mongo_mongo_1 bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Install DOCKER in VSCode to follow along&lt;/p&gt;
&lt;p&gt;Find the Container that&amp;rsquo;s a GREEN TRIANGLE, right click, then &lt;code&gt;attach shell&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; This did not work, so I needed to open a 3rd Terminal to type in:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;docker exec -it mongo_mongo_1 bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;exec&lt;/code&gt; executes a command &lt;code&gt;-it&lt;/code&gt; starts an interactive terminal session &lt;code&gt;mongo_mongo_1&lt;/code&gt; is the name of the container and &lt;code&gt;bash&lt;/code&gt; is the shell.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; You should see something like &lt;code&gt;root@4d5cedd1a8a7:/#&lt;/code&gt;, then type in the following to fire up &lt;strong&gt;Mongo Shell&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;mongosh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another confirmation is &lt;code&gt;Connecting to:          mongodb://127.0.0.1:27017/?directConnection=true&amp;amp;serverSelectionTimeoutMS=2000&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;At this point you can do basic Mongo commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;show collections
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: I was on the &lt;code&gt;test&amp;gt;&lt;/code&gt; database and needed to switch to &lt;code&gt;bountyboard&amp;gt;&lt;/code&gt; database where the &amp;ldquo;test&amp;rdquo; data was located and ready for testing.&lt;/p&gt;
&lt;p&gt;Other commands to run are &lt;code&gt;findOne()&lt;/code&gt; or &lt;code&gt;find()&lt;/code&gt; just to see the &lt;em&gt;seeded&lt;/em&gt; data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db.bounties.findOne()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; I did not get the front end to work so for this session, we only tested the database by querying in Mongo shell.&lt;/p&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Delete a table</title>
      <link>/technical_notes/example_tech/postgresql_delete_table/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_delete_table/</guid>
      <description>&lt;h2 id=&#34;delete-a-table&#34;&gt;Delete a table&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: Sometimes when testing a pipeline, you mess up a table (e.g., append the wrong index), you just need to delete and start over.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;TRUNCATE TABLE public.name_of_table;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on Data and DAOs 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Copy to new table</title>
      <link>/technical_notes/example_tech/postgresql_copy_to_new_table/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_copy_to_new_table/</guid>
      <description>&lt;h2 id=&#34;copy-existing-table-to-a-new-table&#34;&gt;Copy existing table to a new table&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: Useful to create &amp;lsquo;tests&amp;rsquo; tables while testing a new data pipeline. You can preserve the original in case you need to Write to or Update a table.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;CREATE TABLE new_table AS
TABLE original_table
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Connecting to postgresql database</title>
      <link>/technical_notes/example_tech/postgresql_connecting_sqlalchemy/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_connecting_sqlalchemy/</guid>
      <description>&lt;h2 id=&#34;connecting-to-postgresql-database-with-python&#34;&gt;Connecting to postgresql database with python&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: You need to establish connection to an existing table in your postgresql database in order to build a data pipeline into it.&lt;/p&gt;
&lt;p&gt;I use &lt;code&gt;sqlalchemy&lt;/code&gt; to work with existing tables in postgresql. In this project, I connected to a GraphQL API endpoint with &lt;code&gt;requests&lt;/code&gt; and the &lt;code&gt;json&lt;/code&gt; library is needed to work with JSON and &lt;code&gt;pandas&lt;/code&gt; for dataframes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;import sqlalchemy
from sqlalchemy import create_engine
from sqlalchemy import text

import requests
import json
import pandas as pd
from pprint import pprint
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;making-a-connection&#34;&gt;Making a connection&lt;/h2&gt;
&lt;p&gt;With &lt;code&gt;sqlalchemy&lt;/code&gt; we use the &lt;code&gt;create_engine()&lt;/code&gt; function. Here we&amp;rsquo;re reading a table and doing some data manipulation:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;db_string = &#39;postgresql://user:password@localhost:port/mydatabase&#39;
db = create_engine(db_string)

# once a database connection is established, we can select pieces of data we want from a table:

# Query existing postgres table: stg_subgraph_bank
# read from stg_subgraph_bank to select MAX (tx_timestamp)
# then, set to variable max_tx_timestamp

with db.connect() as conn:
    result = conn.execute(
        text(&amp;quot;SELECT MAX(tx_timestamp) AS max_tx_timestamp, MAX(id) AS max_id FROM stg_subgraph_bank_1&amp;quot;))
    for row in result:
        max_tx_timestamp = row.max_tx_timestamp
        max_id = row.max_id
        print(&amp;quot;new max_tx_timestamp: &amp;quot;, max_tx_timestamp)
        print(&amp;quot;new max_id: &amp;quot;, max_id)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on Data and DAOs 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Manually insert data to database</title>
      <link>/technical_notes/example_tech/postgresql_insert_csv_to_db/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_insert_csv_to_db/</guid>
      <description>&lt;h2 id=&#34;delete-a-table&#34;&gt;Delete a table&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: If you have a CSV file, you can manually load it into PostgreSQL through the pgAdmin client. This may require creating the data values in Excel first.&lt;/p&gt;
&lt;p&gt;First, you&amp;rsquo;d have to create a table with the right columns in pgAdmin before inserting data in.&lt;/p&gt;
&lt;p&gt;To create in Excel, you&amp;rsquo;d need a function to copy the values from the dataframe into a tuple of string values. Data is cut short to keep the example manageable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# In Excel
=CONCATENATE(&amp;quot;(&#39;&amp;quot;,C2,&amp;quot;&#39;,&#39;&amp;quot;,A2,&amp;quot;&#39;,&#39;&amp;quot;,B2,&amp;quot;&#39;,&#39;&amp;quot;,E2,&amp;quot;&#39;,&#39;&amp;quot;,D2,&amp;quot;&#39;),&amp;quot;)

=CONCATENATE(&amp;quot;(&#39;&amp;quot;,amount_display,&amp;quot;&#39;,&#39;&amp;quot;,from_address,&amp;quot;&#39;,&#39;&amp;quot;,id,&amp;quot;&#39;,&#39;&amp;quot;,timestamp,&amp;quot;&#39;,&#39;&amp;quot;,to_address,&amp;quot;&#39;),&amp;quot;)

# sample tuple format
(&#39;0x7a250d5630b4cf539739df2c5dacb4c659f2488d&#39;,&#39;14897.1883870177&#39;,&#39;0x59c1349bc6f28a427e78ddb6130ec669c2f39b48&#39;,&#39;0x0f433138b2a8f2997ef387ffcebec7cd204ab2053c43f8d4a6efaa74eddc0e0c-23&#39;,&#39;1620159318&#39;,&#39;Tue, 04 May 2021 20:15:18 GMT&#39;),
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the data is prepped in Excel, you can manully paste into pgAdmin (note: can be error prone with 20,000+ rows). Data is cut short to keep the example manageable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;INSERT INTO public.table_to_insert(
        amount_display, from_address, id, timestamp, to_address)
        VALUES
        (&#39;14897.1883870177&#39;,&#39;0x59c1349bc6f28a427e78ddb6130ec669c2f39b48&#39;,&#39;0x0f433138b2a8f2997ef387ffcebec7cd204ab2053c43f8d4a6efaa74eddc0e0c-23&#39;,&#39;1620159318&#39;,&#39;Tue, 04 May 2021 20:15:18 GMT&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: this is similar to how it&amp;rsquo;s done using the &lt;code&gt;sqlalchemy&lt;/code&gt; library in python.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# Sending Multiple Parameters
with engine.connect() as conn:
    conn.execute(
        text(&amp;quot;INSERT INTO some_table (x, y) VALUES (:x, :y)&amp;quot;),
        [{&amp;quot;x&amp;quot;: 11, &amp;quot;y&amp;quot;: 12}, {&amp;quot;x&amp;quot;: 13, &amp;quot;y&amp;quot;: 14}]
    )
    conn.commit()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on Data and DAOs 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prep dataframe to insert to database</title>
      <link>/technical_notes/example_tech/pipeline_prep_index_before_insert_to_db/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/pipeline_prep_index_before_insert_to_db/</guid>
      <description>&lt;h2 id=&#34;prep-dataframe-to-insert-to-database&#34;&gt;Prep dataframe to insert to database&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: When inserting to postgresql with sqlalchemy, the &lt;code&gt;to_sql()&lt;/code&gt; function works, but we need to make sure we&amp;rsquo;re appending the &lt;code&gt;id&lt;/code&gt; (primary key) column the right way &amp;ndash; incrementally.&lt;/p&gt;
&lt;p&gt;This will involve manipulating the dataframe with by incremeting with the &lt;code&gt;max_id&lt;/code&gt; before using &lt;code&gt;reset_index()&lt;/code&gt; to create an additional column using the natural index, then setting the &lt;code&gt;index=False&lt;/code&gt; parameter.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# change column name
# id, graph_id, amount_display, from_address, to_address, tx_timestamp, timestamp_display

# use rename function to change Two column names, set inplace=False to preserve original dataframe column name
df2 = df.rename(columns={&#39;id&#39;: &#39;graph_id&#39;,
                         &#39;timestamp&#39;: &#39;tx_timestamp&#39;}, inplace=False)


# reorder dataframe column using list of names
# list of names (in same order as stg_subgraph_bank)
list_of_col_names = [&#39;graph_id&#39;, &#39;amount_display&#39;, &#39;from_address&#39;,
                     &#39;to_address&#39;, &#39;tx_timestamp&#39;, &#39;timestamp_display&#39;]
df2 = df2.filter(list_of_col_names)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This next part is KEY:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;df2.index += max_id  # increment with max_id
df2 = df2.reset_index()  # reset index to later increment with max_id

df3 = df2.rename(columns={&#39;index&#39;: &#39;id&#39;}, inplace=False)

# only do this step if you&#39;ve made sure to duplicate a test table in postgresql, then ensure that the dataframe is in the same shape as the postgresql table
df3.to_sql(&#39;stg_subgraph_bank_1&#39;, con=db, if_exists=&#39;append&#39;, index=False)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Select a range of rows</title>
      <link>/technical_notes/example_tech/postgresql_select_range_of_rows/</link>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/postgresql_select_range_of_rows/</guid>
      <description>&lt;h2 id=&#34;select-a-range-of-rows&#34;&gt;Select a range of rows&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: This is most useful if your data table does not have a primary key. You can use the table&amp;rsquo;s natural index.&lt;/p&gt;
&lt;p&gt;Here is a way to select a range of rows. &lt;strong&gt;OFFSET&lt;/strong&gt; value is the number of rows to skip (here skipping &lt;code&gt;20500&lt;/code&gt; rows before returning any rows). &lt;strong&gt;ALL&lt;/strong&gt; indicates the max number of rows to return.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;SELECT * FROM table
LIMIT ALL OFFSET 20500
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wanted to start on row 15 and only return 10 rows, the query would be:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;SELECT * FROM table
LIMIT 10 OFFSET 15
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use pgAdmin to upload CSV to Postgres</title>
      <link>/technical_notes/example_tech/sql_upload_csv_postgres_pgadmin/</link>
      <pubDate>Wed, 03 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/sql_upload_csv_postgres_pgadmin/</guid>
      <description>&lt;h2 id=&#34;use-pgadmin-to-upload-csv-to-postgres-quick--dirty&#34;&gt;Use pgAdmin to upload CSV to Postgres (Quick &amp;amp; Dirty)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: There are many ways to upload CSV into Postgres. This is the relatively quick and dirty way. This represents an infrequent step where we happen to be loading a 20,000+ rows as a one-time event with subsequent smaller, more regular, events.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: The example below is part of a larger process of querying GraphQL in JSON and converting it to Pandas dataframe before getting it into Postgres. Here we are using a mixture of Excel and pgAdmin (Postgres client) to get the job done.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;: pgAdmin happens to be the Postgresql-client I&amp;rsquo;m using, but any client could work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pre-requisite Steps&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a database table in pgAdmin. Ideally, the columns are defined and consistent with the CSV data that&amp;rsquo;s about to be uploaded.
1a. Assuming a table has already been created, we will be using the &lt;code&gt;INSERT&lt;/code&gt; statement, otherwise, it would be a &lt;code&gt;CREATE TABLE&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;To &lt;code&gt;INSERT&lt;/code&gt; table, you&amp;rsquo;ll right click on a table (here we&amp;rsquo;re using, &amp;lsquo;stg_subgraph_bank&amp;rsquo;), select Scripts&amp;hellip;,then &lt;code&gt;INSERT Scripts&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following or close variation should appear. Here we are &lt;em&gt;inserting into&lt;/em&gt; the &lt;code&gt;stg_subgraph_bank&lt;/code&gt; table. In this example, there are 6 columns: &lt;code&gt;to_address&lt;/code&gt;, &lt;code&gt;amount_display&lt;/code&gt;, &lt;code&gt;from_address&lt;/code&gt;, &lt;code&gt;graph_id&lt;/code&gt;, &lt;code&gt;tx_timestamp&lt;/code&gt; and &lt;code&gt;timestamp_display&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;The &lt;code&gt;TRUNCATE TABLE&lt;/code&gt; is to remove existing data before inserting new data (if needed).&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;TRUNCATE TABLE public.stg_subgraph_bank;

INSERT INTO public.stg_subgraph_bank(
	to_address, amount_display, from_address, graph_id, tx_timestamp, timestamp_display)
	VALUES (?, ?, ?, ?, ?, ?);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we&amp;rsquo;re turning to Excel to prepare the data that will ultimately replace &amp;ldquo;VALUE (?, ?, ?, ?, ?, ?)&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;There is a &lt;code&gt;CONCATENATE&lt;/code&gt; function in Excel that converts data from rows/columns (CSV format) into parentheses of string values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;=CONCATENATE(&amp;quot;(&#39;&amp;quot;,C2,&amp;quot;&#39;,&#39;&amp;quot;,A2,&amp;quot;&#39;,&amp;quot;,B2,&amp;quot;&#39;,&#39;&amp;quot;,E2,&amp;quot;&#39;,&#39;&amp;quot;,D2,&amp;quot;&#39;),&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After that&amp;rsquo;s been created in Excel, we&amp;rsquo;re copying and pasting all 20,000+ rows (or however many) back into pgAdmin.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a truncated version of the 20,000+ rows of data with the &lt;code&gt;TRUNCATE&lt;/code&gt; command to remove existing data before inserting new data:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;TRUNCATE TABLE public.stg_subgraph_bank;

INSERT INTO public.stg_subgraph_bank(
	to_address, amount_display, from_address, graph_id, tx_timestamp, timestamp_display)
	VALUES 
	(&#39;0x7a250d5630b4cf539739df2c5dacb4c659f2488d&#39;,&#39;14897.1883870177&#39;,&#39;0x59c1349bc6f28a427e78ddb6130ec669c2f39b48&#39;,&#39;0x0f433138b2a8f2997ef387ffcebec7cd204ab2053c43f8d4a6efaa74eddc0e0c-23&#39;,&#39;1620159318&#39;,&#39;Tue, 04 May 2021 20:15:18 GMT&#39;),
(&#39;0x156d3129b2fd634d5b0817132401aa68b0126098&#39;,&#39;14897.1883870177&#39;,&#39;0x7a250d5630b4cf539739df2c5dacb4c659f2488d&#39;,&#39;0x0f433138b2a8f2997ef387ffcebec7cd204ab2053c43f8d4a6efaa74eddc0e0c-27&#39;,&#39;1620159318&#39;,&#39;Tue, 04 May 2021 20:15:18 GMT&#39;),
(&#39;0x11ebc944350df20940fb10dd8782d654d6aad8c6&#39;,&#39;37422.0374220399&#39;,&#39;0x9d1f1847582261be41f5a54e8b60cad21400c74f&#39;,&#39;0x355666cd33644fd05b36a54e4ddcd14190a71eea08a291731b6cd9ec8950a199-387&#39;,&#39;1620159318&#39;,&#39;Tue, 04 May 2021 20:15:18 GMT&#39;),
(&#39;0x5e7a1573620e0df38e41dd302f68d7d8e5b99bba&#39;,&#39;3231.14250158999&#39;,&#39;0x9d1f1847582261be41f5a54e8b60cad21400c74f&#39;,&#39;0x98f688d6adcdbb1a395b21c8f30b81ef0da8454d863e6d6f9a03305c082bae82-263&#39;,&#39;1620159320&#39;,&#39;Tue, 04 May 2021 20:15:20 GMT&#39;),
(&#39;0x2db3c0f42022fdc8dfe70036fee85e48a24b88af&#39;,&#39;3949.39809822999&#39;,&#39;0xfe8cac7dc7ac38da9ba540eb4d1797d0417dcc41&#39;,&#39;0xc9e209771502f73334340eeea2b943f98d9663a9b1eb4370d23f34a3c860c007-106&#39;,&#39;1620159320&#39;,&#39;Tue, 04 May 2021 20:15:20 GMT&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then run the query and the new data should populate the table.&lt;/p&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Check Equality of Two Columns</title>
      <link>/technical_notes/example_tech/sql_check_equality_two_columns/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/sql_check_equality_two_columns/</guid>
      <description>&lt;h2 id=&#34;check-equality-of-two-columns&#34;&gt;Check Equality of Two Columns&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: There are two tables with two columns with different names. You want a simple script to check if the rows of those columns are equal, so the two tables can be joined.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the SQL script, taken from 
&lt;a href=&#34;https://stackoverflow.com/questions/1632792/how-do-i-compare-two-columns-for-equality-in-sql-server/1632831&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this stackoverflow answer&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;
SELECT 
  CASE WHEN COLUMN1 = COLUMN2 
    THEN &#39;1&#39; 
    ELSE &#39;0&#39; 
  END 
  AS MyDesiredResult
FROM Table1
INNER JOIN Table2 ON Table1.PrimaryKey = Table2.ForeignKey

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s an application of this script used in &lt;strong&gt;DAO Dash&lt;/strong&gt;. We are comparing two tables - &lt;code&gt;discord_user&lt;/code&gt; and &lt;code&gt;discord_messages&lt;/code&gt; by these two columns respectively:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;discord_user_id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;author_user_id&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r}&#34;&gt;SELECT 
  CASE WHEN discord_user_id = author_user_id 
    THEN &#39;1&#39;
    ELSE &#39;0&#39;
  END
  AS AreColumnsEqual
FROM discord_user d
INNER JOIN discord_messages m ON d.discord_user_id = m.author_user_id 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Database Design Course by Caleb Curry</title>
      <link>/technical_notes/example_tech/database_design_tips/</link>
      <pubDate>Tue, 26 Oct 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/database_design_tips/</guid>
      <description>&lt;h2 id=&#34;introduction-to-database-design&#34;&gt;Introduction to Database Design&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: There are notes from an 
&lt;a href=&#34;https://www.youtube.com/watch?v=ztHopE5Wnpc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;8 hour course on YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;tldr&#34;&gt;TLDR&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;What is the relationship between entities (tables)? Physically draw out the lines and relationships (cardinality)
&lt;ol&gt;
&lt;li&gt;one-to-one&lt;/li&gt;
&lt;li&gt;one-to-many (&amp;lsquo;many&amp;rsquo; side is the Foreign Key)&lt;/li&gt;
&lt;li&gt;many-to-many (break into two one-to-many relationships w/ intermediary table)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Do we need Lookup Tables?&lt;/li&gt;
&lt;li&gt;Design Data Tables for Integrity
&lt;ol&gt;
&lt;li&gt;Entity Integrity - ID for uniqueness
&lt;ol&gt;
&lt;li&gt;Ensure Atomic Values (Natural Keys, if cannot, then add surrogate keys)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Referential Integrity - connect tables between Foreign Keys to Primary Keys&lt;/li&gt;
&lt;li&gt;Domain Integrity - identify data types of each variable (i.e., numeric, string, date)&lt;/li&gt;
&lt;li&gt;No repeating data&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Identify which foreign key is NOT NULL (surrogate id will Auto-Increment) (modality)&lt;/li&gt;
&lt;li&gt;Normalize the data
&lt;ol&gt;
&lt;li&gt;1 NF (first normal form) - atomicity&lt;/li&gt;
&lt;li&gt;2 NF (second normal form) - partial depenency&lt;/li&gt;
&lt;li&gt;3 NF (third normal form) - transitive dependency (solution: take problematic columns and split into their own tables with foreign key)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Foreign Key Constraints; SQL statements:
&lt;ol&gt;
&lt;li&gt;ON DELETE
&lt;ol&gt;
&lt;li&gt;RESTRICT&lt;/li&gt;
&lt;li&gt;CASCADE&lt;/li&gt;
&lt;li&gt;SET NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;ON UPDATE
&lt;ol&gt;
&lt;li&gt;RESTRICT&lt;/li&gt;
&lt;li&gt;CASCADE&lt;/li&gt;
&lt;li&gt;SET NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Deteremine which JOIN is needed to get the best &amp;ldquo;view&amp;rdquo;; which table goes after the FROM statement (which table is on the left?)
&lt;ol&gt;
&lt;li&gt;INNER JOIN&lt;/li&gt;
&lt;li&gt;LEFT JOIN&lt;/li&gt;
&lt;li&gt;SELF JOIN&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;What is a Relational Database?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entity (Rows)
&lt;ol&gt;
&lt;li&gt;Entity = User (a person, an object)&lt;/li&gt;
&lt;li&gt;Row = all attribute values for an entity&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Attribute (Columns)
&lt;ol&gt;
&lt;li&gt;Attributes are &lt;em&gt;about&lt;/em&gt; an entity (user name, name, password, address etc)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Mathematical name for a Row is a Tuple&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;RDBMS&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;View Mechanism changes the how data is presented (i.e., we don&amp;rsquo;t want all rows x columns, just a subset)
&lt;ol&gt;
&lt;li&gt;Select only certain columns&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;View = Read Only (not everyone has access to Update for security purpose)&lt;/li&gt;
&lt;li&gt;RDBMS allows &amp;ldquo;transactions&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Example: MySQL, SQL Server, PostgreSQL (open source)&lt;/li&gt;
&lt;li&gt;Database &amp;amp; Relational Database are not separate things&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define structure (DDL, data definition language)
&lt;ol&gt;
&lt;li&gt;CREATE,&lt;/li&gt;
&lt;li&gt;structure &amp;amp; connection between tables - JOIN&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Manipulates data (DML, data manipulation language) -
&lt;ol&gt;
&lt;li&gt;UPDATE&lt;/li&gt;
&lt;li&gt;data within tables&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;What is Database Design?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Separate information into multiple tables, while preventing data integrity issues&lt;/li&gt;
&lt;li&gt;How do you measure whether a database is &amp;ldquo;good&amp;rdquo; or &amp;ldquo;bad&amp;rdquo;? &amp;ndash;&amp;gt; Data Integrity&lt;/li&gt;
&lt;li&gt;Good design prevents &amp;ldquo;data integrity issues&amp;rdquo;
&lt;ol&gt;
&lt;li&gt;All data up to date&lt;/li&gt;
&lt;li&gt;No repeating data&lt;/li&gt;
&lt;li&gt;No incorrect data&lt;/li&gt;
&lt;li&gt;No broken relationships&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Conceptual Schema: How data is related.&lt;/li&gt;
&lt;li&gt;Logical Schema: Table structures (i.e., X number of columns, data types), number of tables&lt;/li&gt;
&lt;li&gt;Physical Schema: Implementing into database, table types, what server? how will people access?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Data Integrity&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Entity integrity
&lt;ol&gt;
&lt;li&gt;ID is used to enforce uniqueness of an entity (user)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Referential integrity
&lt;ol&gt;
&lt;li&gt;Foreign key constrains&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Domain integrity
&lt;ol&gt;
&lt;li&gt;Range of what we&amp;rsquo;re storing (correct Data Types; integers, text or dates)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Note: Relational Database does not come from the word &amp;ldquo;relationship&amp;rdquo;, it comes from Relations which is a mathematical connection between Sets&lt;/li&gt;
&lt;li&gt;When we don&amp;rsquo;t have data integrity, we have errors&lt;/li&gt;
&lt;li&gt;When we have errors, data integrity allows us to correct those errors&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Database Terms (Review)&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data&lt;/li&gt;
&lt;li&gt;Database&lt;/li&gt;
&lt;li&gt;Relational Database (stores things in tables)&lt;/li&gt;
&lt;li&gt;DBMS (how to control database)&lt;/li&gt;
&lt;li&gt;RDBMS&lt;/li&gt;
&lt;li&gt;Null (when someone doesn&amp;rsquo;t enter a value)&lt;/li&gt;
&lt;li&gt;Anomolies (errors)&lt;/li&gt;
&lt;li&gt;Integrity (protect against anomolies)
&lt;ol&gt;
&lt;li&gt;Entity&lt;/li&gt;
&lt;li&gt;Referential - keep connection through Foreign Keys and Primary Keys&lt;/li&gt;
&lt;li&gt;Domain - correct data types&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Entity - what we store&lt;/li&gt;
&lt;li&gt;Attributes*** - things about an entity&lt;/li&gt;
&lt;li&gt;Relations* - connection between two sets or Tables&lt;/li&gt;
&lt;li&gt;Tuple** or Row (all attributes about an entity)&lt;/li&gt;
&lt;li&gt;Table* - physical representation of
&lt;ol&gt;
&lt;li&gt;Rows**&lt;/li&gt;
&lt;li&gt;Columns***&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;File* (aka Table)&lt;/li&gt;
&lt;li&gt;Record** (aka Row)&lt;/li&gt;
&lt;li&gt;Field*** (aka Column)&lt;/li&gt;
&lt;li&gt;Value (something in a column)&lt;/li&gt;
&lt;li&gt;Entry (aka a Row)&lt;/li&gt;
&lt;li&gt;DB Design - process of designing table to have integrity&lt;/li&gt;
&lt;li&gt;Schema - structure of tables&lt;/li&gt;
&lt;li&gt;Normalization - steps to get the best data base design&lt;/li&gt;
&lt;li&gt;Naming Convention - consistency in naming&lt;/li&gt;
&lt;li&gt;Keys - something to make things in unique in a table and connect between tables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;More Database Terms&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SQL
&lt;ol&gt;
&lt;li&gt;DDL data define language&lt;/li&gt;
&lt;li&gt;DML data manipulation language&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;SQL Keywords - reserved words (e.g., SELECT)&lt;/li&gt;
&lt;li&gt;Frontend - we program frontends so people can securely access the database (doesn&amp;rsquo;t allow us to type in SQL)&lt;/li&gt;
&lt;li&gt;Backend - serverside code to communicate with database&lt;/li&gt;
&lt;li&gt;Client side&lt;/li&gt;
&lt;li&gt;Server side - serves instances of the database to the client&lt;/li&gt;
&lt;li&gt;Server side scripting language&lt;/li&gt;
&lt;li&gt;Views - taking data from database and illustrating it in a different from how it&amp;rsquo;s stored&lt;/li&gt;
&lt;li&gt;Joins - connect data from multiple tables
&lt;ol&gt;
&lt;li&gt;ID foreign key connection&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Atomic Values&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Everything in a database should be about 1 thing&lt;/li&gt;
&lt;li&gt;Example: &amp;ldquo;Paul Apivat Hanvongse&amp;rdquo; &amp;ndash; to make it atomic, create 3 separate columns (i.e., nickname, first name, last name)&lt;/li&gt;
&lt;li&gt;Atom - smallest indivisible piece (1 thing) but still makes sense to treat as 1 thing
&lt;ol&gt;
&lt;li&gt;example: Address - street, city, state, zip code (3 columns)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Relationships&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Relationship - connects two or more entities&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Example:
(Entities)
Database &amp;ndash;&amp;gt; Student - Attribute
&amp;ndash;&amp;gt; Professor - Attribute
&amp;ndash;&amp;gt; Class - Attribute
&amp;ndash;&amp;gt; Major - Attribute&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s multiple relationships here; Student have a Major, Students are in a Class, Professors are part of a Major, Professors teach a Class.&lt;/p&gt;
&lt;p&gt;One-to-One&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One Entity has connection with another Entity (e.g., Husband - Wife)&lt;/li&gt;
&lt;li&gt;Social security number unique to one person&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One-to-Many&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Comments under a Youtube video;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;User &amp;ndash;&amp;gt; Comment 1
&amp;ndash;&amp;gt; Comment 2
&amp;ndash;&amp;gt; Comment 3&lt;/p&gt;
&lt;p&gt;Many-to-Many&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Polygamous marriage (i.e., Multiple husbands have multiple wives)&lt;/li&gt;
&lt;li&gt;College: Class &amp;amp; Students; class can have multiple students &amp;amp; students can take multiple classes&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Designing One-to-One Relationships&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Example: Person and Username&lt;/li&gt;
&lt;li&gt;Generally One-to-one relations are stored in the same table&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;user_name&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Apivat&lt;/td&gt;
&lt;td&gt;Paul&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Caleb&lt;/td&gt;
&lt;td&gt;Caleb_Curry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;There are times when one-to-one relations are stored in &lt;em&gt;different&lt;/em&gt; tables (when you want to store &lt;em&gt;extra&lt;/em&gt; attributes &lt;em&gt;about&lt;/em&gt; the attribute)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Cardholder Entity         &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;first_name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;card_id&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(card_id &amp;lt;&amp;ndash;&amp;gt; ID )&lt;/p&gt;
&lt;p&gt;Card&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;card_number&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;issue_date&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;late_fees&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Summary - One-to-One Relationship&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Store attribute of the entity in the table&lt;/li&gt;
&lt;li&gt;OR use another table and connect with a foreign_key&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Designing One-to-Many Relationships&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &amp;ldquo;many&amp;rdquo; side is a foreign key to the &amp;ldquo;one&amp;rdquo; side&lt;/li&gt;
&lt;li&gt;User id stays the same.&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(multiple cards)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Card&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;card_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Card2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;card2_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Card3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;card3_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Parent Tables and Child Tables&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Tables are either Parent or Child&lt;/li&gt;
&lt;li&gt;Keys keep tables Unique&lt;/li&gt;
&lt;li&gt;Primary key = Parent (User ID)&lt;/li&gt;
&lt;li&gt;Foreign key = Child (user_id as a reference to User ID)&lt;/li&gt;
&lt;li&gt;Child points back to Parents&lt;/li&gt;
&lt;li&gt;In one-to-one, we don&amp;rsquo;t have to worry about parent or child&lt;/li&gt;
&lt;li&gt;In one-to-many, many Children point to a Parent&lt;/li&gt;
&lt;li&gt;When we have a Child table, we always know the Parent (but not vice versa)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Notation&lt;/strong&gt;
One to One &amp;ndash;&amp;gt; 1 : 1
One to Many &amp;ndash;&amp;gt; 1 : N
Many to Many &amp;ndash;&amp;gt; M : N&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Designing Many-to-Many Relationships&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;M : N&lt;/li&gt;
&lt;li&gt;Classes : Students&lt;/li&gt;
&lt;li&gt;Parent &amp;lt;&amp;ndash;&amp;gt; Parent&lt;/li&gt;
&lt;li&gt;Solution: Break it up to TWO One-to-Many Relationships with an INTERMEDIARY or JUNCTION table to connect&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th&gt;Class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;td&gt;math&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;science&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;english&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;ID&lt;/th&gt;
&lt;th&gt;Student&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;John&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;Jake&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;Sally&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Claire&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Intermediary Table
(Child Table for both Parents)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;class_id&lt;/th&gt;
&lt;th&gt;student_id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;75&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;89&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Summary of Relationships&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Now we can design every &amp;ldquo;binary relationship&amp;rdquo; - any relationship between two Entities&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Keys&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Keys should be Unique&lt;/li&gt;
&lt;li&gt;Never Changing&lt;/li&gt;
&lt;li&gt;Never NULL&lt;/li&gt;
&lt;li&gt;What should be unique? (e.g., a user e-mail)
&lt;ol&gt;
&lt;li&gt;Could be a &lt;em&gt;Natural Key&lt;/em&gt; (already in the table, no need to define a new column)&lt;/li&gt;
&lt;li&gt;Could be &lt;em&gt;user name&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Key should be Never Changing (otherwise database integrity is compromised)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Primary Key Index&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Index - think Index in a Book;&lt;/li&gt;
&lt;li&gt;Index points you to the data&lt;/li&gt;
&lt;li&gt;Keys are a type of Index&lt;/li&gt;
&lt;li&gt;Indexs are used for
&lt;ol&gt;
&lt;li&gt;SELECT * FROM&lt;/li&gt;
&lt;li&gt;WHERE first_name = &amp;lsquo;Caleb&amp;rsquo;     (need index for this)&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Look Up Table&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Example look-up table of member status:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;member_status id is the foreign key that can point to a members table&lt;/li&gt;
&lt;li&gt;all connections stay the same even if member_status changes&lt;/li&gt;
&lt;li&gt;can set Foreign Key constraints&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;member_status&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;gold&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;silver&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;bronze&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;first_quest_complete&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;guess_pass&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;level_1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;level_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;level_3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(where member_status &amp;amp; student_id are One-to-Many)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;student&lt;/th&gt;
&lt;th&gt;member_status_id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;John&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;Jake&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;Sally&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Claire&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;(where member_status &amp;amp; student_id are Many-to-Many)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;student_id&lt;/th&gt;
&lt;th&gt;member_status_id&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Lookup Tables (w Keys) allow for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Integrity&lt;/li&gt;
&lt;li&gt;Uniqueness&lt;/li&gt;
&lt;li&gt;Improves functionality (no repeating data)&lt;/li&gt;
&lt;li&gt;Less work&lt;/li&gt;
&lt;li&gt;Allows for added complexity&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Superkey and Candidate Key&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Two main kinds of keys:
&lt;ol&gt;
&lt;li&gt;Primary Key&lt;/li&gt;
&lt;li&gt;Foreign Key&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Superkey&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Any number of columns that forces each row to be unique&lt;/li&gt;
&lt;li&gt;How do we know each row is unique and talks about one entity (user)?&lt;/li&gt;
&lt;li&gt;Superkey = any number column values  to force that each row is unique&lt;/li&gt;
&lt;li&gt;Candidate key = the least number of column to force every row to be unique (ie., username)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You&amp;rsquo;ll never program a superkey&lt;/p&gt;
&lt;p&gt;Candidate Key&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Superkey is asking: &amp;ldquo;Can every row be unique?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Then, once we answer yes, Candidate key asks: &amp;ldquo;How many columns are needed (to force every row to be unique) ?&amp;rdquo; &amp;ndash; what&amp;rsquo;s the least number of columns&lt;/li&gt;
&lt;li&gt;Then, &amp;ldquo;How many Candidate Keys do we have?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;THEN, decide which Candidate Key will be the PRIMARY KEY.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Primary Key &amp;amp; Alternate Keys&lt;/strong&gt;
Primary Key Possibilities&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;username*&lt;/li&gt;
&lt;li&gt;email&lt;/li&gt;
&lt;li&gt;full name, last name, middle name, address, birthday&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;*out of these three, username is the best primary key&lt;/p&gt;
&lt;p&gt;What are the criteria for choosing a Primary Key?&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;UNIQUE&lt;/li&gt;
&lt;li&gt;NEVER CHANGING&lt;/li&gt;
&lt;li&gt;NEVER NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Primary keys can also be an Index (use Select statement and how you connect most of your data).&lt;/p&gt;
&lt;p&gt;Keys &lt;em&gt;not&lt;/em&gt; chosen to be the Primary Key become the Alternate Keys. Alternate Keys can be useful - you could use &amp;ldquo;email&amp;rdquo; (an alternate key) as an Index.&lt;/p&gt;
&lt;p&gt;SELECT * FROM table
WHERE email = &amp;ldquo;&lt;a href=&#34;mailto:value@gmail.com&#34;&gt;value@gmail.com&lt;/a&gt;&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Surrogate Keys and Natural Keys&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;These are &amp;ldquo;categories&amp;rdquo; of Primary Keys&lt;/li&gt;
&lt;li&gt;You won&amp;rsquo;t search for these, but you&amp;rsquo;ll Design the Database with these in mind&lt;/li&gt;
&lt;li&gt;Natural Keys are NATURALLY in the table; they fit requirements for Primary Keys and already &lt;em&gt;in&lt;/em&gt; the table (email, username)&lt;/li&gt;
&lt;li&gt;Surrogate Keys are ADDED to your table (i.e., &lt;em&gt;id&lt;/em&gt;); they AUTO-INCREMENT
&lt;ol&gt;
&lt;li&gt;user &amp;ndash;&amp;gt; user_id&lt;/li&gt;
&lt;li&gt;sale &amp;ndash;&amp;gt; sale_id&lt;/li&gt;
&lt;li&gt;comment &amp;ndash;&amp;gt; comment_id&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Should I use Surrogate Keys or Natural Keys?&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Natural keys = already there, but not always obvious which should e natural key&lt;/li&gt;
&lt;li&gt;Surrogate keys = easy, but you have to add a new column&lt;/li&gt;
&lt;li&gt;Choose one or the other
&lt;ol&gt;
&lt;li&gt;minor performance differences&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Caleb personally uses Surrogate Key
&lt;ol&gt;
&lt;li&gt;Example:    user &amp;ndash;&amp;gt; user_id&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Foreign Key&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Foreign Key References a Primary Key (either same table or separate table)&lt;/li&gt;
&lt;li&gt;Every table has ONE Primary Key (could be composed of many columns)&lt;/li&gt;
&lt;li&gt;Every table can have MULTIPLE Foreign Keys referencing many other tables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Not NULL Foreign Keys&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Foreign Key constraints&lt;/li&gt;
&lt;li&gt;Every row is required to have a value if the column has &amp;ldquo;not Null&amp;rdquo;&lt;/li&gt;
&lt;li&gt;related to Cardinality&lt;/li&gt;
&lt;li&gt;(NOTE: sometimes you don&amp;rsquo;t want to set &amp;ldquo;Not NULL&amp;rdquo; because  an id doesn&amp;rsquo;t currently exist; but sometimes you want to force that relationship to be there between Foreign Key and Primary Key)&lt;/li&gt;
&lt;li&gt;you either want Not NULL or Not Required (depending on the situation)&lt;/li&gt;
&lt;li&gt;Primary Key values should never change, Foreign Key values &lt;em&gt;can&lt;/em&gt; change&lt;/li&gt;
&lt;li&gt;We don&amp;rsquo;t want Primary Key values to change, but we could have Foreign Key references change (?)&lt;/li&gt;
&lt;li&gt;Primary Key and Foreign Key should be the same data type&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Foreign Key Constraints&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;FK = Referential Integrity&lt;/li&gt;
&lt;li&gt;Make sure if you update Parent, ZChildren will update&lt;/li&gt;
&lt;li&gt;Prevent creating Children if there&amp;rsquo;s no Parent&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;SQL Statements that talk about FK constraints and refer to the Parent (Primary Key)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ON DELETE = when we delete the Parent, we want to delete the Child
&lt;ol&gt;
&lt;li&gt;RESTRICT = (no action) throw an error whenever the Parent is deleted&lt;/li&gt;
&lt;li&gt;CASCADE = whatever we do to Parent, we do to Child (delete parent, delete child)&lt;/li&gt;
&lt;li&gt;SET NULL = if delete Parent, sets Child to NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;ON UPDATE = when we update the Parent, we want to update the Child
&lt;ol&gt;
&lt;li&gt;RESTRICT = (no action) throw an error when try to Update Parent&lt;/li&gt;
&lt;li&gt;CASCADE = If we update Parent, Child updates as well&lt;/li&gt;
&lt;li&gt;SET NULL = if update Parents, thro&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Every Foreign Key column value needs to reference a Primary Key value&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Simple Key, Composite Key, Compound Key&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;categories of Keys&lt;/li&gt;
&lt;li&gt;Simple Primary Keys - single column (e.g., username)&lt;/li&gt;
&lt;li&gt;Composite Primary Key has multiple columns, as a group as Primary Key; at least one column doesn&amp;rsquo;t have to be a key&lt;/li&gt;
&lt;li&gt;Compound Primary Key - combination of columns in intermediary tables (in many-to-many relations); Primary Keys are compounded; all columns have to be a key&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For Intermediary Tables some people will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;add a surrogate_id to the Compound&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;REVIEW&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Superkey&lt;/li&gt;
&lt;li&gt;Candidate Key - least number of columns used to enforce uniqueness&lt;/li&gt;
&lt;li&gt;Primary Key** - the candidate key you select as the Main key&lt;/li&gt;
&lt;li&gt;Alternate Keys - the candidate keys you didn&amp;rsquo;t select as Primary Key&lt;/li&gt;
&lt;li&gt;Foreign Keys** - make connection between tables; references Primary Keys&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Primary + Foreign&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Surrogate &amp;amp; Natural Keys - surrogate (user_id) is random with no real value; Natural is already contained in your database&lt;/li&gt;
&lt;li&gt;(don&amp;rsquo;t switch between these two)&lt;/li&gt;
&lt;li&gt;Rule: You should be able to enforce uniqueness by the columns that are Naturally already there, &lt;em&gt;add&lt;/em&gt; a surrogate key if you want&lt;/li&gt;
&lt;li&gt;Rule 2: If you cannot define uniqueness naturally, you&amp;rsquo;ll need to rely on a Surrogate key (try to avoid)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(can switch between Simple + Composites - you won&amp;rsquo;t define these explicitly)
6. Simple Key - one column key
7. Composite Key - multiple column keys
8. Compound Key - multiple column keys&lt;/p&gt;
&lt;p&gt;Foreign Key Constraints&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ON DELETE
&lt;ol&gt;
&lt;li&gt;RESTRICT&lt;/li&gt;
&lt;li&gt;CASCADE&lt;/li&gt;
&lt;li&gt;SET NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;ON UPDATE
&lt;ol&gt;
&lt;li&gt;RESTRICT&lt;/li&gt;
&lt;li&gt;CASCADE&lt;/li&gt;
&lt;li&gt;SET NULL&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Entity Relationship Modeling&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A standard for Drawing Databases&lt;/li&gt;
&lt;li&gt;EER Model (Enhanced Entity Relationship Model)&lt;/li&gt;
&lt;li&gt;ERD            (Enhanced Relationship Diagram)&lt;/li&gt;
&lt;li&gt;ER Model   (Enhanced Relationship)&lt;/li&gt;
&lt;li&gt;DDL: Define Database Structure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;{do actual drawing}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cardinality&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one to one: |&amp;mdash;&amp;mdash;-|&lt;/li&gt;
&lt;li&gt;one to many:    |&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;E&lt;/li&gt;
&lt;li&gt;one row to many rows&lt;/li&gt;
&lt;li&gt;many to one:    E&amp;mdash;&amp;mdash;&amp;mdash;|&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Modality&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can assign &amp;ldquo;NOT NULL&amp;rdquo; to Foreign Key, to say each card &lt;em&gt;must&lt;/em&gt; have an owner&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;card_holder (Primary Key)&lt;/th&gt;
&lt;th&gt;card Foreign Key&lt;/th&gt;
&lt;th&gt;card_number&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;368&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;98&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;368&lt;/td&gt;
&lt;td&gt;112&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;4 Modalities
card_owner &amp;mdash;&amp;mdash;&amp;ndash; card&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;-|&amp;mdash;&amp;mdash;&amp;mdash;0&amp;ndash;|-      one-to-one; one card_owner can have zero or 1 card&lt;/li&gt;
&lt;li&gt;-|&amp;mdash;&amp;mdash;&amp;mdash;|&amp;ndash;|-      one-to-one; one card_owner must have 1 and only 1 card&lt;/li&gt;
&lt;li&gt;-|&amp;mdash;&amp;mdash;&amp;mdash;0&amp;ndash;E-  one-to-many; one card_owner can have 0 or many cards&lt;/li&gt;
&lt;li&gt;-|&amp;mdash;&amp;mdash;&amp;mdash;|&amp;ndash;E-  one-to-many; one card_owner must hv 1 or many cards&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Introduction to Database Normalization&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Normalization is a process where we go through our database and correct things that may cause database problems like
&lt;ol&gt;
&lt;li&gt;data integrity problems&lt;/li&gt;
&lt;li&gt;repeating data&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Third Main Forms (three step-by-step data normalization process)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;1 NF     (first normal form)&lt;/li&gt;
&lt;li&gt;2 NF    (second normal form)&lt;/li&gt;
&lt;li&gt;3 NF    (third normal form)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Systematic way to normalize a good structured database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;everything must be atomic&lt;/li&gt;
&lt;li&gt;think about how data &lt;em&gt;depends&lt;/em&gt; on other data (dependencies)&lt;/li&gt;
&lt;li&gt;must go in sequential order 1 NF &amp;ndash;&amp;gt; 2 NF &amp;ndash;&amp;gt; 3 NF&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1 NF (First Normal Form of Database Normalization)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Atomicity  (data must be atomic or about one thing)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Problem: &amp;ldquo;Address column&amp;rdquo; is not atomic (street, apt, city, country, zip)
Solution: Break this column into multiple columns&lt;/p&gt;
&lt;p&gt;Problem: User enters two email(s) as a single value (two values in one cell)
Still Problem: Generate same two users for two emails (two of same primary keys)&lt;/p&gt;
&lt;p&gt;Solution: Break into &lt;em&gt;two&lt;/em&gt; tables - User table &amp;amp; Email table - turn this into a
one-to-many   (one user to many emails)&lt;/p&gt;
&lt;p&gt;User
user_id (primary key)
first_name
last_name&lt;/p&gt;
&lt;p&gt;Email
email_id
email
user_id (foreign key)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2 NF (Second Normal Form of Database Normalization)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Partial Dependency&lt;/em&gt;  (when a column depends on part of a Primary Key)&lt;/li&gt;
&lt;li&gt;You need ot have a &lt;em&gt;compound&lt;/em&gt; or &lt;em&gt;composite&lt;/em&gt; key (Primary Key has to be multiple columns)&lt;/li&gt;
&lt;li&gt;Found in Many-to-Many relationships w/ Intermediary Tables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;{see notebook for illustration}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3 NF (Third Normal Form of Database Normalization)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;must do 1st and 2nd Normal Form before getting to 3 NF&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Transitive Dependency&lt;/em&gt; (when a column depends on a column, which depends on a Primary Key)&lt;/li&gt;
&lt;li&gt;Solution: Take a transitive dependency (problematic column), move them to a new table and reference them with a foreign key&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Summary of Normal Forms&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;1 NF = making everything atomic&lt;/li&gt;
&lt;li&gt;2 NF = removing partial dependencies&lt;/li&gt;
&lt;li&gt;3 NF = removing transitive dependencies&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Indexes (Clustered, Nonclustered, Composite Index)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See a book&amp;rsquo;s index (or Phone Book)&lt;/li&gt;
&lt;li&gt;A list of where certain data points are&lt;/li&gt;
&lt;li&gt;Data is sorted in a way that can easily be found&lt;/li&gt;
&lt;li&gt;Nonclustered Index = tells you how to get to the data (book&amp;rsquo;s index)
&lt;ul&gt;
&lt;li&gt;points to the data&lt;/li&gt;
&lt;li&gt;a list of references that point to the data (like back of the book)&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clustered Index = organizes the actual data in a way that&amp;rsquo;s easy to use
&lt;ul&gt;
&lt;li&gt;organizes the actual data&lt;/li&gt;
&lt;li&gt;faster and better than non-clustered&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Databases&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rather than having to go through &amp;ldquo;all&amp;rdquo; the data (i.e., Table Scan), you create an index (index seek, makes queries faster)&lt;/li&gt;
&lt;li&gt;Downside: When you update the data, you have to update the index as well otherwise index becomes outdated and useless&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;li&gt;You only want to create an index for frequently used data
&lt;ul&gt;
&lt;li&gt;Primary Key that is indexed makes it faster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apply WHERE (sql query) column to an Indexed column&lt;/li&gt;
&lt;li&gt;Index increase speed of JOINS&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Whenever you&amp;rsquo;re JOINing certain columns, the two columns you&amp;rsquo;re joining should be Indexed&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Data Types&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Date
&lt;ol&gt;
&lt;li&gt;date&lt;/li&gt;
&lt;li&gt;time&lt;/li&gt;
&lt;li&gt;datetime&lt;/li&gt;
&lt;li&gt;timestamp (can be millisecond or time, when something was &amp;ldquo;done&amp;rdquo; or when something was &amp;ldquo;created&amp;rdquo; or &amp;ldquo;updated&amp;rdquo; or when a new row is entered)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Numeric
&lt;ol&gt;
&lt;li&gt;integer (only whole numbers)&lt;/li&gt;
&lt;li&gt;decimal (more accurate)&lt;/li&gt;
&lt;li&gt;float / double (unsigned)&lt;/li&gt;
&lt;li&gt;binary&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;String
&lt;ol&gt;
&lt;li&gt;Char(8),&lt;/li&gt;
&lt;li&gt;varchar(8) 0 up to 8 characters&lt;/li&gt;
&lt;li&gt;text - longer strings (comments, paragraphs)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;everything-above-here-is-ddl---data-definition-language&#34;&gt;Everything above here is DDL - data definition language&lt;/h2&gt;
&lt;h2 id=&#34;below-here-are-dml---data-manipulation-language&#34;&gt;Below here are DML - data manipulation language**&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Introduction to JOINS&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joins bring multiple tables into a presentable format&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Inner Join&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Table A (customer table)&lt;/li&gt;
&lt;li&gt;Table B (card table)&lt;/li&gt;
&lt;li&gt;When there are rows that connect them, a new Table is presented&lt;/li&gt;
&lt;li&gt;Taking only the rows that intersect between two tables
&lt;ul&gt;
&lt;li&gt;Eliminate any customers that do not have a card&lt;/li&gt;
&lt;li&gt;Eliminate any cards that do not have a customer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Exclude rows that are &lt;em&gt;not&lt;/em&gt; in both tables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:&lt;/p&gt;
&lt;p&gt;Customer Table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;customer (Primary Key)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;customer_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;first_name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;last_name&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Card Table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;card (Foreign Key)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;card_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;customer_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_amount&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;monthly_bill&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;amount_paid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;amount_owed&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Example Inner Join of Customer Table &amp;amp; Card Table&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;first_name&lt;/th&gt;
&lt;th&gt;last_name&lt;/th&gt;
&lt;th&gt;amount_paid&lt;/th&gt;
&lt;th&gt;amount_owed&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Paul&lt;/td&gt;
&lt;td&gt;Apivat&lt;/td&gt;
&lt;td&gt;2200&lt;/td&gt;
&lt;td&gt;3000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Paul&lt;/td&gt;
&lt;td&gt;Apivat&lt;/td&gt;
&lt;td&gt;720&lt;/td&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jimmy&lt;/td&gt;
&lt;td&gt;John&lt;/td&gt;
&lt;td&gt;3000&lt;/td&gt;
&lt;td&gt;5000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;SELECT
first_name,
last_name,
amount_paid,
amount_owed
FROM customer cu
INNER JOIN card ca ON cu.customer_id = ca.customer_id&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;INNER JOIN on 3 Tables&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;See illustration&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;INNER JOIN on 3 Tables (with Example)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;See illustration&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction to OUTER JOINS&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;INNER JOIN                      - least rows&lt;/li&gt;
&lt;li&gt;LEFT (Outer) JOIN&lt;/li&gt;
&lt;li&gt;RIGHT (Outer) JOIN&lt;/li&gt;
&lt;li&gt;FULL (Outer) JOIN          - most rows&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;RIGHT OUTER JOIN&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;same as Left Outer Join, except the Right Table keeps all the rows&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;IN PRACTICE, most people don&amp;rsquo;t use Right Joins; instead they&amp;rsquo;ll use a LEFT JOIN and just flip the tables&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How do you know which table is LEFT or RIGHT?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SELECT column1, column2, column3
FROM this_table_is_Left
LEFT JOIN&amp;hellip;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JOIN with NOT NULL Columns&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not Null columns can cause some confusion when it comes to Joins&lt;/li&gt;
&lt;li&gt;If you want to return &lt;em&gt;all&lt;/em&gt; of a column, don&amp;rsquo;t worry about NOT NULL, just put that table in the SELECT statement (i.e., make the table on the left side) and use a LEFT JOIN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;{see illustrations}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Outer JOIN Across 3 Tables&lt;/strong&gt;
Can combine&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LEFT (outer) JOIN with&lt;/li&gt;
&lt;li&gt;RIGHT (outer) JOIN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Aliases&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use when writing SELECT statements&lt;/li&gt;
&lt;li&gt;use AS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;SELF JOIN&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;take a Table and JOINING with itself&lt;/li&gt;
&lt;li&gt;How to think about it:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Duplicate your exact table&lt;/li&gt;
&lt;li&gt;Joining with itself&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Illustration&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;v1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;user&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;referred_by&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;v2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;SELECT
v1.first_name,
v1.last_name,
v1.email,
v2.email
FROM user AS v1
JOIN user AS v2
ON v1.referred_by = v2.user_id&lt;/p&gt;
&lt;p&gt;(Self-Join is taking the same table, &amp;ldquo;user&amp;rdquo;, and making a duplicate)&lt;/p&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Continuous to Discrete Plotting</title>
      <link>/technical_notes/example_tech/rstats_tip_continuous_to_discrete_plot/</link>
      <pubDate>Sat, 09 Oct 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip_continuous_to_discrete_plot/</guid>
      <description>&lt;h2 id=&#34;continuous-to-discrete-plotting&#34;&gt;Continuous to Discrete Plotting&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: When plotting integers on the x-axis, it shows up in a ggplot like 2.5, 5, 7.5 and we want each bar to be plotted discretely (e.g. 1,2,3,4,5&amp;hellip;)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;
gov_partcipation %&amp;gt;%
    ggplot(aes(x = n, y = nn)) +
    geom_col(aes(fill = as.factor(n))) +
    geom_text(aes(label = nn), vjust = -0.5, color = &amp;quot;white&amp;quot;) +
    # this sets the sequence from 1 to 10 with a break of 1
    # turns a continuous sequence (2.5) into a discrete one (1,2,3...)
    scale_x_continuous(breaks=seq(1,10, 1))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reverse Plotting</title>
      <link>/technical_notes/example_tech/rstats_tip_reverse_plotting/</link>
      <pubDate>Sat, 09 Oct 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip_reverse_plotting/</guid>
      <description>&lt;h2 id=&#34;top-to-bottom&#34;&gt;Top to Bottom&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: AFTER you display bar charts in a specific order because you successfully specified the 
&lt;a href=&#34;https://paulapivat.com/technical_notes/example_tech/rstats_tip_manually_order_factors/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;factor levels order&lt;/a&gt;, you simply want to reverse the order (from top-to-bottom).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: I&amp;rsquo;ve created a specific factor order and simply want to reverse the order so what was on top is now on the bottom, using &lt;code&gt;scale_y_descrete(limits = rev())&lt;/code&gt;, the &lt;code&gt;rev()&lt;/code&gt; and &lt;code&gt;levels()&lt;/code&gt; function are used in tandem to specific the reverse.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;
new %&amp;gt;%
    count(name) %&amp;gt;%
    ggplot(aes(x = n, y = name, fill = name)) +
    geom_col() +
    geom_text(aes(label = n), hjust = -0.2, color = &amp;quot;white&amp;quot;) +
    # reverse from top to bottom on the y-axis
    # note levels for a specific column new$name already set previously
    scale_y_discrete(limits = rev(levels(new$name))) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;right-to-left&#34;&gt;Right to Left&lt;/h2&gt;
&lt;p&gt;Works the same way, but using &lt;code&gt;scale_x_discrete&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two Y-Axes</title>
      <link>/technical_notes/example_tech/rstats_viz_2_y_axes/</link>
      <pubDate>Fri, 08 Oct 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_2_y_axes/</guid>
      <description>&lt;h2 id=&#34;creating-2-y-axes-in-a-plot&#34;&gt;Creating 2 Y-Axes in a Plot&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: You want to create &lt;strong&gt;two y-axes&lt;/strong&gt;. The left y-axis measures an amount, while the &lt;em&gt;right&lt;/em&gt; y-axis converts the amount to a percentage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: This may be useful when you have a bar chart depicting relative amounts (e.g., membership numbers) and you require &lt;em&gt;another&lt;/em&gt; y-axis (right side) to map &lt;em&gt;another&lt;/em&gt; amount as a percentage of the former (e.g., % of members who successfully activated on their first day).&lt;/p&gt;
&lt;p&gt;This is exampe is taken from the 
&lt;a href=&#34;https://docs.google.com/presentation/d/18DGuSTsLgU2C2iNNcvoo2-27uL2Tcb1jfMaMGa9Zeyc/edit#slide=id.gf1c26dd130_1_11&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bankless DAO Community Growth metrics&lt;/a&gt; where we looked at:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How many new members successfully activate on their first day?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;First, unlike typical use cases, we are &lt;strong&gt;not&lt;/strong&gt; using &lt;code&gt;pivot_longer&lt;/code&gt; in this example, but instead keep the data in a &lt;em&gt;wide&lt;/em&gt; format (&lt;code&gt;pivot_wider&lt;/code&gt;). We are visualizing 3 separate variables (columns) here, including: &lt;code&gt;new_members&lt;/code&gt;, &lt;code&gt;pct_communicated&lt;/code&gt; and &lt;code&gt;pct_opened_channels&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In addition, we&amp;rsquo;ll have a hard-coded fourth line that represents the industry &amp;ldquo;benchmark&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Because&lt;/em&gt; we are not using a &lt;code&gt;pivot_longer&lt;/code&gt; function, we will have to &lt;em&gt;manually&lt;/em&gt; create our own legend. This will be explained in the commented code below:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;first_activation %&amp;gt;%
    rename(
        time = &amp;quot;interval_start_timestamp&amp;quot;,
        new = &amp;quot;new_members&amp;quot;,
        talked = &amp;quot;pct_communicated&amp;quot;,
        visited = &amp;quot;pct_opened_channels&amp;quot;
    ) %&amp;gt;%
    ggplot(aes(x = time)) +
    # note: 3 separate charts: one bar and two lines
    geom_bar(aes(y = new, color = &amp;quot;New members&amp;quot;), stat = &amp;quot;identity&amp;quot;, fill = &amp;quot;black&amp;quot;) +
    # The left y-axis goes from 0-1500, &#39;talked&#39; and &#39;visited&#39; is multiplied by 1500/100 = 15
    # color is set to a string so it can be repurposed in the manually created legend
    geom_line(aes(y = talked*15, color = &amp;quot;% talked (voice or text)&amp;quot;), size = 1.5) +
    geom_line(aes(y = visited*15, color = &amp;quot;% visited more than 3 channels&amp;quot;), size = 1.5) +
    geom_line(y = 480, color = &amp;quot;orange&amp;quot;, size = 0.2) +
    # scale_y_continuous(sec.axis) is the key to having two y-axes
    # The left y-axis goes from 0-1500, so sec.axis has ~./1500*100
    # name indicates both left and right y-axis label
    scale_y_continuous(
        name = &amp;quot;New Members&amp;quot;,
        sec.axis = sec_axis(trans = ~./1500*100, name = &amp;quot;% Activated&amp;quot;)
    ) +
    # We have to manually set color because we didn&#39;t actually set color in geom_line above
    scale_color_manual(values = c(&amp;quot;white&amp;quot;, &amp;quot;red&amp;quot;, &amp;quot;black&amp;quot;)) +
    # setting the color = &amp;quot;Legend&amp;quot; allows us to indicate on the chart where legend is
    labs(
        title = &amp;quot;How many new members successfully activate on their first day?&amp;quot;,
        x = &amp;quot;&amp;quot;,
        color = &amp;quot;Legend&amp;quot;
    )

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;converting-second-y-axis-to-another-number-aside-from-percentage-&#34;&gt;Converting Second Y-axis to another number aside from Percentage (%)&lt;/h3&gt;
&lt;p&gt;This is similar to the example above, except the math is adjusted so that if you wanted to convert &lt;strong&gt;two scales&lt;/strong&gt; (and neither is a %). This is appropriate for when visualizing both a &lt;em&gt;total amount&lt;/em&gt; (Messages sent) and &lt;em&gt;average amount&lt;/em&gt; (Messages per communicator).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;
msg_avg %&amp;gt;%
    rename(
        time = &amp;quot;interval_start_timestamp&amp;quot;,
        per = &amp;quot;messages_per_communicator&amp;quot;
    ) %&amp;gt;%
    ggplot(aes(x = time)) +
    geom_bar(aes(y = messages, color = &amp;quot;Messages sent&amp;quot;), stat = &amp;quot;identity&amp;quot;, fill = &amp;quot;black&amp;quot;) +
    # conversion between two y-axis (similar to % conversion)
    # Here we convert 6000 to 12
    geom_line(aes(y = per*6000/12, color = &amp;quot;Messages per communicator&amp;quot;), size = 1.5) +
    geom_line(y = 5000, color = &amp;quot;orange&amp;quot;, size = 0.2) +
    scale_y_continuous(
        name = &amp;quot;Messages sent&amp;quot;,
        sec.axis = sec_axis(trans = ~./6000*12, name = &amp;quot;Message per ommunicator&amp;quot;)
    ) +
    scale_color_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;black&amp;quot;))


&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Manually Ordering Factors</title>
      <link>/technical_notes/example_tech/rstats_tip_manually_order_factors/</link>
      <pubDate>Fri, 08 Oct 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip_manually_order_factors/</guid>
      <description>&lt;h2 id=&#34;manually-ordering-factors&#34;&gt;Manually Ordering Factors&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Situation&lt;/strong&gt;: Sometimes you have want to display bar charts in a specific order, but the numbers get re-arranged or &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;sort&lt;/code&gt; orders by value, but you have a specific order in mind.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;: In this example, I have &amp;ldquo;Proposals&amp;rdquo; numbered &amp;ldquo;1-10&amp;rdquo;. I want to display them in order, but number 10 doesn&amp;rsquo;t go after 9, but instead goes 1, 10, 2, 3, and so on&amp;hellip;I need to &lt;strong&gt;manually set the factor order&lt;/strong&gt; so the bar chart displays exactly how I&amp;rsquo;d like.&lt;/p&gt;
&lt;p&gt;I used &lt;code&gt;fct_relevel&lt;/code&gt; (factor re-level), choose a specific column, and the second parameter is a vector of values with the factors manually arranged according to how I&amp;rsquo;d like. Then I set it to that specific column so R knows the desired factor level.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# manually arranging factors - num
# note: move &amp;quot;proposal 10&amp;quot; to the end
# them apply newly arranged factor levels to column of interest
new$num &amp;lt;- fct_relevel(new$num, c(&amp;quot;proposal 1&amp;quot;, &amp;quot;proposal 2&amp;quot;, &amp;quot;proposal 3&amp;quot;, &amp;quot;proposal 4&amp;quot;, &amp;quot;proposal 5&amp;quot;, 
                       &amp;quot;proposal 6&amp;quot;, &amp;quot;proposal 7&amp;quot;, &amp;quot;proposal 8&amp;quot;, &amp;quot;proposal 9&amp;quot;, &amp;quot;proposal 10&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can also achieve this for string values that don&amp;rsquo;t have an obvious order. Here i&amp;rsquo;m ordering the proposals by a known sequence (but not obvious to the audience).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{python}&#34;&gt;# manually arrange factors - name
# then apply newly arranged factor levels to column of interest
new$name &amp;lt;- fct_relevel(new$name, c(&amp;quot;Approve the Bankless DAO Genesis Proposal&amp;quot;,
                        &amp;quot;What charity should CMS Holdings donate 100k towards&amp;quot;,
                        &amp;quot;Badge Distribution for Second Airdrop&amp;quot;,
                        &amp;quot;Reward Season 0 Active Members&amp;quot;,
                        &amp;quot;Bankless DAO Season 1&amp;quot;,
                        &amp;quot;BanklessDAO Season 1 Grants Committee Ratification&amp;quot;,
                        &amp;quot;BED Index Logo Contest&amp;quot;,
                        &amp;quot;Request for funds for Notion&#39;s ongoing subscription&amp;quot;,
                        &amp;quot;Transfer ownership of the treasury multisig wallet from the genesis team to the DAO&amp;quot;,
                        &amp;quot;Bankless DAO Season 2&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Survey Data Cleaning</title>
      <link>/technical_notes/example_tech/data_cleaning_tip1/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/data_cleaning_tip1/</guid>
      <description>&lt;h2 id=&#34;survey-data-cleaning&#34;&gt;Survey Data Cleaning&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: These tips are a distillation of data cleaning techniques I picked up in the course of cleaning data for the first DAO Creators Survey (Gitcoin x BanklessDAO).&lt;/p&gt;
&lt;p&gt;The DAO Creators Survey was a two part survey sampling 442 and 256 respondents to approximately 50 survey questions ranging from demographics to web3 tooling, DAO compensation/healthcare and income stability, to name a few.&lt;/p&gt;
&lt;p&gt;The questions ranged from highly structured (i.e., multiple choice, multiple response options and dropdown boxes) to highly unstructured (i.e., qualitative responses).&lt;/p&gt;
&lt;p&gt;I created approximately 50 charts for this report and each chart presented unique data cleaning challenges. However, I will describe a base foundation and areas of overlap so the next project is easier.&lt;/p&gt;
&lt;p&gt;Two articles were used for reference, but because this project optimized for speed, I did &lt;em&gt;not&lt;/em&gt; do a full text analysis.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;a href=&#34;https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to Generate Word Clouds in R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.tidytextmining.com/tidytext.html#summary&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Text Mining with R: A Tidy Approach&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;pre-cleaning-steps&#34;&gt;Pre-Cleaning Steps&lt;/h3&gt;
&lt;p&gt;The first move for any survey is to &lt;strong&gt;change column names&lt;/strong&gt; into more manageable short codes and then &lt;strong&gt;delete identifying information&lt;/strong&gt; to preserve privacy, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df1 &amp;lt;- df %&amp;gt;%
    # Rename: shorten column names to be manageable
    rename(
       timestamp = &amp;quot;Timestamp&amp;quot;,
       daos_work_for = &amp;quot;what DAO(s) do you work for? for each DAO, how many hours/month do you work? (feel free to include multiple)&amp;quot;,
       city = &amp;quot;what city are you based in?&amp;quot;,
       twitter = &amp;quot;whats your twitter username?&amp;quot;,
       eth_addr = &amp;quot;whats your ETH address?&amp;quot;,
       ) %&amp;gt;%
    # delete identifying information
    select(-twitter, -eth_addr, -email)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;baseline-step-convert-text-to-tidy-format&#34;&gt;Baseline Step: Convert Text to Tidy Format&lt;/h3&gt;
&lt;p&gt;This requires the &lt;code&gt;tidytext&lt;/code&gt; package and a couple functions. The flow is to use &lt;code&gt;unnest_tokens()&lt;/code&gt; to separate a string of words into a vector of individual words. Then follow-up with &lt;code&gt;anti_join()&lt;/code&gt; to get rid of &lt;strong&gt;stop words&lt;/strong&gt; (a corpus of words is provided with tidytext).&lt;/p&gt;
&lt;p&gt;Then, group and tally, which can be achieved with &lt;code&gt;group_by()&lt;/code&gt; and &lt;code&gt;tally(sort = TRUE)&lt;/code&gt; or one function &lt;code&gt;count(, sort = TRUE)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;daos_work_tbl %&amp;gt;%
    unnest_tokens(word, text) %&amp;gt;%
    anti_join(stop_words) %&amp;gt;% 
    view()

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If there are too many words, we can &lt;code&gt;filter()&lt;/code&gt; and drop NA responses. With &lt;code&gt;dplyr&lt;/code&gt; these operations can be chained to &lt;code&gt;ggplot2&lt;/code&gt; to visualize the output.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;daos_work_tbl %&amp;gt;%
    unnest_tokens(word, text) %&amp;gt;%
    anti_join(stop_words) %&amp;gt;% 
    count(word, sort = TRUE) %&amp;gt;%
    filter(n &amp;gt; 3) %&amp;gt;%
    drop_na() %&amp;gt;%
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;string-detect&#34;&gt;String Detect&lt;/h3&gt;
&lt;p&gt;Sometimes you need to use &lt;code&gt;str_detect()&lt;/code&gt; to see how many instances of a string are present in a column. If there is a &lt;em&gt;match&lt;/em&gt; of string detected, you want to categorize survey responses. This is structured combining &lt;code&gt;if_else()&lt;/code&gt; conditionals with &lt;code&gt;str_detect()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This first requires creating an empty column:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# create empty column
daos_work_long$bin &amp;lt;- NA

# use if_else and str_detect
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;cre8&amp;quot;)==TRUE), &amp;quot;cre8rdao&amp;quot;, &amp;quot;NA&amp;quot;)
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;mstable&amp;quot;)==TRUE), &amp;quot;mstable&amp;quot;, daos_work_long$bin)
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;marrow&amp;quot;)==TRUE), &amp;quot;marrow dao&amp;quot;, daos_work_long$bin)
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;badger&amp;quot;)==TRUE), &amp;quot;badger dao&amp;quot;, daos_work_long$bin)
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;raid&amp;quot;)==TRUE), &amp;quot;raid guild&amp;quot;, daos_work_long$bin)
daos_work_long$bin &amp;lt;- if_else((str_detect(daos_work_long$word, &amp;quot;metagame&amp;quot;)==TRUE), &amp;quot;metagame&amp;quot;, daos_work_long$bin)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;string-match&#34;&gt;String Match&lt;/h3&gt;
&lt;p&gt;In some situations, you may want to see if a string &lt;em&gt;contains&lt;/em&gt; a specific word. The function to use here is &lt;code&gt;str_match()&lt;/code&gt;. Here, we&amp;rsquo;re seeing if a string contains either &lt;code&gt;yes&lt;/code&gt; or &lt;code&gt;yeah&lt;/code&gt; or &lt;code&gt;no&lt;/code&gt; or &lt;code&gt;not&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;income_stability_tbl2 &amp;lt;- income_stability_tbl %&amp;gt;%
    mutate(phrase = strsplit(as.character(text), &amp;quot;,&amp;quot;)) %&amp;gt;%
    unnest(phrase) %&amp;gt;%
    count(phrase, sort = TRUE) %&amp;gt;%
    mutate(
        phrase_no = str_match(phrase, &amp;quot;[Nn]o|[Nn]ot&amp;quot;)[,1],
        phrase_no = str_to_lower(phrase_no)
    ) %&amp;gt;%
    mutate(
        phrase_yes = str_match(phrase, &amp;quot;[Yy]es|[Yy]eah&amp;quot;)[,1],
        phrase_yes = str_to_lower(phrase_yes)
    )

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;handling-each-survey-question-column-separately&#34;&gt;Handling each survey question (column) separately&lt;/h3&gt;
&lt;p&gt;This requires splitting each column off. You could turn it into a &lt;code&gt;vector&lt;/code&gt; first, then &lt;code&gt;tibble&lt;/code&gt; or just subset a dataframe:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;comp_denom_v &amp;lt;- as.vector(df1$comp_denom)
comp_denom_tbl &amp;lt;- tibble(line = 1:445, text = comp_denom_v)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;manually-add-numbers&#34;&gt;Manually add numbers&lt;/h3&gt;
&lt;p&gt;Surprisingly, it was not easy to add items from the &lt;strong&gt;same&lt;/strong&gt; category:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Item&lt;/th&gt;
&lt;th&gt;Number&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Zebra&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Zebra&lt;/td&gt;
&lt;td&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It should be more straight forward to add Zebra. But instead we have to really manually add. For example, here i&amp;rsquo;m manually changing the &lt;code&gt;n&lt;/code&gt; for bankless dao to &lt;code&gt;35&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# bankless dao = 35
daos_work_long2$n[12] &amp;lt;- 35

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;delete-specific-rows&#34;&gt;Delete specific rows&lt;/h3&gt;
&lt;p&gt;There are two ways to delete rows. First is to subset (a base R operation):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;daos_work_long3 &amp;lt;- daos_work_long2[-c(4, 6, 13, 14, 15, 19, 24, 28, 31, 42, 46, 51, 52, 53,
                  61, 63, 67, 68, 69, 70, 78, 81, 87, 95, 100, 103),] %&amp;gt;% 
                  arrange(desc(n))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second way is to use &lt;code&gt;slice&lt;/code&gt; in &lt;code&gt;dplyr&lt;/code&gt;. &lt;code&gt;Slice&lt;/code&gt; can be used to select or re-order rows as well:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;usd_earning_tbl3 &amp;lt;- usd_earning_tbl2 %&amp;gt;%
                    slice(4, 6, 7, 1:3, 5, 8:9)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;assigning-factors-to-preserve-order-for-visualization&#34;&gt;Assigning Factors to Preserve Order for Visualization&lt;/h3&gt;
&lt;p&gt;After using &lt;code&gt;slice&lt;/code&gt; to re-order rows, we can use &lt;code&gt;mutate()&lt;/code&gt; and &lt;code&gt;as_factor()&lt;/code&gt; to create factors for visualization. This preserves the order we want (e.g., age range on the x-axis):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# reorder rows, save as new df
usd_earning_tbl3 &amp;lt;- usd_earning_tbl2 %&amp;gt;%
    slice(4, 6, 7, 1:3, 5, 8:9)

# need to sort by factors before visualize
usd_earning_tbl3 %&amp;gt;% 
    mutate(text_factor = as_factor(text))
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;separate-string-at-comma&#34;&gt;Separate String at Comma&lt;/h3&gt;
&lt;p&gt;Sometimes, simply turning a string into &lt;code&gt;tidytext&lt;/code&gt; doesn&amp;rsquo;t work because meaning phrases of two or three words &lt;em&gt;inadvertently&lt;/em&gt; get split, so we may need to split by comma with &lt;code&gt;mutate()&lt;/code&gt; and &lt;code&gt;strsplit()&lt;/code&gt;, in lieu of using &lt;code&gt;unnest_tokens()&lt;/code&gt;, then group and tally:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;task_tabl2 &amp;lt;- task_tbl %&amp;gt;%
    mutate(phrase = strsplit(as.character(text), &amp;quot;,&amp;quot;)) %&amp;gt;%
    unnest(phrase) %&amp;gt;%
    count(phrase, sort = TRUE) %&amp;gt;%
    view()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;github-repo&#34;&gt;Github Repo&lt;/h3&gt;
&lt;p&gt;See data cleaning scripts 
&lt;a href=&#34;https://github.com/PaulApivat/banklessDAO/tree/main/dao_survey_gitcoin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Consume Open API with R</title>
      <link>/technical_notes/example_tech/rstats_open_api/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_open_api/</guid>
      <description>&lt;h2 id=&#34;reading-in-json-data-from-an-open-api&#34;&gt;Reading in JSON data from an Open API&lt;/h2&gt;
&lt;p&gt;The following example is an 
&lt;a href=&#34;https://covid19.th-stat.com/api/open/timeline&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open API&lt;/a&gt; from the Ministry of Public Health in Thailand.&lt;/p&gt;
&lt;p&gt;The following script consumes the API using the &lt;code&gt;httr&lt;/code&gt; package, then transforms JSON to dataframe via the &lt;code&gt;jsonlite&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;httr&amp;quot;)
install.packages(&amp;quot;jsonlite&amp;quot;)
library(httr)
library(jsonlite)

# send a GET request to the Ministry of Public Health Open API
# consume API to receive JSON file
url &amp;lt;- &amp;quot;https://covid19.th-stat.com/api/open/timeline&amp;quot;
resp &amp;lt;- GET(url = url)

# convert JSON file into text
text_json &amp;lt;- content(resp, as = &amp;quot;text&amp;quot;, encoding = &amp;quot;UTF-8&amp;quot;)

# read text from JSON
jfile &amp;lt;- fromJSON(text_json)

# save as data frame
df &amp;lt;- as.data.frame(jfile)

# view data frame
View(df)

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Circular Dendrogram</title>
      <link>/technical_notes/example_tech/rstats_viz_circular_dendrogram/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_circular_dendrogram/</guid>
      <description>&lt;h2 id=&#34;creating-a-circular-dendrogram-with-ggraph&#34;&gt;Creating a Circular Dendrogram with ggraph&lt;/h2&gt;
&lt;p&gt;I tried creating a 
&lt;a href=&#34;https://www.r-graph-gallery.com/339-circular-dendrogram-with-ggraph.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Circular Dendrogram&lt;/a&gt; using reproducible code from R Graph Gallery.&lt;/p&gt;
&lt;p&gt;However, the code on the website has some issues so I submitted a 
&lt;a href=&#34;https://github.com/holtzy/R-graph-gallery/pull/34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pull request to fix it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The code below, for the most part, match the original on R Graph Gallery, except 4 lines of code that were updated to fix the &lt;code&gt;geom_node_text&lt;/code&gt; issue:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# libraries
library(ggraph)
library(igraph)
library(tidyverse)
library(RColorBrewer) 

# create data.frame
d1=data.frame(from=&amp;quot;origin&amp;quot;, to=paste(&amp;quot;group&amp;quot;, seq(1,10), sep=&amp;quot;&amp;quot;))
d2=data.frame(from=rep(d1$to, each=10), to=paste(&amp;quot;subgroup&amp;quot;, seq(1,100), sep=&amp;quot;_&amp;quot;))
edges=rbind(d1, d2)

# create vertices
vertices = data.frame(
    name = unique(c(as.character(edges$from), as.character(edges$to))) , 
    value = runif(111)
) 

vertices$group = edges$from[ match( vertices$name, edges$to ) ]


vertices$id=NA
myleaves=which(is.na( match(vertices$name, edges$from) ))
nleaves=length(myleaves)
vertices$id[ myleaves ] = seq(1:nleaves)

# change the angle of the geom_node_text
# angle and hjust must be consistent

vertices$angle = 360 / nleaves * vertices$id + 110  # adjust angle calculation

vertices$hjust&amp;lt;-ifelse( vertices$angle &amp;lt; 291, 1, 0) # adjust hjust

vertices$angle&amp;lt;-ifelse(vertices$angle &amp;lt; 291, vertices$angle+180, vertices$angle) # adjust where 180 is added

# crate mygraph object (dendrogram)
mygraph &amp;lt;- graph_from_data_frame( edges, vertices=vertices )

# plot the dendrogram
ggraph(mygraph, layout = &#39;dendrogram&#39;, circular = TRUE) + 
    geom_edge_diagonal(colour=&amp;quot;grey&amp;quot;) +
    scale_edge_colour_distiller(palette = &amp;quot;RdPu&amp;quot;) +
    geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = angle, hjust=hjust, colour=group), size=2.7, alpha=1) +
    geom_node_point(aes(filter = leaf, x = x*1.07, y=y*1.07, colour=group, size=value, alpha=0.2)) +
    scale_colour_manual(values= rep( brewer.pal(9,&amp;quot;Paired&amp;quot;) , 30)) +
    scale_size_continuous( range = c(0.1,10) ) +
    theme_void() +
    theme(
        legend.position=&amp;quot;none&amp;quot;,
        plot.margin=unit(c(0,0,0,0),&amp;quot;cm&amp;quot;),
    ) +
    expand_limits(x = c(-1.3, 1.3), y = c(-1.3, 1.3)) +
    coord_flip()  # add coord_flip

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more content on data science, R, and Python 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Use Anti_Joins to Find Non-Matching Rows</title>
      <link>/technical_notes/example_tech/rstats_tip6/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip6/</guid>
      <description>&lt;h2 id=&#34;finding-non-matching-rows-before-joining-columns&#34;&gt;Finding Non-Matching Rows Before Joining Columns&lt;/h2&gt;
&lt;p&gt;We often need to join two columns from different data frames. Rows to be joined are &lt;em&gt;assumed&lt;/em&gt; to have the same value.&lt;/p&gt;
&lt;p&gt;Even different casing means those values will not be joined. For example: &amp;ldquo;Nigeria&amp;rdquo; and &amp;ldquo;NIGERIA&amp;rdquo; will not be joined.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s particularly useful to know which values are &lt;strong&gt;not&lt;/strong&gt; in sync when you have a list of countries and you want to join with one of the &lt;code&gt;map&lt;/code&gt; libraries (e.g., &lt;code&gt;ggmap&lt;/code&gt;). If the country is spelt differently, the join doesn&amp;rsquo;t happen.&lt;/p&gt;
&lt;p&gt;Enter anti_join:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;world_map1 &amp;lt;- world_map %&amp;gt;%
    mutate(id = region)

df1 &amp;lt;- df %&amp;gt;%
    mutate(id = country)
    
# use anti_join to figure out which rows are not aligned
anti_join(world_map1, df1, by = &amp;quot;id&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Extend Color Palettes</title>
      <link>/technical_notes/example_tech/rstats_viz_extend_color/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_extend_color/</guid>
      <description>&lt;h2 id=&#34;extending-the-number-of-colors-available-in-a-palette&#34;&gt;Extending the number of colors available in a palette&lt;/h2&gt;
&lt;p&gt;You might be using the &lt;code&gt;RColorBrewer&lt;/code&gt; library and one of the palettes: Sequential, Qualitative or Diverging:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sequential&lt;/strong&gt; includes: Blues, BuGn, BuPu, GnBu, Greens, Greys, Oranges, OrRd, PuBu, PuBuGn, PuRd, Purples, RdPu, Reds, YlGn, YlGnBu YlOrBr, YlOrRd.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qualitative&lt;/strong&gt; includes: Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Diverging&lt;/strong&gt; includes: BrBG, PiYG, PRGn, PuOr, RdBu, RdGy, RdYlBu, RdYlGn, Spectral&lt;/p&gt;
&lt;p&gt;These palettes 8-9 colors, at most 12. But what if you need more? Here&amp;rsquo;show to &lt;em&gt;extend&lt;/em&gt; the palettes:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(RColorBrewer)

number.colors &amp;lt;- 46
mycolors &amp;lt;- colorRampPalette(brewer.pal(8, &amp;quot;Set1&amp;quot;))(number.colors)

df %&amp;gt;%
   ggplot(aes(x=x, y=y)) +
   geom_boxplot() +
   geom_point() +
   scale_color_manual(values = mycolors)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Formating Dates with Lubridate</title>
      <link>/technical_notes/example_tech/rstats_dates/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_dates/</guid>
      <description>&lt;h2 id=&#34;changing-date-formats-with-lubridate&#34;&gt;Changing Date formats with Lubridate&lt;/h2&gt;
&lt;p&gt;For every data visualization project that involves using &lt;code&gt;dates&lt;/code&gt; on one of the axes, I always find myself having to re-format the date so that visualization &amp;ldquo;works&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a workflow that is recommended at the &lt;strong&gt;start&lt;/strong&gt; of any data visualization project.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(lubridate) # handling dates

df %&amp;gt;%
    # handling date first
    mutate(
        date = original_date_variable %&amp;gt;% ymd(),
        year = date %&amp;gt;% year(),
        month = date %&amp;gt;% month(),
        day = date %&amp;gt;% day(),
        year_month = make_datetime(year, month) # combine year &amp;amp; month
    ) 
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Reading and manipulating nested data</title>
      <link>/technical_notes/example_tech/rstats_unnest/</link>
      <pubDate>Sun, 11 Oct 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_unnest/</guid>
      <description>&lt;h2 id=&#34;ways-of-handling-nested-data&#34;&gt;Ways of handling nested data&lt;/h2&gt;
&lt;p&gt;Recently, I downloaded JSON data from BigQuery and had to make sense of the data. This starts with getting the data into tabular form.&lt;/p&gt;
&lt;p&gt;Here are the libraries I used:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(jsonlite)
library(tidyverse)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, read in JSON data. Once read in, we check its class type to see that its a list. We&amp;rsquo;ll want to get it into a data frame.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# read data out into Large list (321 elements, 2.4 Mb)
# each row is *another* list

funnel &amp;lt;- lapply(readLines(&amp;quot;bq-mixpanel-funnel.json&amp;quot;), fromJSON)

# &amp;quot;list&amp;quot; class
class(funnel)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After searching online, three approaches continually resurfaced.&lt;/p&gt;
&lt;p&gt;First, using &lt;code&gt;unlist()&lt;/code&gt; and converting into &lt;code&gt;matrix()&lt;/code&gt; before wrapping &lt;em&gt;that&lt;/em&gt; in a &lt;code&gt;data.frame()&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Approach 1: convert to matrix, array

unlist_funnel &amp;lt;- matrix(unlist(funnel), byrow = TRUE, ncol = length(funnel[[1]]))
rownames(unlist_funnel) &amp;lt;- names(funnel)
as.data.frame(unlist_funnel) %&amp;gt;% view()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These next approaches get us closer (&lt;strong&gt;note&lt;/strong&gt;: I know from interacting with the data in BigQuery that there &lt;em&gt;should&lt;/em&gt; be 321 rows):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Approach 2: Convert list to data frame

df &amp;lt;- data.frame(matrix(unlist(funnel), nrow = length(funnel), byrow = TRUE))
df2 &amp;lt;- data.frame(matrix(unlist(funnel), nrow = length(funnel), byrow = FALSE))
df3 &amp;lt;- data.frame(matrix(unlist(funnel), nrow = 321, byrow = TRUE), stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next approach is to use &lt;code&gt;lapply()&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#works but everything is on one column

unlist(lapply(funnel, c)) %&amp;gt;% view() 

# this makes everything a list, but we want everything into a vector
t(lapply(funnel, c)) %&amp;gt;% view() 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, the approach that worked best, in this particular case was &lt;code&gt;sapply()&lt;/code&gt;. This functions turns things into vector, which can then be converted into a dataframe:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#still the ideal, this works because &#39;c&#39; is used ot combine lists

t(sapply(funnel, c)) %&amp;gt;% view()  
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Styling tables with reactable</title>
      <link>/technical_notes/example_tech/rstats_viz_reactable/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_reactable/</guid>
      <description>&lt;h2 id=&#34;setting-up-a-barebones-table-with-reactable&#34;&gt;Setting up a barebones table with {reactable}&lt;/h2&gt;
&lt;p&gt;There are several &lt;code&gt;packages&lt;/code&gt; to style your tables. This note will help you get setup with a basic table using the &lt;code&gt;reactable&lt;/code&gt; package. With just a few lines of code, you can have a table with pagination and column sorting.&lt;/p&gt;
&lt;p&gt;The data for this note comes from 
&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-22/readme.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TidyTuesday 2020-09-22, &amp;ldquo;Himalayan Climbers&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This note assumes that data has been wrangled and in &lt;code&gt;tibble&lt;/code&gt; form, ready to be styled into a table.&lt;/p&gt;
&lt;h2 id=&#34;sample-tibble&#34;&gt;Sample Tibble&lt;/h2&gt;
&lt;p&gt;Here, I&amp;rsquo;ve saved my tibble of 20 rows and 3 columns in &lt;code&gt;df&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; df

# A tibble: 20 x 3
   peak            attempts fail_rate
   &amp;lt;chr&amp;gt;              &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
 1 Everest            21813     0.54 
 2 Cho Oyu             8890     0.570
 3 Ama Dablam          8406     0.479
 4 Manaslu             4593     0.621
 5 Dhaulagiri I        2592     0.789
 6 Makalu              2405     0.764
 7 Lhotse              2379     0.638
 8 Baruntse            2190     0.708
 9 Pumori              1780     0.706
10 Annapurna I         1669     0.821
11 Kangchenjunga       1385     0.682
12 Himlung Himal       1308     0.573
13 Annapurna IV         812     0.845
14 Putha Hiunchuli      738     0.599
15 Tilicho              670     0.781
16 Tukuche              462     0.753
17 Jannu                339     0.782
18 Langtang Lirung      338     0.84 
19 Makalu II            322     0.758
20 Nuptse               303     0.934

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;load-libraries&#34;&gt;Load Libraries&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)
library(reactable)
library(htmltools)

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;basic-table&#34;&gt;Basic Table&lt;/h2&gt;
&lt;p&gt;The amazing thing is, with just this one line, you have a barebones table with &lt;strong&gt;pagination&lt;/strong&gt; (with 20 rows, it shows 10 at a time; this can be adjusted) and  &lt;strong&gt;sorting&lt;/strong&gt; for both columns.&lt;/p&gt;
&lt;p&gt;You can check out the rest of the repo 
&lt;a href=&#34;https://github.com/PaulApivat/tidytuesday/blob/master/2020/himalaya/exploratory.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;reactable(df)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;adding-bar-charts-for-each-row&#34;&gt;Adding Bar Charts for Each Row&lt;/h2&gt;
&lt;p&gt;Of course, bare bones is not much to look at, so adding bar charts is essential for visually communicating quantities and percentages. However, you&amp;rsquo;ll need to use the &lt;code&gt;htmltools&lt;/code&gt; package to begin adding &lt;code&gt;div&lt;/code&gt; to your chart.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Bar Charts can be added with a function 

bar_chart &amp;lt;- function(label, width = &amp;quot;100%&amp;quot;, height = &amp;quot;14px&amp;quot;, fill = &amp;quot;#00bfc4&amp;quot;, background = NULL){
    bar &amp;lt;- div(style = list(background = fill, width = width, height = height))
    chart &amp;lt;- div(style = list(flexGrow = 1, marginLeft = &amp;quot;6px&amp;quot;, background = background), bar)
    div(style = list(display = &amp;quot;flex&amp;quot;, alignItems = &amp;quot;center&amp;quot;), label, chart)
}


# The bar_chart function is then inserted into the numeric columns

reactable(
    df,
    defaultSorted = &amp;quot;attempts&amp;quot;,
    columns = list(
        peak = colDef(
            name = &amp;quot;Peaks&amp;quot;
        ),
        attempts = colDef(
            name = &amp;quot;Attempts (#)&amp;quot;,
            defaultSortOrder = &amp;quot;desc&amp;quot;,
            #format = colFormat(separators = TRUE),
            
            # Render Bar charts using a custom cell render function
            cell = function(value){
                width &amp;lt;- paste0(value * 100 / max(df$attempts), &amp;quot;%&amp;quot;)
                # Add thousands separators
                value &amp;lt;- format(value, big.mark = &amp;quot;,&amp;quot;)
                # Fix each label using the width of the widest number (incl. thousands separators)
                value &amp;lt;- format(value, width = 9, justify = &#39;right&#39;)
                bar_chart(value, width = width, fill = &amp;quot;#3fc1c9&amp;quot;)
            },
            # And left-align the columns
            align = &amp;quot;left&amp;quot;,
            # Use the operating system&#39;s default monospace font, and
            # preserve the white space to prevent it from being collapsed by default
            style = list(fontFamily = &amp;quot;monospace&amp;quot;, whiteSpace = &amp;quot;pre&amp;quot;)
        ),
        fail_rate = colDef(
            name = &amp;quot;Fail (%)&amp;quot;,
            defaultSortOrder = &amp;quot;desc&amp;quot;,
            #format = colFormat(percent = TRUE, digits = 1)
            
            # Render Bar charts using a custom cell render function
            cell = function(value){
                # Format as percentage with 1 decimal place
                value &amp;lt;- paste0(format(value * 100, nsmall = 1), &amp;quot;%&amp;quot;)
                # Fix width here to align single and double-digit percentages
                value &amp;lt;- format(value, width = 5, justify = &amp;quot;right&amp;quot;)
                bar_chart(value, width = value, fill = &amp;quot;#fc5185&amp;quot;, background = &amp;quot;#e1e1e1&amp;quot;)
            },
            # And left-align the columns
            align = &amp;quot;left&amp;quot;,
            style = list(fontFamily = &amp;quot;monospace&amp;quot;, whiteSpace = &amp;quot;pre&amp;quot;)
        )
    )
)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Decimals to Integers</title>
      <link>/technical_notes/example_tech/rstats_viz_scale_x/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_scale_x/</guid>
      <description>&lt;h2 id=&#34;changing-the-x-axis-from-decimals-to-integers&#34;&gt;Changing the x-axis from decimals to integers&lt;/h2&gt;
&lt;p&gt;When creating plots in &lt;code&gt;ggplot2&lt;/code&gt; you&amp;rsquo;ll often want to customize the x-axis so that values appear on a certain interval. In the example below, I wanted to change the intervals from 0.25, 0.50, 0.75 to 1,2,3,4 and so on. In this specific instance, I wanted &lt;em&gt;each&lt;/em&gt; season of the show Friends to have its down tick on the x-axis (note: the show had ten seasons).&lt;/p&gt;
&lt;p&gt;This operation changes the x-axis ticks from having decimals to being integers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(ggplot)

ggplot(total_data, aes(x = season, y = episode, fill=imdb_rating)) +
    geom_tile() +
    scale_fill_gradient(low = &#39;#FFF580&#39;, high = &#39;#FF4238&#39;) +
    
    ## the seq() function defines the start and end numbers
    ## &#39;by =&#39; indicates the desired interval
    scale_x_continuous(breaks = seq(1,10, by = 1)) + 
    
    theme_classic()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>GGPlot Flavored Treemaps</title>
      <link>/technical_notes/example_tech/rstats_viz_treemapify/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_viz_treemapify/</guid>
      <description>&lt;h2 id=&#34;treemapify&#34;&gt;Treemapify&lt;/h2&gt;
&lt;p&gt;There are several options for visualizing treemaps in R. This note focuses on  
&lt;a href=&#34;https://cran.r-project.org/web/packages/treemapify/vignettes/introduction-to-treemapify.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Treemapify&lt;/a&gt;, a package maintained by 
&lt;a href=&#34;https://github.com/wilkox&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Wilkins&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I favor this approach over the &lt;code&gt;treemap&lt;/code&gt; package because it is compatible with &lt;code&gt;ggplot2&lt;/code&gt; and allows users to access its&#39; functionality.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s an example Treemap I created to visualize the dominant emotions displayed for the iconic 90&amp;rsquo;s sitcom, Friends. You can find out more about the 
&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-09-08/readme.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Friends dataset here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Other visualizations I created for the Friends project can also be found 
&lt;a href=&#34;https://github.com/PaulApivat/tidytuesday/tree/master/2020/friends&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below, we can see that &lt;code&gt;geom_treemap&lt;/code&gt;, &lt;code&gt;geom_treemap_subgroup_border&lt;/code&gt; and &lt;code&gt;geom_treemap_subgroup_text&lt;/code&gt; are layers that works seamlessly with other layers like &lt;code&gt;scale_fill_manual&lt;/code&gt;, &lt;code&gt;theme&lt;/code&gt;, and &lt;code&gt;labs&lt;/code&gt; that are staples of the ggplot2 package.&lt;/p&gt;
&lt;p&gt;Bottom line, it&amp;rsquo;s easier to customize treemaps from the &lt;code&gt;treemapify&lt;/code&gt; package than the &lt;code&gt;treemap&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(treemapify)

ggplot(friends_emo_tree, aes(area = n, label = speaker, subgroup = emotion)) +
    geom_treemap(aes(fill = emotion, alpha = n)) +
    geom_treemap_subgroup_border(color = &#39;white&#39;) +
    geom_treemap_subgroup_text(place = &#39;bottom&#39;, grow = T, alpha = 0.3, color = &#39;black&#39;,
                               min.size = 0) +
    geom_treemap_text(color = &#39;white&#39;, fontface = &#39;italic&#39;, place = &#39;centre&#39;, reflow = T) +
    scale_fill_manual(values = c(&#39;#FF4238&#39;, &#39;#FFDC00&#39;, &#39;#42A2D6&#39;, &#39;#9A0006&#39;, &#39;#FFF580&#39;, &#39;#00009E&#39;)) +
    theme(
        plot.background = element_rect(fill = &#39;#36454F&#39;),
        legend.position = &#39;none&#39;,
        title = element_text(colour = &#39;white&#39;, family = &#39;Friends&#39;)
    ) +
    labs(
        title = &#39;The One with the Dominant Emotions&#39;,
        caption = &#39;Viz: @paulapivat | Data: #TidyTuesday&#39;
    )
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Visualize Scatterplots with Marginal Distribution using ggExtra</title>
      <link>/technical_notes/example_tech/data_viz_tip2/</link>
      <pubDate>Wed, 02 Sep 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/data_viz_tip2/</guid>
      <description>&lt;h2 id=&#34;marginal-distribution-with-ggplot2-and-ggextra&#34;&gt;Marginal Distribution with ggplot2 and ggExtra&lt;/h2&gt;
&lt;p&gt;The data in this example is from the UN 
&lt;a href=&#34;https://unstats.un.org/sdgs/indicators/database/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Statistics Division&lt;/a&gt; Sustainable Development Goal, Indicator 4.4.1.&lt;/p&gt;
&lt;p&gt;Also check out the 
&lt;a href=&#34;https://www.r-graph-gallery.com/277-marginal-histogram-for-ggplot2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r-graph-gallery.com&lt;/a&gt; for inspiration.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the breakdown:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load Packages and Libraries&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The key here is the &lt;code&gt;ggExtra&lt;/code&gt; package.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&#39;ggExtra&#39;)
library(ggExtra)
library(tidyverse)

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create a basic scatter plot&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The key here is using &lt;code&gt;pivot_wider&lt;/code&gt; to give all &lt;code&gt;Type of skill&lt;/code&gt; their own columns. We&amp;rsquo;ll then pick out specific columns (i.e., COPA, EMAIL, PCPR) to summarize, then plot on the x- and y- axes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Basic Scatter Plot (color cluster by Gender)
p &amp;lt;- data %&amp;gt;%
    select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
    group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
    pivot_wider(names_from = `Type of skill`, values_from = Value) %&amp;gt;%
    mutate(
        COPA = as.numeric(COPA),
        EMAIL = as.numeric(EMAIL),
        PCPR = as.numeric(PCPR)
    ) %&amp;gt;%
    # Group by GeoAreaName, across TimePeriod, Sex
    group_by(GeoAreaName, Sex) %&amp;gt;%
    summarize(
        avg_COPA = mean(COPA, na.rm = TRUE),
        avg_EMAIL = mean(EMAIL, na.rm = TRUE),
        avg_PCPR = mean(PCPR, na.rm = TRUE)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    ggplot(aes(x = avg_PCPR, y = avg_EMAIL, color = Sex)) + 
    geom_point()
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Use &lt;code&gt;ggMarginal()&lt;/code&gt; to create the marginal distribution along the side of the scatter plots. This is a function from the &lt;code&gt;ggExtra&lt;/code&gt; package.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# Scatter Plot with Marginal Distribution
ggMarginal(p, type = &#39;histogram&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This particular chart is especially useful to highlight different distributions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calculating 25th, 50th and 75th Percentile of Column Values</title>
      <link>/technical_notes/example_tech/rstats_tip4/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip4/</guid>
      <description>&lt;h2 id=&#34;calculating-percentiles&#34;&gt;Calculating Percentiles&lt;/h2&gt;
&lt;p&gt;When we have a list of values in a column, how can we determine which values are under/over the 25th percentile, 50th percentile or 75th percentile?&lt;/p&gt;
&lt;p&gt;Here the example are countries&#39; &lt;em&gt;average percentages&lt;/em&gt; of the population with, broadly speaking, ICT Skills as determine by the Sustainable Development Goals, 
&lt;a href=&#34;https://unstats.un.org/wiki/display/SDGeHandbook/Indicator&amp;#43;4.4.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Indicator 4.4.1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are three methods. First, manually calculating values for the 25th, 50th and 75th percentile with the &lt;code&gt;quantile()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Country mean_values at 25th, 50th and 75th percentile 

data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(Value = as.numeric(Value)) %&amp;gt;%
    group_by(GeoAreaName) %&amp;gt;%
    summarize(
        mean_value = mean(Value)
    ) %&amp;gt;%
    mutate(
        min_mean = min(mean_value),
        iqr_25_percentile = quantile(mean_value, probs = c(0.25)),
        iqr_50_percentile = quantile(mean_value, probs = c(0.50)),
        iqr_75_percentile = quantile(mean_value, probs = c(0.75)),
        max_mean = max(mean_value)
    ) %&amp;gt;%
    arrange(desc(mean_value)) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second approach is to use the &lt;code&gt;ntile()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Creating bins using ntile()

data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(Value = as.numeric(Value)) %&amp;gt;%
    group_by(GeoAreaName) %&amp;gt;%
    summarize(
        mean_value = mean(Value)
    ) %&amp;gt;%
    mutate(
        mean_value_binned = ntile(mean_value, 4)
    ) %&amp;gt;%
    arrange(desc(mean_value))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The third approach uses the &lt;code&gt;purrr&lt;/code&gt; package and the &lt;code&gt;partial&lt;/code&gt; function that can be used with &lt;code&gt;dplyr&#39;s&lt;/code&gt; &lt;code&gt;summarize_at()&lt;/code&gt; function. Check out the 
&lt;a href=&#34;https://tbradley1013.github.io/2018/10/01/calculating-quantiles-for-groups-with-dplyr-summarize-and-purrr-partial/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;source&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
## Using purrr
library(purrr)
    
p &amp;lt;- c(0.25, 0.50, 0.75)

p_names &amp;lt;- map_chr(p, ~paste0(.x*100, &amp;quot;%&amp;quot;))

p_funs &amp;lt;- map(p, ~partial(quantile, probs = .x, na.rm = TRUE)) %&amp;gt;%
    set_names(nm = p_names)

p_funs

data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(Value = as.numeric(Value)) %&amp;gt;%
    group_by(GeoAreaName) %&amp;gt;%
    summarize(
        mean_value = mean(Value)
    ) %&amp;gt;%
    summarize_at(vars(mean_value), funs(!!!p_funs))

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Does order of operation matter among dplyr functions?</title>
      <link>/technical_notes/example_tech/rstats_tip5/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip5/</guid>
      <description>&lt;h2 id=&#34;data-wrangling-does-order-matter&#34;&gt;Data Wrangling: Does Order matter?&lt;/h2&gt;
&lt;p&gt;In short, yes, it matters. But when and where?&lt;/p&gt;
&lt;p&gt;Below are examples to highlight when function order matters and when it doesn&amp;rsquo;t. The source for the raw data used in this illustration are from the United Nations&#39; Statistics Division for 
&lt;a href=&#34;https://unstats.un.org/sdgs/indicators/database/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sustainable Development Goals&lt;/a&gt; (SDG) Indicators (Goal 4, Target 4.4).&lt;/p&gt;
&lt;p&gt;See also UN Statistics Wiki on 
&lt;a href=&#34;https://unstats.un.org/wiki/display/SDGeHandbook/Indicator&amp;#43;4.4.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Indicator 4.4.1&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Example chain of functions to determine proportion of Thailand&#39;s population to have certain ICT skills in 2018

data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(
        Value = as.double(Value)
    ) %&amp;gt;%
    filter(GeoAreaName == &#39;Thailand&#39;) %&amp;gt;% 
    filter(TimePeriod == 2018) %&amp;gt;% 
    group_by(type_of_skill) %&amp;gt;%
    summarize(
        mean_value = mean(Value),
        median_value = median(Value)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    arrange(desc(mean_value))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, the &lt;code&gt;filter&lt;/code&gt; functions are moved up to be before &lt;code&gt;rename&lt;/code&gt; and &lt;code&gt;mutate&lt;/code&gt;. The ordering here does &lt;strong&gt;not&lt;/strong&gt; matter.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %&amp;gt;%
    
    # putting filter before rename, mutate is fine
    filter(GeoAreaName == &#39;Thailand&#39;) %&amp;gt;% 
    filter(TimePeriod == 2018) %&amp;gt;% 
    
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(
        Value = as.double(Value)
    ) %&amp;gt;%
    group_by(type_of_skill) %&amp;gt;%
    summarize(
        mean_value = mean(Value),
        median_value = median(Value)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    arrange(desc(mean_value))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Furthermore, we could even experiment with the &lt;code&gt;filter&lt;/code&gt; function being before or after &lt;code&gt;select&lt;/code&gt;. Here, ordering also does &lt;strong&gt;not&lt;/strong&gt; matter.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data %&amp;gt;%
    filter(GeoAreaName == &#39;Thailand&#39;) %&amp;gt;% 
    filter(TimePeriod == 2018) %&amp;gt;% 
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(
        Value = as.double(Value)
    ) %&amp;gt;%
    group_by(type_of_skill) %&amp;gt;%
    summarize(
        mean_value = mean(Value),
        median_value = median(Value)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    arrange(desc(mean_value))

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is there order &lt;strong&gt;does&lt;/strong&gt; matter. When we try to move the two &lt;code&gt;filter&lt;/code&gt; functions below &lt;code&gt;group_by&lt;/code&gt;, &lt;code&gt;summarize&lt;/code&gt; and &lt;code&gt;ungroup&lt;/code&gt;, the filtering does &lt;em&gt;not&lt;/em&gt; work. By the time we get to &lt;code&gt;filter(GeoAreaName == &#39;Thailand&#39;)&lt;/code&gt; in this example, GeoAreaName has been removed because we did &lt;em&gt;not&lt;/em&gt; &lt;code&gt;group_by&lt;/code&gt; &lt;code&gt;GeoAreaName&lt;/code&gt;, so we get an error.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Running this code, we&#39;ll get the ERROR: Problem with `filter()` input `..1`. x object &#39;GeoAreaName&#39; not found ℹ Input `..1` is 
# `GeoAreaName == &amp;quot;Thailand&amp;quot;`.

data %&amp;gt;%
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %&amp;gt;%
    relocate(Sex, Value, GeoAreaName) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(
        Value = as.double(Value)
    ) %&amp;gt;%
    # filter was previously here
    group_by(type_of_skill) %&amp;gt;%
    summarize(
        mean_value = mean(Value),
        median_value = median(Value)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    # moving filter down below group_by &amp;amp; summarize() does not work
    filter(GeoAreaName == &#39;Thailand&#39;) %&amp;gt;% 
    filter(TimePeriod == 2018) %&amp;gt;% 
    arrange(desc(mean_value))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, if we want to use &lt;code&gt;filter&lt;/code&gt; on the &lt;em&gt;results&lt;/em&gt; of the &lt;code&gt;mutate&lt;/code&gt; function, we see that order &lt;strong&gt;does&lt;/strong&gt; matter. By the time we get to the final &lt;code&gt;filter(Value &amp;lt; 10)&lt;/code&gt;, the &lt;code&gt;Value&lt;/code&gt; variable is no longer available to us because we did not &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;summarize&lt;/code&gt; by Value (instead we created &lt;code&gt;mean_value&lt;/code&gt; and &lt;code&gt;median_value&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
data %&amp;gt;%
    filter(GeoAreaName == &#39;Thailand&#39;) %&amp;gt;% 
    filter(TimePeriod == 2018) %&amp;gt;% 
    select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %&amp;gt;%
    rename(type_of_skill = `Type of skill`) %&amp;gt;%
    mutate(
        Value = as.double(Value)
    ) %&amp;gt;%
    # filtering for Values less than 10 does work here
    filter(Value &amp;lt; 10) %&amp;gt;%
    group_by(type_of_skill) %&amp;gt;%
    summarize(
        mean_value = mean(Value),
        median_value = median(Value)
    ) %&amp;gt;%
    ungroup() %&amp;gt;%
    arrange(desc(mean_value)) %&amp;gt;%
    # filter for Values less than 10 does not work down here
    filter(Value &amp;lt; 10)

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Creating a dendrogram with R and ggraph</title>
      <link>/technical_notes/example_tech/data_viz_tip1/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/data_viz_tip1/</guid>
      <description>&lt;h2 id=&#34;nested-and-hierarchical-data&#34;&gt;Nested and Hierarchical Data&lt;/h2&gt;
&lt;p&gt;When you have data with multiple subgroups, one option is to treat them as nested and/or hierarchical data.&lt;/p&gt;
&lt;p&gt;In this technical note, I&amp;rsquo;ll outline how to create a dendrogram.&lt;/p&gt;
&lt;p&gt;The data used is from the 
&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-08-18/readme.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extinct Plants&lt;/a&gt; data set from 
&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TidyTuesday&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the breakdown:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load Packages and Libraries&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;ggraph&amp;quot;)
install.packages(&amp;quot;igraph&amp;quot;)
library(ggraph)
library(igraph)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Create a data frame with three levels&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Taking the &lt;code&gt;plants&lt;/code&gt; data frame, I do some wrangling to get the desired columns.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plants_data &amp;lt;- plants %&amp;gt;%
    select(group, binomial_name) %&amp;gt;%
    group_by(group) %&amp;gt;%
    arrange(group) %&amp;gt;% 
    mutate(
        level1 = &#39;center&#39;,
        level2 = group,
        level3 = binomial_name
    ) %&amp;gt;%
    # important to ungroup here
    ungroup() %&amp;gt;%
    select(level1:level3) 

&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Create an edge list&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# transform it to an edge list
plants_edges_level1_2 &amp;lt;- plants_data %&amp;gt;% 
    select(level1, level2) %&amp;gt;% 
    unique %&amp;gt;% 
    rename(from=level1, to=level2)

plants_edges_level2_3 &amp;lt;- plants_data %&amp;gt;% 
    select(level2, level3) %&amp;gt;% 
    unique %&amp;gt;% 
    rename(from=level2, to=level3)

plants_edge_list=rbind(plants_edges_level1_2, plants_edges_level2_3)
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Plot a basic chart&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Because I have many observations, I&amp;rsquo;m optiing to use a &amp;ldquo;circular&amp;rdquo; dendrogram.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# plot plant dendogram
plantgraph &amp;lt;- graph_from_data_frame(plants_edge_list)

ggraph(plantgraph, layout = &amp;quot;dendrogram&amp;quot;, circular = TRUE) +
    geom_edge_diagonal() +
    geom_node_point() +
    theme_void()
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;Add text to the end of the edges&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;# add text &amp;amp; color(leaf)
ggraph(plantgraph, layout = &amp;quot;dendrogram&amp;quot;, circular = TRUE) +
    geom_edge_diagonal() +
    geom_node_text(aes(label = name, filter=leaf), hjust = 1, size = 1) +
    geom_node_point()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;NOTE: The breakdown of plant groupings are listed below. We can see the Flowering Plants &lt;em&gt;disproportionately&lt;/em&gt; out number other groups like Ferns &amp;amp; Allies, Cycad, Mosses, Algae and Conifer.&lt;/p&gt;
&lt;p&gt;When visualizing, we&amp;rsquo;re better off separating Flowering Plants from the other groups.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plants %&amp;gt;%
    group_by(group) %&amp;gt;%
    tally(sort = TRUE)

# A tibble: 6 x 2
  group                n
  &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;
1 Flowering Plant    471
2 Ferns and Allies    13
3 Cycad                8
4 Mosses               4
5 Algae                3
6 Conifer              1

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s a sample picture of the plants&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./png/data_viz_tip1_pic1.png&#34; alt=&#34;dendrogram&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./data_viz_tip1_pic1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;















&lt;figure id=&#34;figure-dendrogram&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;./data_viz_tip1_pic1.png&#34; data-caption=&#34;Dendrogram.&#34;&gt;


  &lt;img src=&#34;./data_viz_tip1_pic1.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Dendrogram.
  &lt;/figcaption&gt;


&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Using the pivot_wider() function</title>
      <link>/technical_notes/example_tech/rstats_tip3/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip3/</guid>
      <description>&lt;p&gt;With 
&lt;a href=&#34;https://www.tidyverse.org/blog/2019/09/tidyr-1-0-0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tidyr 1.0.0&lt;/a&gt;, there are several enhancements, one of which are &lt;code&gt;pivot_wider()&lt;/code&gt; and &lt;code&gt;pivot_longer()&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;using-pivot_wider&#34;&gt;Using pivot_wider()&lt;/h2&gt;
&lt;p&gt;In another 
&lt;a href=&#34;https://paulapivat.com/technical_notes/example_tech/rstats_tip2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt;, the &lt;code&gt;spread()&lt;/code&gt; function was introduced as a way to observe the &amp;ldquo;tidy&amp;rdquo; principle of data formatting for analysis.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;pivot_wider()&lt;/code&gt; function is an updated of &lt;code&gt;spread()&lt;/code&gt; and is much more intuitive. Here&amp;rsquo;s how it works:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# PIVOT_WIDER - even better than Spread

data %&amp;gt;%
    filter(GeoAreaName==&amp;quot;Morocco&amp;quot; | GeoAreaName==&amp;quot;Qatar&amp;quot;) %&amp;gt;% 
    select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
    group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
    pivot_wider(names_from = `Type of skill`, values_from = Value) 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this data set, &lt;code&gt;Type of skill&lt;/code&gt; represents, broadly speaking, ICT Skills broken down into eight categories in this column. By using &lt;code&gt;pivot_wider()&lt;/code&gt; each sub-category of ICT Skills gets it&amp;rsquo;s &lt;strong&gt;own&lt;/strong&gt; column, thus making the overall data frame &lt;em&gt;wider&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;using-pivot_longer&#34;&gt;Using pivot_longer()&lt;/h2&gt;
&lt;p&gt;Conversely, there&amp;rsquo;s also &lt;code&gt;pivot_longer&lt;/code&gt; for the opposite effect. This next code chunk is part of my attempt for 
&lt;a href=&#34;https://github.com/rfordatascience/tidytuesday&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TidyTuesday&lt;/a&gt; (&amp;lsquo;Extinct Plants&amp;rsquo; for the week of 2020-08-18)&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cols&lt;/code&gt; parameter determines the range of columns to be changed from wide to long. The &lt;code&gt;names_to&lt;/code&gt; parameter sets the new column name and &lt;code&gt;values_to&lt;/code&gt; indicates the value of the new columns.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# PIVOT_LONGER - better than Gather

plants %&amp;gt;%
    select(binomial_name, threat_AA:action_NA) %&amp;gt;%
    pivot_longer(cols = threat_AA:action_NA, names_to = &amp;quot;action&amp;quot;, values_to = &amp;quot;count&amp;quot;) %&amp;gt;%
    ggplot(aes(x = binomial_name, y = action, fill = count)) +
    geom_tile() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Use the spread() function</title>
      <link>/technical_notes/example_tech/rstats_tip2/</link>
      <pubDate>Tue, 25 Aug 2020 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip2/</guid>
      <description>&lt;p&gt;One principle of &lt;code&gt;tidy&lt;/code&gt; data is to change from wide to long; and conversely, long to wide.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s a concrete example:&lt;/p&gt;
&lt;h2 id=&#34;using-spread&#34;&gt;Using spread()&lt;/h2&gt;
&lt;p&gt;The first part of the below pre-processing steps include subsetting the original data frame (data) by selecting two countries for comparison (Morocco and Qatar) on specific variables such as: &lt;code&gt;GeoAreaName&lt;/code&gt;, &lt;code&gt;TimePeriod&lt;/code&gt;, &lt;code&gt;Sex&lt;/code&gt;, &lt;code&gt;Type of skill&lt;/code&gt; and &lt;code&gt;Value&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then employing &lt;code&gt;group_by&lt;/code&gt; to ensure all rows are unique. The next line is key as it addresses an error that each row must be marked by a unique id key.&lt;/p&gt;
&lt;p&gt;Finally, the &lt;code&gt;spread()&lt;/code&gt; function allows us to see each countries&#39; relative performance on various 
&lt;a href=&#34;http://tcg.uis.unesco.org/4-4-1-proportion-of-youth-and-adults-with-information-and-communications-technology-ict-skills-by-type-of-skill/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICT skills&lt;/a&gt;. Please consult meta-data for more details.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data %&amp;gt;%
    filter(GeoAreaName==&amp;quot;Morocco&amp;quot; | GeoAreaName==&amp;quot;Qatar&amp;quot;) %&amp;gt;% 
    select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
    group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %&amp;gt;%
	
    # Error: Each row of output must be identified by a unique combination of keys.
    # rowid_to_column() address this error
	
    tibble::rowid_to_column() %&amp;gt;%
    spread(key = `Type of skill`, value = Value)

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Make your work reproducible</title>
      <link>/technical_notes/example_tech/rstats_tip1/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/rstats_tip1/</guid>
      <description>&lt;p&gt;Understanding reproducibility and the &lt;code&gt;set.seed()&lt;/code&gt; function in &lt;code&gt;R&lt;/code&gt; is best achieved through generating various random numbers. Here are some more tips for making your work reproducible:&lt;/p&gt;
&lt;h2 id=&#34;using-setseed&#34;&gt;Using set.seed()&lt;/h2&gt;
&lt;p&gt;Example of reproducibility in fitting ML models using set.seed()&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#First Line
set.seed(1234)   

#Second Line
model_05_rand_forest_ranger &amp;lt;- rand_forest(
    mode = &amp;quot;regression&amp;quot;, mtry = 4, trees = 1000, min_n = 10
    ) %&amp;gt;%
    set_engine(&amp;quot;ranger&amp;quot;, splitrule = &amp;quot;extratrees&amp;quot;, importance = &amp;quot;impurity&amp;quot;) %&amp;gt;%
    fit(price ~ ., data = train_tbl %&amp;gt;% select(-id, -model, -model_tier))

#Third Line
model_05_rand_forest_ranger %&amp;gt;% calc_metrics(test_tbl)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;random-numbers&#34;&gt;Random Numbers&lt;/h2&gt;
&lt;p&gt;Here are several ways to get random numbers. These examples are informed by the &lt;code&gt;R Cookbook&lt;/code&gt;, see 
&lt;a href=&#34;http://www.cookbook-r.com/Numbers/Generating_random_numbers/#:~:text=For%20uniformly%20distributed%20%28flat%29%20random,is%20from%200%20to%201.&amp;amp;text=To%20generate%20numbers%20from%20a,the%20standard%20deviation%20is%201.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# get one random number using runif() from base-R, stats package
# default 0 to 1
runif(1)

# get two random numbers
runif(2)

# get a vector of three random numbers
# increase range beyond the default, -10 to 110
runif(3, min = -10, max = 110)

# ensure three random numbers do *not* have decimals
# use floor() function to round down
floor(runif(3, min = -10, max = 110))

# sample() function does the same thing - using just one function
# replace parameter: should sampling be with or without replacement?
sample(-10:110, 3, replace = TRUE)

# Reproducibility
# use set.seed() before any of the aforementioned random number generators

set.seed(123)
sample(-10:110, 3, replace = FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;random-numbers-from-a-normal-distribution&#34;&gt;Random Numbers from a Normal Distribution&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;# Get five random numbers from a normal distribution
# Here the default is mean = 0, standard deviation = 1.
rnorm(5)

# Change mean and standard deviation away from default
rnorm(5, mean = 66, sd = 12)

# Ensure reproducibility with set.seed()
set.seed(123)
rnorm(5, mean = 66, sd = 12)

# Ensure normal distribution by setting sufficiently large number with rnorm()
# Ensure reproducibility
# Plot a histogram

set.seed(123)
x &amp;lt;- rnorm(500, mean = 66, sd = 12)
hist(x)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Technical Notes Page 2</title>
      <link>/technical_notes/example_tech/technical_notes2/</link>
      <pubDate>Sun, 05 May 2019 00:00:00 +0100</pubDate>
      <guid>/technical_notes/example_tech/technical_notes2/</guid>
      <description>&lt;p&gt;Here are some more tips for getting started with Academic:&lt;/p&gt;
&lt;h2 id=&#34;technical-tip-3&#34;&gt;Technical Tip 3&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
&lt;h2 id=&#34;technical-tip-4&#34;&gt;Technical Tip 4&lt;/h2&gt;
&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
