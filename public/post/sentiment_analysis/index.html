<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Paul Apivat Hanvongse">

  
  
  
    
  
  <meta name="description" content="Using Python and R to read, pre-process, wrangle and visualize data.">

  
  <link rel="alternate" hreflang="en-us" href="/post/sentiment_analysis/">

  


  
  
  
  <meta name="theme-color" content="#E32626">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Domine:wght@400;700&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/post/sentiment_analysis/">

  
  
  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@paulapivat">
  <meta property="twitter:creator" content="@paulapivat">
  
  <meta property="og:site_name" content="Paul Apivat">
  <meta property="og:url" content="/post/sentiment_analysis/">
  <meta property="og:title" content="How Positive are Your Facebook Posts? | Paul Apivat">
  <meta property="og:description" content="Using Python and R to read, pre-process, wrangle and visualize data."><meta property="og:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2021-01-26T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2021-01-26T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/sentiment_analysis/"
  },
  "headline": "How Positive are Your Facebook Posts?",
  
  "datePublished": "2021-01-26T00:00:00Z",
  "dateModified": "2021-01-26T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Paul Apivat Hanvongse"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Paul Apivat",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "Using Python and R to read, pre-process, wrangle and visualize data."
}
</script>

  

  


  


  





  <title>How Positive are Your Facebook Posts? | Paul Apivat</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Paul Apivat</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Paul Apivat</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/#"><span>Start Here</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#accomplishments"><span>News</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#gallery"><span>Viz</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/courses/"><span>Courses</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/technical_notes/"><span>Technical Notes</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>How Positive are Your Facebook Posts?</h1>

  
  <p class="page-subtitle">Rule-based Sentiment Analysis Using Python and R</p>
  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/author/paul-apivat-hanvongse/">Paul Apivat Hanvongse</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Jan 26, 2021
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <h3 id="table-of-contents">Table of contents</h3>
<ul>
<li>
<a href="#overview">Overview</a></li>
<li>
<a href="#getting_data">Getting Data</a></li>
<li>
<a href="#tokenization">Tokenization</a></li>
<li>
<a href="#normalizing_sentences">Normalizing Sentences</a></li>
<li>
<a href="#frequency">Frequency</a></li>
<li>
<a href="#sentiment_analysis">Sentiment Analysis</a></li>
<li>
<a href="#data_transformation">Data Transformation</a></li>
<li>
<a href="#visualization">Visualization</a></li>
<li>
<a href="#references">References</a></li>
</ul>
<h2 id="overview">Overview</h2>
<h4 id="why-sentiment-analysis">Why Sentiment Analysis?</h4>
<p>NLP is subfield of linguistic, computer science and artificial intelligence (
<a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank" rel="noopener">wiki</a>), and you could spend years studying it.</p>
<p>Alternatively, I wanted a quick mini-dive into this domain, to a get a basic intuition for how NLP works.</p>
<p>The ideal dataset to work is our own social media post as we may feel connected to the data and motivated to see hidden insights.</p>
<h4 id="how-well-does-facebook-know-us">How well does Facebook know us?</h4>
<p>How much is too much?</p>
<p>To find out, I download 14 years of posts to apply basic <strong>text analysis</strong> and <strong>pre-processing</strong>. I  used <code>Python</code> to read in <code>json</code> data downloaded from Facebook.</p>
<p>We&rsquo;ll perform pre-processing tasks like tokenization, normalization, stemming and lemmatization aided by Python&rsquo;s <strong>Natural Language Toolkit</strong>, <code>NLTK</code>. We can get a frequency of words and sentences from all posts. Finally, we&rsquo;ll use the <code>VADER</code> module (Hutto &amp; Gilbert, 2014) for rule-based (or lexicon) model of <strong>sentiment analysis</strong>.</p>
<p>Then, we&rsquo;ll transition our work flow to <code>R</code> for <strong>data manipulation</strong> and <strong>visualization</strong>.</p>
<h2 id="getting_data">Getting_Data</h2>
<p>First, you&rsquo;ll need to download your own Facebook data by following: Setting &amp; Privacy &gt; Setting &gt; Your Facebook Information &gt; Download Your Information &gt; (select) Posts.</p>
<p>In the example below, I named my file <code>your_posts_1.json</code>, but you can change this.
To read in json, we&rsquo;ll use Python&rsquo;s <code>json</code> module. I also like getting a feel for the data with <code>type</code> and <code>len</code>.</p>
<pre><code class="language-python">import json

# load json into python, assign to 'data'
with open('your_posts_1.json') as file:
    data = json.load(file)

type(data)     # a list
type(data[0])  # first object in the list: a dictionary
len(data)      # my list contains 2166 dictionaries
</code></pre>
<p>Here are <em>all</em> the libraries we use in this post:</p>
<pre><code class="language-python">import pandas as pd
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.stem import LancasterStemmer, WordNetLemmatizer      # OPTIONAL (more relevant for individual words)
from nltk.corpus import stopwords
from nltk.probability import FreqDist
import re
import unicodedata
import nltk
import json
import inflect
import matplotlib.pyplot as plt
</code></pre>
<p>
<a href="https://www.nltk.org/" target="_blank" rel="noopener">Natural Language Tookkit</a> This is a popular Python platform for work with human language data. Ideally for us, it has over 50 lexical resources; we&rsquo;ll be using the 
<a href="https://github.com/cjhutto/vaderSentiment" target="_blank" rel="noopener">Vader Sentiment Lexicon</a>, that is <em>specifically</em> attuned to sentiments expressed in social media. Ideal for our use case. NLTK will also help with frequency count, stopwards, stemming and lemmatization.</p>
<p>
<a href="https://docs.python.org/3/library/re.html" target="_blank" rel="noopener">Regex</a> We&rsquo;ll use regular expressions to remove punctuation.</p>
<p>
<a href="https://docs.python.org/3/library/unicodedata.html" target="_blank" rel="noopener">Unicode Database</a> We&rsquo;ll access Unicode Database to remove non-ASCII characters.</p>
<p>
<a href="https://docs.python.org/3/library/json.html" target="_blank" rel="noopener">JSON</a> We&rsquo;ll use the <strong>json</strong> module to read in json from Facebook.</p>
<p>
<a href="https://pypi.org/project/inflect/" target="_blank" rel="noopener">Inflect</a> This allows us to convert numbers to words.</p>
<p>
<a href="https://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a> This is a powerful data manipulation and data analysis tool that we&rsquo;ll need when we want to save our text data into a data frame and write to csv.</p>
<p>After we have our data (in <code>json</code> format), we&rsquo;ll 
<a href="https://twitter.com/paulapivat/status/1352893979897909251?s=20" target="_blank" rel="noopener">dig through</a> to get the actual <strong>text data</strong> (our posts).</p>
<p>We&rsquo;ll store this text in a list.</p>
<p>The code for doing this is. <strong>Note</strong>: the <code>data</code> key occassionally returns an empty array and we want to skip over those by checking <code>len(v) &gt; 0</code>.</p>
<pre><code class="language-python"># create empty list
empty_lst = []

# multiple nested loops to store all post in empty list
for dct in data:
    for k, v in dct.items():
        if k == 'data':
            if len(v) &gt; 0:
                for k_i, v_i in vee[0].items():  
                    if k_i == 'post':
                        empty_lst.append(v_i)

print(&quot;This is the empty list: &quot;, empty_lst)
print(&quot;\nLength of list: &quot;, len(empty_lst))
</code></pre>
<p>We now have a list of strings.</p>
<h2 id="tokenization">Tokenization</h2>
<p>We&rsquo;ll loop through a list of strings (empty_lst) to tokenize each <em>sentence</em> with <code>nltk.sent_tokenize()</code>. The text comes as one big blob and we want to either split into individual words or sentences. I think it&rsquo;ll make more sense to try to find the sentiment of each sentence, so we&rsquo;ll tokenize by sentence.</p>
<p>This yields a list of list, we&rsquo;ll need to flatten it:</p>
<pre><code class="language-python"># - list of list, len: 1762 (each list contain sentences)
nested_sent_token = [nltk.sent_tokenize(lst) for lst in empty_lst]

# flatten list, len: 3241
flat_sent_token = [item for sublist in nested_sent_token for item in sublist]
print(&quot;Flatten sentence token: &quot;, len(flat_sent_token))
</code></pre>
<h2 id="normalizing_sentences">Normalizing_Sentences</h2>
<p>For context on the functions used in this section, check out this article by Matthew Mayo on 
<a href="https://www.kdnuggets.com/2018/03/text-data-preprocessing-walkthrough-python.html" target="_blank" rel="noopener">Text Data Preprocessing</a>.</p>
<p>First, we <code>remove_non_ascii(words)</code> characters including: <code>#</code>, <code>-</code>, <code>'</code> and <code>?</code>, among many others. Then we&rsquo;ll <code>to_lowercase(words)</code>, <code>remove_punctuation(words)</code>, <code>replace_numbers(words)</code>, and <code>remove_stopwords(words)</code>.</p>
<p>Examples stopwords are: your, yours, yourself, yourselves, he, him, his, himself etc.</p>
<p>All this allows us to clean up the text and have each sentence be on equal playing field.</p>
<p><strong>NOTE</strong>: I think the process of normalization makes more sense at the individual word level, so we won&rsquo;t actually need stemming and lemmatization for sentences.</p>
<pre><code class="language-python"># Remove Non-ASCII
def remove_non_ascii(words):
    &quot;&quot;&quot;Remove non-ASCII character from List of tokenized words&quot;&quot;&quot;
    new_words = []
    for word in words:
        new_word = unicodedata.normalize('NFKD', word).encode(
            'ascii', 'ignore').decode('utf-8', 'ignore')
        new_words.append(new_word)
    return new_words


# To LowerCase
def to_lowercase(words):
    &quot;&quot;&quot;Convert all characters to lowercase from List of tokenized words&quot;&quot;&quot;
    new_words = []
    for word in words:
        new_word = word.lower()
        new_words.append(new_word)
    return new_words


# Remove Punctuation , then Re-Plot Frequency Graph
def remove_punctuation(words):
    &quot;&quot;&quot;Remove punctuation from list of tokenized words&quot;&quot;&quot;
    new_words = []
    for word in words:
        new_word = re.sub(r'[^\w\s]', '', word)
        if new_word != '':
            new_words.append(new_word)
    return new_words


# Replace Numbers with Textual Representations
def replace_numbers(words):
    &quot;&quot;&quot;Replace all interger occurrences in list of tokenized words with textual representation&quot;&quot;&quot;
    p = inflect.engine()
    new_words = []
    for word in words:
        if word.isdigit():
            new_word = p.number_to_words(word)
            new_words.append(new_word)
        else:
            new_words.append(word)
    return new_words

# Remove Stopwords
def remove_stopwords(words):
    &quot;&quot;&quot;Remove stop words from list of tokenized words&quot;&quot;&quot;
    new_words = []
    for word in words:
        if word not in stopwords.words('english'):
            new_words.append(word)
    return new_words
    
# Combine all functions into Normalize() function
def normalize(words):
    words = remove_non_ascii(words)
    words = to_lowercase(words)
    words = remove_punctuation(words)
    words = replace_numbers(words)
    words = remove_stopwords(words)
    return words
</code></pre>
<p>However, for this post we&rsquo;re normalizing <em>sentences</em>, rather than <em>words</em>.</p>
<pre><code class="language-python">sents = normalize(flat_sent_token)
print(&quot;Length of sentences list: &quot;, len(sents))   # 3194
</code></pre>
<h2 id="frequency">Frequency</h2>
<p>You can use the <code>FreqDist()</code> function to get the most common sentences. After, you could plot a line chart for a visual comparison of the most frequent sentences.</p>
<p>Although simple, counting frequencies can yield some 
<a href="https://twitter.com/paulapivat/status/1353704114467729408?s=20" target="_blank" rel="noopener">insights</a>.</p>
<pre><code class="language-python">from nltk.probability import FreqDist

# Find frequency of sentence
fdist_sent = FreqDist(sents)
fdist_sent.most_common(10)   

# Plot
fdist_sent.plot(10)
</code></pre>
<h2 id="sentiment_analysis">Sentiment_Analysis</h2>
<p>We&rsquo;ll use the <code>Vader</code> module from <code>NLTK</code>. Vader stands for:</p>
<blockquote>
<p>Valence, Aware, Dictionary and sEntiment Reasoner.</p>
</blockquote>
<p>We are taking a <strong>Rule-based/Lexicon</strong> approach to sentiment analysis because we have a fairly large dataset, but lack labelled data to build a robust training set, thus Machine Learning would <strong>not</strong> be ideal for this task.</p>
<p>Two empty lists are created for a specific purpose.</p>
<p><code>sentiment</code> the result of the first for-loop, capturing each sentence and <code>sent_scores</code>, which initializes the <code>nltk.sentiment.vader.SentimentIntensityAnalyzer</code> and calculates the <strong>polarity_score</strong> of each sentence (i.e., negative, neutral, positive). Because the polarity_score is stored in a dictionary, I&rsquo;d like to split each key-value pair separately to eventually have a separate column for each: negative, neutral and positive scores.</p>
<p><code>sentiment2</code> captures the result of the nested for-loop (2nd layer), where it stores each polarity and value in a list of tuples.</p>
<p><img src="./sentiment_2.png" alt="sentiment_2"></p>
<p>After the nested for-loop has appended the data for each sentence (<code>sentiment</code>) and their respective individual polarity scores (<code>sentiment2</code>, negative, neutral, positive), we&rsquo;ll <strong>create data frames</strong> to store these with pandas. Then, we&rsquo;ll write the data frames to <strong>CSV</strong> to transition to R. Note that we set index to false when saving for CSV. The reason is that Python starts counting at 0, while <code>R</code> starts at 1, so these minor differences means we&rsquo;re better off re-creating the index as a separate column in <code>R</code>.</p>
<p><strong>NOTE</strong>: There is likely a more efficient way for what I&rsquo;m doing here. My hacky solution is to save two CSV files and move the work flow over to R for further data manipulation and visualization. This is primarily a personal preference for handling data frames and visualizations in R, but this <em>can</em> be done in pandas and matplotlib.</p>
<pre><code class="language-python"># nltk.download('vader_lexicon')

sid = SentimentIntensityAnalyzer()

sentiment = []
sentiment2 = []

for sent in sents:
    sent1 = sent
    sent_scores = sid.polarity_scores(sent1)
    for x, y in sent_scores.items():
        sentiment2.append((x, y))
    sentiment.append((sent1, sent_scores))
    # print(sentiment)

# sentiment
cols = ['sentence', 'numbers']
result = pd.DataFrame(sentiment, columns=cols)
print(&quot;First five rows of results: &quot;, result.head())

# sentiment2
cols2 = ['label', 'values']
result2 = pd.DataFrame(sentiment2, columns=cols2)
print(&quot;First five rows of results2: &quot;, result2.head())

# save to CSV
result.to_csv('sent_sentiment.csv', index=False)
result2.to_csv('sent_sentiment_2.csv', index=False)
</code></pre>
<h2 id="data_transformation">Data_Transformation</h2>
<p><strong>NOTE</strong>: From this point forward, we&rsquo;ll be using <code>R</code> and the <code>tidyverse</code> for data manipulation and visualization. <code>RStudio</code> is generally the IDE of choice here. We&rsquo;ll create an <code>R Script</code> to store all our data transformation and visualization process. We should be in the same directory in which the above CSV files were created with pandas.</p>
<p>We&rsquo;ll load the two CSV files we saved and the <code>tidyverse</code> library:</p>
<pre><code class="language-r">library(tidyverse)

# load data
df &lt;- read_csv(&quot;sent_sentiment.csv&quot;)       
df2 &lt;- read_csv('sent_sentiment_2.csv')    
</code></pre>
<p>We&rsquo;ll create another column that matches the index for the first data frame (sent_sentiment.csv). I save it as <code>df1</code>, but you could overwrite the original <code>df</code> if you wanted.</p>
<pre><code class="language-r"># create a unique identifier for each sentence
df1 &lt;- df %&gt;%
    mutate(row = row_number())
</code></pre>
<p>Then, for the second data frame (sent_sentiment_2.csv), we&rsquo;ll also create another column matching the index, but also use <code>pivot_wider</code> from the <code>tidyr</code> package. <strong>NOTE</strong>: You&rsquo;ll want to <code>group_by</code> label first, then use <code>mutate</code> to create a unique identifier.</p>
<p>We&rsquo;ll then use <code>pivot_wider</code> to ensure that all polarity values (negative, neutral, positive) have their own columns.</p>
<p>By creating a unique identifier using <code>mutate</code> and <code>row_number()</code>, we&rsquo;ll be able to join (<code>left_join</code>) by row.</p>
<p>After, I save the operation to <code>df3</code> which allows me to work off a fresh new data frame for visualization.</p>
<pre><code class="language-r"># long-to-wide for df2
# note: first, group by label; then, create a unique identifier for each label then use pivot_wider

df3 &lt;- df2 %&gt;%
    group_by(label) %&gt;%
    mutate(row = row_number()) %&gt;%
    pivot_wider(names_from = label, values_from = values) %&gt;%
    left_join(df1, by = 'row') %&gt;%
    select(row, sentence, neg:compound, numbers) 
</code></pre>
<h2 id="visualization">Visualization</h2>
<p>First, we&rsquo;ll visualize the positive and negative polarity scores separately, across all 3194 sentences (your numbers will vary).</p>
<p><img src="./positivity_line.png" alt="positivity_line"></p>
<p><img src="./negativity_line.png" alt="negativity_line"></p>
<p>When I sum positive and negative scores to get a ratio, it&rsquo;s about 568:97 or around 5.8x more positive than negative according to the VADER (Valance Aware Dictionary and Sentiment Reasoner).</p>
<p>The Vader module will take in every sentence that is inputted and assign a valence score from -1 (most negative) to 1 (most positive). We can either classify sentences as a combination of <code>pos</code> (positive), <code>neu</code> (neutral) and <code>neg</code>(negative) or as a <code>compound</code> score (i.e., normalized, weighted composite score). For more details, see 
<a href="https://pypi.org/project/vader-sentiment/" target="_blank" rel="noopener">vader-sentiment documentation</a>.</p>
<p>To see both positive and negative scores together (positive = blue, negative = red, neutral = black).</p>
<p><img src="./sentiment2.png" alt="sentiment2.png"></p>
<p>Finally, we can also use <code>histograms</code> to help us see the distribution of negative and positive sentiment among aggregated Facebook posts:</p>
<p><img src="./patch_histo.png" alt="patch_histo"></p>
<h4 id="summary">Summary</h4>
<p>I downloaded 14 years worth of Facebook posts to run a rule-based sentiment analysis and visualize the results, using a combination of Python and R.</p>
<p>I enjoyed using both Python and R for this project and I think we played to their strengths. I found parsing JSON fairly straight-forward with Python, but once we transition to data frames, I was itching to get back to R.</p>
<p>Because we lacked labelled data, using a lexicon-approach to sentiment analysis made sense. Now that we have a label for valence scores, it&rsquo;s may be possible to take a machine learning approach to predict the valence of future posts.</p>
<h2 id="references">References</h2>
<ol>
<li>Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.</li>
</ol>
<p>For more content on data science, machine learning, R, Python, SQL and more, 
<a href="https://twitter.com/paulapivat" target="_blank" rel="noopener">find me on Twitter</a>.</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/data-science/">Data Science</a>
  
  <a class="badge badge-light" href="/tag/facebook-data/">Facebook Data</a>
  
  <a class="badge badge-light" href="/tag/python/">Python</a>
  
  <a class="badge badge-light" href="/tag/r/">R</a>
  
  <a class="badge badge-light" href="/tag/sentiment-analysis/">Sentiment Analysis</a>
  
  <a class="badge badge-light" href="/tag/text-analysis/">Text Analysis</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/sentiment_analysis/&amp;text=How%20Positive%20are%20Your%20Facebook%20Posts?" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/sentiment_analysis/&amp;t=How%20Positive%20are%20Your%20Facebook%20Posts?" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=How%20Positive%20are%20Your%20Facebook%20Posts?&amp;body=/post/sentiment_analysis/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/sentiment_analysis/&amp;title=How%20Positive%20are%20Your%20Facebook%20Posts?" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=How%20Positive%20are%20Your%20Facebook%20Posts?%20/post/sentiment_analysis/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/sentiment_analysis/&amp;title=How%20Positive%20are%20Your%20Facebook%20Posts?" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/paul-apivat-hanvongse/avatar_hu63a07477d78c9be41fad7b90b509fc17_91571_270x270_fill_q90_lanczos_center.jpg" alt="Paul Apivat Hanvongse">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/">Paul Apivat Hanvongse</a></h5>
        <h6 class="card-subtitle">Self-Employed | Getwyze</h6>
        <p class="card-text">My interests include data science, machine learning and R/Python programming.</p>
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/paulapivat" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/paulapivat/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/paulapivat" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  


  










  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/twitter_analytics/">Analyzing Your Twitter Data</a></li>
      
      <li><a href="/post/dsfs_8/">Gradient Descent -- Data Science from Scratch (ch8)</a></li>
      
      <li><a href="/post/dsfs_7/">Data Science from Scratch (ch7) - Hypothesis and Inference</a></li>
      
      <li><a href="/post/statistics_probability/">Statistics &amp; Probability in Code</a></li>
      
      <li><a href="/post/dsfs_6/">Data Science from Scratch (ch6) - Probability</a></li>
      
    </ul>
  </div>
  




  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  
  <p class="powered-by">
    
      <a href="/privacy/">Privacy Policy</a>
    
    
       &middot; 
      <a href="/terms/">Terms</a>
    
  </p>
  

  <p class="powered-by">
    © 2020 Paul Apivat Hanvongse. All Rights Reserved.
  </p>

  
  






  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
