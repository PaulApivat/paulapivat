<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Text Mining | Paul Apivat</title>
    <link>/tag/text-mining/</link>
      <atom:link href="/tag/text-mining/index.xml" rel="self" type="application/rss+xml" />
    <description>Text Mining</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020 Paul Apivat Hanvongse. All Rights Reserved.</copyright><lastBuildDate>Thu, 18 Mar 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Text Mining</title>
      <link>/tag/text-mining/</link>
    </image>
    
    <item>
      <title>Pad Thai is a Terrible Choice</title>
      <link>/post/query_ethereum/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/post/query_ethereum/</guid>
      <description>&lt;h3 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#exploratory_questions&#34;&gt;Exploratory Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#web_scraping&#34;&gt;Web Scraping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#data_cleaning&#34;&gt;Data Cleaning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#data_visualization&#34;&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#text_mining&#34;&gt;Text Mining&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s order Thai.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Great, what&amp;rsquo;s your go-to dish?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Pad Thai.”&lt;/p&gt;
&lt;p&gt;This has bugged me for years and is the genesis for this project.&lt;/p&gt;
&lt;p&gt;People need to know they have other choices aside from Pad Thai. Pad Thai is one of 53 individual dishes and stopping there risks missing out on at least 201 shared Thai dishes (source: 
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This project is an opportunity to build a data set of Thai dishes by scraping tables off Wikipedia. We will use Python for web scraping and R for visualization. Web scraping is done in &lt;code&gt;Beautiful Soup&lt;/code&gt; (Python) and pre-processed further with &lt;code&gt;dplyr&lt;/code&gt; and visualized with &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, we&amp;rsquo;ll use the &lt;code&gt;tidytext&lt;/code&gt; package in R to explore the names of Thai dishes (in English) to see if we can learn some interest things from text data.&lt;/p&gt;
&lt;p&gt;Finally, there is an opportunity to make an open source 
&lt;a href=&#34;https://github.com/holtzy/R-graph-gallery/pull/34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;contribution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project repo is 
&lt;a href=&#34;https://github.com/PaulApivat/thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;exploratory_questions&#34;&gt;Exploratory_Questions&lt;/h3&gt;
&lt;p&gt;The purpose of this analysis is to generate questions.&lt;/p&gt;
&lt;p&gt;Because &lt;strong&gt;exploratory analysis&lt;/strong&gt; is iterative, these questions were generated in the process of manipulating and visualizing data. We can use these questions to structure the rest of the post:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How might we organized Thai dishes?&lt;/li&gt;
&lt;li&gt;What is the best way to organized the different dishes?&lt;/li&gt;
&lt;li&gt;Which raw material(s) are most popular?&lt;/li&gt;
&lt;li&gt;Which raw materials are most important?&lt;/li&gt;
&lt;li&gt;Could you learn about Thai food just from the names of the dishes?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;web_scraping&#34;&gt;Web_Scraping&lt;/h3&gt;
&lt;p&gt;We scraped over 
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;300 Thai dishes&lt;/a&gt;. For each dish, we got:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thai name&lt;/li&gt;
&lt;li&gt;Thai script&lt;/li&gt;
&lt;li&gt;English name&lt;/li&gt;
&lt;li&gt;Region&lt;/li&gt;
&lt;li&gt;Description&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, we&amp;rsquo;ll use the following Python libraries/modules:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests
from bs4 import BeautifulSoup
import urllib.request
import urllib.parse
import urllib.error
import ssl
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;rsquo;ll use &lt;code&gt;requests&lt;/code&gt; to send an HTTP requests to the wikipedia url we need. We&amp;rsquo;ll access network sockets using &amp;lsquo;secure sockets layer&amp;rsquo; (SSL). Then we&amp;rsquo;ll read in the html data to parse it with &lt;strong&gt;Beautiful Soup&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Before using &lt;strong&gt;Beautiful Soup&lt;/strong&gt;, we want to understand the structure of the page (and tables) we want to scrape under &lt;strong&gt;inspect element&lt;/strong&gt; on the browser (note: I used Chrome). We can see that we want the &lt;code&gt;table&lt;/code&gt; tag, along with &lt;code&gt;class&lt;/code&gt; of wikitable sortable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./web_scrap.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The main function we&amp;rsquo;ll use from &lt;strong&gt;Beautiful Soup&lt;/strong&gt; is &lt;code&gt;findAll()&lt;/code&gt; and the three parameters are &lt;code&gt;th&lt;/code&gt; (Header Cell in HTML table), &lt;code&gt;tr&lt;/code&gt; (Row in HTML table) and &lt;code&gt;td&lt;/code&gt; (Standard Data Cell).&lt;/p&gt;
&lt;p&gt;First, we&amp;rsquo;ll save the table headers in a list, which we&amp;rsquo;ll use when creating an empty &lt;code&gt;dictionary&lt;/code&gt; to store the data we need.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;header = [item.text.rstrip() for item in all_tables[0].findAll(&#39;th&#39;)]

table = dict([(x, 0) for x in header])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Initially, we want to scrape one table, knowing that we&amp;rsquo;ll need to repeat the process for all 16 tables. Therefore we&amp;rsquo;ll use a &lt;em&gt;nested loop&lt;/em&gt;. Because all tables have 6 columns, we&amp;rsquo;ll want to create 6 empty lists.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll scrape through all table rows &lt;code&gt;tr&lt;/code&gt; and check for 6 cells (which we should have for 6 columns), then we&amp;rsquo;ll &lt;em&gt;append&lt;/em&gt; the data to each empty list we created.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# loop through all 16 tables
a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

# 6 empty list (for 6 columns) to store data
a1 = []
a2 = []
a3 = []
a4 = []
a5 = []
a6 = []

# nested loop for looping through all 16 tables, then all tables individually
for i in a:
    for row in all_tables[i].findAll(&#39;tr&#39;):
        cells = row.findAll(&#39;td&#39;)
        if len(cells) == 6:
            a1.append([string for string in cells[0].strings])
            a2.append(cells[1].find(text=True))
            a3.append(cells[2].find(text=True))
            a4.append(cells[3].find(text=True))
            a5.append(cells[4].find(text=True))
            a6.append([string for string in cells[5].strings])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&amp;rsquo;ll note the code for &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt; are slightly different. In retrospect, I found that &lt;code&gt;cells[0].find(text=True)&lt;/code&gt; did &lt;strong&gt;not&lt;/strong&gt; yield certain texts, particularly if they were links, therefore a slight adjustment is made.&lt;/p&gt;
&lt;p&gt;The strings tag returns a &lt;code&gt;NavigableString&lt;/code&gt; type object while text returns a &lt;code&gt;unicode&lt;/code&gt; object (see 
&lt;a href=&#34;https://stackoverflow.com/questions/25327693/difference-between-string-and-text-beautifulsoup&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stack overflow&lt;/a&gt; explanation).&lt;/p&gt;
&lt;p&gt;After we&amp;rsquo;ve scrapped the data, we&amp;rsquo;ll need to store the data in a &lt;code&gt;dictionary&lt;/code&gt; before converting to &lt;code&gt;data frame&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# create dictionary
table = dict([(x, 0) for x in header])

# append dictionary with corresponding data list
table[&#39;Thai name&#39;] = a1
table[&#39;Thai script&#39;] = a2
table[&#39;English name&#39;] = a3
table[&#39;Image&#39;] = a4
table[&#39;Region&#39;] = a5
table[&#39;Description&#39;] = a6

# turn dict into dataframe
df_table = pd.DataFrame(table)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt;, we need to do an extra step of joining the strings together, so I&amp;rsquo;ve created two additional corresponding columns, &lt;code&gt;Thai name 2&lt;/code&gt; and &lt;code&gt;Description2&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Need to Flatten Two Columns: &#39;Thai name&#39; and &#39;Description&#39;
# Create two new columns
df_table[&#39;Thai name 2&#39;] = &amp;quot;&amp;quot;
df_table[&#39;Description2&#39;] = &amp;quot;&amp;quot;

# join all words in the list for each of 328 rows and set to thai_dishes[&#39;Description2&#39;] column
# automatically flatten the list
df_table[&#39;Description2&#39;] = [
    &#39; &#39;.join(cell) for cell in df_table[&#39;Description&#39;]]

df_table[&#39;Thai name 2&#39;] = [
    &#39; &#39;.join(cell) for cell in df_table[&#39;Thai name&#39;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After we&amp;rsquo;ve scrapped all the data and converted from &lt;code&gt;dictionary&lt;/code&gt; to &lt;code&gt;data frame&lt;/code&gt;, we&amp;rsquo;ll write to CSV to prepare for data cleaning in R (&lt;strong&gt;note&lt;/strong&gt;: I saved the csv as thai_dishes.csv, but you can choose a different name).&lt;/p&gt;
&lt;h3 id=&#34;data_cleaning&#34;&gt;Data_Cleaning&lt;/h3&gt;
&lt;p&gt;Data cleaning is typically non-linear.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll manipulate the data to explore, learn &lt;em&gt;about&lt;/em&gt; the data and see that certain things need cleaning or, in some cases, going back to Python to re-scrape. The columns &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt; were scraped differently from other columns due to &lt;strong&gt;missing data&lt;/strong&gt; found during exploration and cleaning.&lt;/p&gt;
&lt;p&gt;For certain links, using &lt;code&gt;.find(text=True)&lt;/code&gt; did not work as intended, so a slight adjustment was made.&lt;/p&gt;
&lt;p&gt;For this post, &lt;code&gt;R&lt;/code&gt; is the tool of choice for cleaning the data.&lt;/p&gt;
&lt;p&gt;Here are other data cleaning tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Changing column names (snake case)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# read data
df &amp;lt;- read_csv(&amp;quot;thai_dishes.csv&amp;quot;)

# change column name
df &amp;lt;- df %&amp;gt;%
    rename(
        Thai_name = `Thai name`,
        Thai_name_2 = `Thai name 2`,
        Thai_script = `Thai script`,
        English_name = `English name`
    )

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Remove newline escape sequence (\n)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# remove  \n from all columns ----
df$Thai_name &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_name)
df$Thai_name_2 &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_name_2)
df$Thai_script &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_script)
df$English_name &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$English_name)
df$Image &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Image)
df$Region &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Region)
df$Description &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Description)
df$Description2 &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Description2)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Add/Mutate new columns (major_groupings, minor_groupings):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Add Major AND Minor Groupings ----
df &amp;lt;- df %&amp;gt;%
    mutate(
        major_grouping = as.character(NA),
        minor_grouping = as.character(NA)
        )
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Edit rows for missing data in Thai_name column: 26, 110, 157, 234-238, 240, 241, 246&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This was only necessary the first time round, after the changes are made to how I scraped &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt;, this step is &lt;strong&gt;no longer necessary&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# If necessary; may not need to do this after scraping a1 and a6 - see above
# Edit Rows for missing Thai_name
df[26,]$Thai_name &amp;lt;- &amp;quot;Khanom chin nam ngiao&amp;quot;
df[110,]$Thai_name &amp;lt;- &amp;quot;Lap Lanna&amp;quot;
df[157,]$Thai_name &amp;lt;- &amp;quot;Kai phat khing&amp;quot;
df[234,]$Thai_name &amp;lt;- &amp;quot;Nam chim chaeo&amp;quot;
df[235,]$Thai_name &amp;lt;- &amp;quot;Nam chim kai&amp;quot;
df[236,]$Thai_name &amp;lt;- &amp;quot;Nam chim paesa&amp;quot;
df[237,]$Thai_name &amp;lt;- &amp;quot;Nam chim sate&amp;quot;
df[238,]$Thai_name &amp;lt;- &amp;quot;Nam phrik i-ke&amp;quot;
df[240,]$Thai_name &amp;lt;- &amp;quot;Nam phrik kha&amp;quot;
df[241,]$Thai_name &amp;lt;- &amp;quot;Nam phrik khaep mu&amp;quot;
df[246,]$Thai_name &amp;lt;- &amp;quot;Nam phrik pla chi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;save to &amp;ldquo;edit_thai_dishes.csv&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Write new csv to save edits made to data frame
write_csv(df, &amp;quot;edit_thai_dishes.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;data_visualization&#34;&gt;Data_Visualization&lt;/h3&gt;
&lt;p&gt;There are several ways to visualize the data. Because we want to communicate the diversity of Thai dishes, &lt;em&gt;aside&lt;/em&gt; from Pad Thai, we want a visualization that captures the many, many options.&lt;/p&gt;
&lt;p&gt;I opted for a &lt;strong&gt;dendrogram&lt;/strong&gt;. This graph assumes hierarchy within the data, which fits our project because we can organize the dishes in grouping and sub-grouping.&lt;/p&gt;
&lt;h4 id=&#34;how-might-we-organized-thai-dishes&#34;&gt;How might we organized Thai dishes?&lt;/h4&gt;
&lt;p&gt;We first make a distinction between &lt;strong&gt;individual&lt;/strong&gt; and &lt;strong&gt;shared&lt;/strong&gt; dishes to show that Pad Thai is not even close to being the best &lt;em&gt;individual&lt;/em&gt; dish. And, in fact, more dishes fall under the &lt;strong&gt;shared&lt;/strong&gt; grouping.&lt;/p&gt;
&lt;p&gt;To avoid cramming too much data into one visual, we&amp;rsquo;ll create two separate visualizations for individual vs. shared dishes.&lt;/p&gt;
&lt;p&gt;Here is the first &lt;strong&gt;dendrogram&lt;/strong&gt; representing 52 individual dish alternatives to Pad Thai.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./indiv_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Creating a dendrogram requires using the &lt;code&gt;ggraph&lt;/code&gt; and &lt;code&gt;igraph&lt;/code&gt; libraries. First, we&amp;rsquo;ll load the libraries and sub-set our data frame by filtering for Individual Dishes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df &amp;lt;- read_csv(&amp;quot;edit_thai_dishes.csv&amp;quot;)

library(ggraph)
library(igraph)

df %&amp;gt;%
    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&amp;gt;%
    filter(major_grouping == &#39;Individual dishes&#39;) %&amp;gt;%
    group_by(minor_grouping) %&amp;gt;%
    count() 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We create edges and nodes (i.e., from and to) to create the sub-groupings within Individual Dishes (i.e., Rice, Noodles and Misc):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Individual Dishes ----

# data: edge list
d1 &amp;lt;- data.frame(from=&amp;quot;Individual dishes&amp;quot;, to=c(&amp;quot;Misc Indiv&amp;quot;, &amp;quot;Noodle dishes&amp;quot;, &amp;quot;Rice dishes&amp;quot;))

d2 &amp;lt;- df %&amp;gt;%
    select(minor_grouping, Thai_name) %&amp;gt;%
    slice(1:53) %&amp;gt;%
    rename(
        from = minor_grouping,
        to = Thai_name
    ) 

edges &amp;lt;- rbind(d1, d2)

# plot dendrogram (idividual dishes)
indiv_dishes_graph &amp;lt;- graph_from_data_frame(edges)

ggraph(indiv_dishes_graph, layout = &amp;quot;dendrogram&amp;quot;, circular = FALSE) +
    geom_edge_diagonal(aes(edge_colour = edges$from), label_dodge = NULL) +
    geom_node_text(aes(label = name, filter = leaf, color = &#39;red&#39;), hjust = 1.1, size = 3) +
    geom_node_point(color = &amp;quot;whitesmoke&amp;quot;) +
    theme(
        plot.background = element_rect(fill = &#39;#343d46&#39;),
        panel.background = element_rect(fill = &#39;#343d46&#39;),
        legend.position = &#39;none&#39;,
        plot.title = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;, size = 25),
        plot.subtitle = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;),
        plot.caption = element_text(color = &#39;whitesmoke&#39;, face = &#39;italic&#39;)
    ) +
    labs(
        title = &#39;52 Alternatives to Pad Thai&#39;,
        subtitle = &#39;Individual Thai Dishes&#39;,
        caption = &#39;Data: Wikipedia | Graphic: @paulapivat&#39;
    ) +
    expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +
    coord_flip() +
    annotate(&amp;quot;text&amp;quot;, x = 47, y = 1, label = &amp;quot;Miscellaneous (7)&amp;quot;, color = &amp;quot;#7CAE00&amp;quot;)+
    annotate(&amp;quot;text&amp;quot;, x = 31, y = 1, label = &amp;quot;Noodle Dishes (24)&amp;quot;, color = &amp;quot;#00C08B&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 8, y = 1, label = &amp;quot;Rice Dishes (22)&amp;quot;, color = &amp;quot;#C77CFF&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 26, y = 2, label = &amp;quot;Individual\nDishes&amp;quot;, color = &amp;quot;#F8766D&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;what-is-the-best-way-to-organized-the-different-dishes&#34;&gt;What is the best way to organized the different dishes?&lt;/h4&gt;
&lt;p&gt;There are approximately &lt;strong&gt;4X&lt;/strong&gt; as many &lt;em&gt;shared&lt;/em&gt; dishes as individual dishes, so the dendrogram should be &lt;strong&gt;circular&lt;/strong&gt; to fit the names of all dishes in one graphic.&lt;/p&gt;
&lt;p&gt;A wonderful resource I use regularly for these types of visuals is the 
&lt;a href=&#34;https://www.r-graph-gallery.com/339-circular-dendrogram-with-ggraph.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R Graph Gallery&lt;/a&gt;. There was a slight issue in how the &lt;strong&gt;text angles&lt;/strong&gt; were calculated so I submitted a 
&lt;a href=&#34;https://github.com/holtzy/R-graph-gallery/pull/34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PR to fix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Perhaps distinguishing between individual and shared dishes is too crude, within the dendrogram for 201 shared Thai dishes, we can see further sub-groupings including Curries, Sauces/Pastes, Steamed, Grilled, Deep-Fried, Fried &amp;amp; Stir-Fried, Salads, Soups and other Misc:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./shared_dishes_final.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Shared Dishes ----
df %&amp;gt;%
    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&amp;gt;%
    filter(major_grouping == &#39;Shared dishes&#39;) %&amp;gt;%
    group_by(minor_grouping) %&amp;gt;%
    count() %&amp;gt;%
    arrange(desc(n))

d3 &amp;lt;- data.frame(from=&amp;quot;Shared dishes&amp;quot;, to=c(&amp;quot;Curries&amp;quot;, &amp;quot;Soups&amp;quot;, &amp;quot;Salads&amp;quot;,
                                            &amp;quot;Fried and stir-fried dishes&amp;quot;, &amp;quot;Deep-fried dishes&amp;quot;, &amp;quot;Grilled dishes&amp;quot;,
                                            &amp;quot;Steamed or blanched dishes&amp;quot;, &amp;quot;Stewed dishes&amp;quot;, &amp;quot;Dipping sauces and pastes&amp;quot;, &amp;quot;Misc Shared&amp;quot;))


d4 &amp;lt;- df %&amp;gt;%
    select(minor_grouping, Thai_name) %&amp;gt;%
    slice(54:254) %&amp;gt;%
    rename(
        from = minor_grouping,
        to = Thai_name
    )

edges2 &amp;lt;- rbind(d3, d4)

# create a vertices data.frame. One line per object of hierarchy
vertices = data.frame(
    name = unique(c(as.character(edges2$from), as.character(edges2$to)))
)

# add column with group of each name. Useful to later color points
vertices$group = edges2$from[ match(vertices$name, edges2$to)]

# Add information concerning the label we are going to add: angle, horizontal adjustment and potential flip
# calculate the ANGLE of the labels
vertices$id=NA
myleaves=which(is.na(match(vertices$name, edges2$from)))
nleaves=length(myleaves)
vertices$id[myleaves] = seq(1:nleaves)
vertices$angle = 360 / nleaves * vertices$id + 90    


# calculate the alignment of labels: right or left
vertices$hjust&amp;lt;-ifelse( vertices$angle &amp;lt; 275, 1, 0)



# flip angle BY to make them readable
vertices$angle&amp;lt;-ifelse(vertices$angle &amp;lt; 275, vertices$angle+180, vertices$angle)

# plot dendrogram (shared dishes)
shared_dishes_graph &amp;lt;- graph_from_data_frame(edges2)

ggraph(shared_dishes_graph, layout = &amp;quot;dendrogram&amp;quot;, circular = TRUE) +
    geom_edge_diagonal(aes(edge_colour = edges2$from), label_dodge = NULL) +
    geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = vertices$angle, hjust= vertices$hjust, colour= vertices$group), size=2.7, alpha=1) +
    geom_node_point(color = &amp;quot;whitesmoke&amp;quot;) +
    theme(
        plot.background = element_rect(fill = &#39;#343d46&#39;),
        panel.background = element_rect(fill = &#39;#343d46&#39;),
        legend.position = &#39;none&#39;,
        plot.title = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;, size = 25),
        plot.subtitle = element_text(colour = &#39;whitesmoke&#39;, margin = margin(0,0,30,0), size = 20),
        plot.caption = element_text(color = &#39;whitesmoke&#39;, face = &#39;italic&#39;)
    ) +
    labs(
        title = &#39;Thai Food is Best Shared&#39;,
        subtitle = &#39;201 Ways to Make Friends&#39;,
        caption = &#39;Data: Wikipedia | Graphic: @paulapivat&#39;
    ) +
    #expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +
    expand_limits(x = c(-1.5, 1.5), y = c(-1.5, 1.5)) +
    coord_flip() +
    annotate(&amp;quot;text&amp;quot;, x = 0.4, y = 0.45, label = &amp;quot;Steamed&amp;quot;, color = &amp;quot;#F564E3&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.2, y = 0.5, label = &amp;quot;Grilled&amp;quot;, color = &amp;quot;#00BA38&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.2, y = 0.5, label = &amp;quot;Deep-Fried&amp;quot;, color = &amp;quot;#DE8C00&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.4, y = 0.1, label = &amp;quot;Fried &amp;amp;\n Stir-Fried&amp;quot;, color = &amp;quot;#7CAE00&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.3, y = -0.4, label = &amp;quot;Salads&amp;quot;, color = &amp;quot;#00B4F0&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.05, y = -0.5, label = &amp;quot;Soups&amp;quot;, color = &amp;quot;#C77CFF&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.3, y = -0.5, label = &amp;quot;Curries&amp;quot;, color = &amp;quot;#F8766D&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.5, y = -0.1, label = &amp;quot;Misc&amp;quot;, color = &amp;quot;#00BFC4&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.5, y = 0.1, label = &amp;quot;Sauces\nPastes&amp;quot;, color = &amp;quot;#B79F00&amp;quot;)
    
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;text_mining&#34;&gt;Text_Mining&lt;/h3&gt;
&lt;h4 id=&#34;which-raw-materials-are-most-popular&#34;&gt;Which raw material(s) are most popular?&lt;/h4&gt;
&lt;p&gt;One way to answer this question is to use text mining to &lt;strong&gt;tokenize&lt;/strong&gt; by either word and count the words by frequency as one measure of popularity.&lt;/p&gt;
&lt;p&gt;In the below bar chart, we see frequency of words across all Thai Dishes. &lt;strong&gt;Mu&lt;/strong&gt; (หมู) which means pork in Thai appears most frequently across all dish types and sub-grouping. Next we have &lt;strong&gt;kaeng&lt;/strong&gt; (แกง) which means curry. &lt;strong&gt;Phat&lt;/strong&gt; (ผัด) comings in third suggesting &amp;ldquo;stir-fry&amp;rdquo; is a popular cooking mode.&lt;/p&gt;
&lt;p&gt;As we can see &lt;strong&gt;not&lt;/strong&gt; all words refer to raw materials, so we may not be able to answer this question directly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./word_freq_barchart.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;library(tidytext)
library(scales)

# new csv file after data cleaning (see above)
df &amp;lt;- read_csv(&amp;quot;../web_scraping/edit_thai_dishes.csv&amp;quot;)

df %&amp;gt;%
    select(Thai_name, Thai_script) %&amp;gt;%
    # can substitute &#39;word&#39; for ngrams, sentences, lines
    unnest_tokens(ngrams, Thai_name) %&amp;gt;%  
    # to reference thai spelling: group_by(Thai_script)
    group_by(ngrams) %&amp;gt;%  
    tally(sort = TRUE) %&amp;gt;%  # alt: count(sort = TRUE)
    filter(n &amp;gt; 9) %&amp;gt;%
# visualize
# pipe directly into ggplot2, because using tidytools
    ggplot(aes(x = n, y = reorder(ngrams, n))) + 
    geom_col(aes(fill = ngrams)) +
    scale_fill_manual(values = c(
        &amp;quot;#c3d66b&amp;quot;,
        &amp;quot;#70290a&amp;quot;,
        &amp;quot;#2f1c0b&amp;quot;,
        &amp;quot;#ba9d8f&amp;quot;,
        &amp;quot;#dda37b&amp;quot;,
        &amp;quot;#8f5e23&amp;quot;,
        &amp;quot;#96b224&amp;quot;,
        &amp;quot;#dbcac9&amp;quot;,
        &amp;quot;#626817&amp;quot;,
        &amp;quot;#a67e5f&amp;quot;,
        &amp;quot;#be7825&amp;quot;,
        &amp;quot;#446206&amp;quot;,
        &amp;quot;#c8910b&amp;quot;,
        &amp;quot;#88821b&amp;quot;,
        &amp;quot;#313d5f&amp;quot;,
        &amp;quot;#73869a&amp;quot;,
        &amp;quot;#6f370f&amp;quot;,
        &amp;quot;#c0580d&amp;quot;,
        &amp;quot;#e0d639&amp;quot;,
        &amp;quot;#c9d0ce&amp;quot;,
        &amp;quot;#ebf1f0&amp;quot;,
        &amp;quot;#50607b&amp;quot;
    )) +
    theme_minimal() +
    theme(legend.position = &amp;quot;none&amp;quot;) +
    labs(
        x = &amp;quot;Frequency&amp;quot;,
        y = &amp;quot;Words&amp;quot;,
        title = &amp;quot;Frequency of Words in Thai Cuisine&amp;quot;,
        subtitle = &amp;quot;Words appearing at least 10 times in Individual or Shared Dishes&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphic: @paulapivat&amp;quot;
    )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also see words common to both Individual and Shared Dishes. We see other words like &lt;strong&gt;nuea&lt;/strong&gt; (beef), &lt;strong&gt;phrik&lt;/strong&gt; (chili) and &lt;strong&gt;kaphrao&lt;/strong&gt; (basil leaves).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./word_freq_indiv_shared_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# frequency for Thai_dishes (Major Grouping) ----

# comparing Individual and Shared Dishes (Major Grouping)
thai_name_freq &amp;lt;- df %&amp;gt;%
    select(Thai_name, Thai_script, major_grouping) %&amp;gt;%
    unnest_tokens(ngrams, Thai_name) %&amp;gt;% 
    count(ngrams, major_grouping) %&amp;gt;%
    group_by(major_grouping) %&amp;gt;%
    mutate(proportion = n / sum(n)) %&amp;gt;%
    select(major_grouping, ngrams, proportion) %&amp;gt;%
    spread(major_grouping, proportion) %&amp;gt;%
    gather(major_grouping, proportion, c(`Shared dishes`)) %&amp;gt;%
    select(ngrams, `Individual dishes`, major_grouping, proportion)


# Expect warming message about missing values
ggplot(thai_name_freq, aes(x = proportion, y = `Individual dishes`,
       color = abs(`Individual dishes` - proportion))) +
    geom_abline(color = &#39;gray40&#39;, lty = 2) +
    geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
    geom_text(aes(label = ngrams), check_overlap = TRUE, vjust = 1.5) +
    scale_x_log10(labels = percent_format()) +
    scale_y_log10(labels = percent_format()) +
    scale_color_gradient(limits = c(0, 0.01), 
                         low = &amp;quot;red&amp;quot;, high = &amp;quot;blue&amp;quot;) +    # low = &amp;quot;darkslategray4&amp;quot;, high = &amp;quot;gray75&amp;quot;
    theme_minimal() +
    theme(legend.position = &amp;quot;none&amp;quot;,
          legend.text = element_text(angle = 45, hjust = 1)) +
    labs(y = &amp;quot;Individual Dishes&amp;quot;,
         x = &amp;quot;Shared Dishes&amp;quot;,
         color = NULL,
         title = &amp;quot;Comparing Word Frequencies in the names Thai Dishes&amp;quot;,
         subtitle = &amp;quot;Individual and Shared Dishes&amp;quot;,
         caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;which-raw-materials-are-most-important&#34;&gt;Which raw materials are most important?&lt;/h4&gt;
&lt;p&gt;We can only learn so much from frequency, so text mining practitioners have created &lt;strong&gt;term frequency - inverse document frequency&lt;/strong&gt; to better reflect how important a word is in a document or corpus (further details 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Again, the words don&amp;rsquo;t necessarily refer to raw materials, so this question can&amp;rsquo;t be fully answered directly here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./td_idf_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;could-you-learn-about-thai-food-just-from-the-names-of-the-dishes&#34;&gt;Could you learn about Thai food just from the names of the dishes?&lt;/h4&gt;
&lt;p&gt;The short answer is &amp;ldquo;yes&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;We learned just from frequency and &amp;ldquo;term frequency - inverse document frequency&amp;rdquo; not only the most frequent words, but the relative importance within the current set of words that we have tokenized with &lt;code&gt;tidytext&lt;/code&gt;. This informs us of not only popular raw materials (Pork), but also dish types (Curries) and other popular mode of preparation (Stir-Fry).&lt;/p&gt;
&lt;p&gt;We can even examine the &lt;strong&gt;network of relationships&lt;/strong&gt; between words. Darker arrows suggest a stronger relationship between pairs of words, for example &amp;ldquo;nam phrik&amp;rdquo; is a strong pairing. This means &amp;ldquo;chili sauce&amp;rdquo; in Thai and suggests the important role that it plays across many types of dishes.&lt;/p&gt;
&lt;p&gt;We learned above that &amp;ldquo;mu&amp;rdquo; (pork) appears frequently. Now we see that &amp;ldquo;mu&amp;rdquo; and &amp;ldquo;krop&amp;rdquo; are more related than other pairings (note: &amp;ldquo;mu krop&amp;rdquo; means &amp;ldquo;crispy pork&amp;rdquo;). We also saw above that &amp;ldquo;khao&amp;rdquo; appears frequently in Rice dishes. This alone is not surprising as &amp;ldquo;khao&amp;rdquo; means rice in Thai, but we see here &amp;ldquo;khao phat&amp;rdquo; is strongly related suggesting that fried rice (&amp;ldquo;khao phat&amp;rdquo;) is quite popular.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./network_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Visualizing a network of Bi-grams with {ggraph} ----
library(igraph)
library(ggraph)
set.seed(2021)

thai_dish_bigram_counts &amp;lt;- df %&amp;gt;%
    select(Thai_name, minor_grouping) %&amp;gt;%
    unnest_tokens(bigram, Thai_name, token = &amp;quot;ngrams&amp;quot;, n = 2) %&amp;gt;%
    separate(bigram, c(&amp;quot;word1&amp;quot;, &amp;quot;word2&amp;quot;), sep = &amp;quot; &amp;quot;) %&amp;gt;%
    count(word1, word2, sort = TRUE)


# filter for relatively common combinations (n &amp;gt; 2)
thai_dish_bigram_graph &amp;lt;- thai_dish_bigram_counts %&amp;gt;%
    filter(n &amp;gt; 2) %&amp;gt;%
    graph_from_data_frame()


# polishing operations to make a better looking graph
a &amp;lt;- grid::arrow(type = &amp;quot;closed&amp;quot;, length = unit(.15, &amp;quot;inches&amp;quot;))

set.seed(2021)
ggraph(thai_dish_bigram_graph, layout = &amp;quot;fr&amp;quot;) +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                   arrow = a, end_cap = circle(.07, &#39;inches&#39;)) +
    geom_node_point(color = &amp;quot;dodgerblue&amp;quot;, size = 5, alpha = 0.7) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    labs(
        title = &amp;quot;Network of Relations between Word Pairs&amp;quot;,
        subtitle = &amp;quot;{ggraph}: common nodes in Thai food&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;
    ) +
    theme_void()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we may be interested in word relationships &lt;em&gt;within&lt;/em&gt; individual dishes.&lt;/p&gt;
&lt;p&gt;The below graph shows a network of word pairs with moderate-to-high correlations. We can see certain words clustered near each other with relatively dark lines: kaeng (curry), pet (spicy), wan (sweet), khiao (green curry), phrik (chili) and mu (pork). These words represent a collection of ingredient, mode of cooking and description that are generally combined.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./indiv_dish_corr.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;set.seed(2021)

# Individual Dishes
individual_dish_words &amp;lt;- df %&amp;gt;%
    select(major_grouping, Thai_name) %&amp;gt;%
    filter(major_grouping == &#39;Individual dishes&#39;) %&amp;gt;%
    mutate(section = row_number() %/% 10) %&amp;gt;%
    filter(section &amp;gt; 0) %&amp;gt;%
    unnest_tokens(word, Thai_name)  # assume no stop words

individual_dish_cors &amp;lt;- individual_dish_words %&amp;gt;%
    group_by(word) %&amp;gt;% 
    filter(n() &amp;gt;= 2) %&amp;gt;%     # looking for co-occuring words, so must be 2 or greater
    pairwise_cor(word, section, sort = TRUE) 


individual_dish_cors %&amp;gt;%
    filter(correlation &amp;lt; -0.40) %&amp;gt;%
    graph_from_data_frame() %&amp;gt;%
    ggraph(layout = &amp;quot;fr&amp;quot;) +
    geom_edge_link(aes(edge_alpha = correlation, size = correlation), show.legend = TRUE) +
    geom_node_point(color = &amp;quot;green&amp;quot;, size = 5, alpha = 0.5) +
    geom_node_text(aes(label = name), repel = TRUE) +
    labs(
        title = &amp;quot;Word Pairs in Individual Dishes&amp;quot;,
        subtitle = &amp;quot;{ggraph}: Negatively correlated (r = -0.4)&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;
    ) +
    theme_void()
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;
&lt;p&gt;We have completed an exploratory data project where we scraped, clean, manipulated and visualized data using a combination of Python and R. We also used the &lt;code&gt;tidytext&lt;/code&gt; package for basic text mining task to see if we could gain some insights into Thai cuisine using  words from dish names scraped off Wikipedia.&lt;/p&gt;
&lt;p&gt;For more content on data science, R, Python, SQL and more, 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pad Thai is a Terrible Choice</title>
      <link>/post/thai_dishes_project/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>/post/thai_dishes_project/</guid>
      <description>&lt;h3 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#overview&#34;&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#exploratory_questions&#34;&gt;Exploratory Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#web_scraping&#34;&gt;Web Scraping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#data_cleaning&#34;&gt;Data Cleaning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#data_visualization&#34;&gt;Data Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#text_mining&#34;&gt;Text Mining&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s order Thai.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Great, what&amp;rsquo;s your go-to dish?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Pad Thai.”&lt;/p&gt;
&lt;p&gt;This has bugged me for years and is the genesis for this project.&lt;/p&gt;
&lt;p&gt;People need to know they have other choices aside from Pad Thai. Pad Thai is one of 53 individual dishes and stopping there risks missing out on at least 201 shared Thai dishes (source: 
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This project is an opportunity to build a data set of Thai dishes by scraping tables off Wikipedia. We will use Python for web scraping and R for visualization. Web scraping is done in &lt;code&gt;Beautiful Soup&lt;/code&gt; (Python) and pre-processed further with &lt;code&gt;dplyr&lt;/code&gt; and visualized with &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Furthermore, we&amp;rsquo;ll use the &lt;code&gt;tidytext&lt;/code&gt; package in R to explore the names of Thai dishes (in English) to see if we can learn some interest things from text data.&lt;/p&gt;
&lt;p&gt;Finally, there is an opportunity to make an open source 
&lt;a href=&#34;https://github.com/holtzy/R-graph-gallery/pull/34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;contribution&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project repo is 
&lt;a href=&#34;https://github.com/PaulApivat/thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;exploratory_questions&#34;&gt;Exploratory_Questions&lt;/h3&gt;
&lt;p&gt;The purpose of this analysis is to generate questions.&lt;/p&gt;
&lt;p&gt;Because &lt;strong&gt;exploratory analysis&lt;/strong&gt; is iterative, these questions were generated in the process of manipulating and visualizing data. We can use these questions to structure the rest of the post:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How might we organized Thai dishes?&lt;/li&gt;
&lt;li&gt;What is the best way to organized the different dishes?&lt;/li&gt;
&lt;li&gt;Which raw material(s) are most popular?&lt;/li&gt;
&lt;li&gt;Which raw materials are most important?&lt;/li&gt;
&lt;li&gt;Could you learn about Thai food just from the names of the dishes?&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;web_scraping&#34;&gt;Web_Scraping&lt;/h3&gt;
&lt;p&gt;We scraped over 
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Thai_dishes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;300 Thai dishes&lt;/a&gt;. For each dish, we got:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thai name&lt;/li&gt;
&lt;li&gt;Thai script&lt;/li&gt;
&lt;li&gt;English name&lt;/li&gt;
&lt;li&gt;Region&lt;/li&gt;
&lt;li&gt;Description&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, we&amp;rsquo;ll use the following Python libraries/modules:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import requests
from bs4 import BeautifulSoup
import urllib.request
import urllib.parse
import urllib.error
import ssl
import pandas as pd
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;rsquo;ll use &lt;code&gt;requests&lt;/code&gt; to send an HTTP requests to the wikipedia url we need. We&amp;rsquo;ll access network sockets using &amp;lsquo;secure sockets layer&amp;rsquo; (SSL). Then we&amp;rsquo;ll read in the html data to parse it with &lt;strong&gt;Beautiful Soup&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Before using &lt;strong&gt;Beautiful Soup&lt;/strong&gt;, we want to understand the structure of the page (and tables) we want to scrape under &lt;strong&gt;inspect element&lt;/strong&gt; on the browser (note: I used Chrome). We can see that we want the &lt;code&gt;table&lt;/code&gt; tag, along with &lt;code&gt;class&lt;/code&gt; of wikitable sortable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./web_scrap.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The main function we&amp;rsquo;ll use from &lt;strong&gt;Beautiful Soup&lt;/strong&gt; is &lt;code&gt;findAll()&lt;/code&gt; and the three parameters are &lt;code&gt;th&lt;/code&gt; (Header Cell in HTML table), &lt;code&gt;tr&lt;/code&gt; (Row in HTML table) and &lt;code&gt;td&lt;/code&gt; (Standard Data Cell).&lt;/p&gt;
&lt;p&gt;First, we&amp;rsquo;ll save the table headers in a list, which we&amp;rsquo;ll use when creating an empty &lt;code&gt;dictionary&lt;/code&gt; to store the data we need.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;header = [item.text.rstrip() for item in all_tables[0].findAll(&#39;th&#39;)]

table = dict([(x, 0) for x in header])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Initially, we want to scrape one table, knowing that we&amp;rsquo;ll need to repeat the process for all 16 tables. Therefore we&amp;rsquo;ll use a &lt;em&gt;nested loop&lt;/em&gt;. Because all tables have 6 columns, we&amp;rsquo;ll want to create 6 empty lists.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll scrape through all table rows &lt;code&gt;tr&lt;/code&gt; and check for 6 cells (which we should have for 6 columns), then we&amp;rsquo;ll &lt;em&gt;append&lt;/em&gt; the data to each empty list we created.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# loop through all 16 tables
a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]

# 6 empty list (for 6 columns) to store data
a1 = []
a2 = []
a3 = []
a4 = []
a5 = []
a6 = []

# nested loop for looping through all 16 tables, then all tables individually
for i in a:
    for row in all_tables[i].findAll(&#39;tr&#39;):
        cells = row.findAll(&#39;td&#39;)
        if len(cells) == 6:
            a1.append([string for string in cells[0].strings])
            a2.append(cells[1].find(text=True))
            a3.append(cells[2].find(text=True))
            a4.append(cells[3].find(text=True))
            a5.append(cells[4].find(text=True))
            a6.append([string for string in cells[5].strings])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&amp;rsquo;ll note the code for &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt; are slightly different. In retrospect, I found that &lt;code&gt;cells[0].find(text=True)&lt;/code&gt; did &lt;strong&gt;not&lt;/strong&gt; yield certain texts, particularly if they were links, therefore a slight adjustment is made.&lt;/p&gt;
&lt;p&gt;The strings tag returns a &lt;code&gt;NavigableString&lt;/code&gt; type object while text returns a &lt;code&gt;unicode&lt;/code&gt; object (see 
&lt;a href=&#34;https://stackoverflow.com/questions/25327693/difference-between-string-and-text-beautifulsoup&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stack overflow&lt;/a&gt; explanation).&lt;/p&gt;
&lt;p&gt;After we&amp;rsquo;ve scrapped the data, we&amp;rsquo;ll need to store the data in a &lt;code&gt;dictionary&lt;/code&gt; before converting to &lt;code&gt;data frame&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# create dictionary
table = dict([(x, 0) for x in header])

# append dictionary with corresponding data list
table[&#39;Thai name&#39;] = a1
table[&#39;Thai script&#39;] = a2
table[&#39;English name&#39;] = a3
table[&#39;Image&#39;] = a4
table[&#39;Region&#39;] = a5
table[&#39;Description&#39;] = a6

# turn dict into dataframe
df_table = pd.DataFrame(table)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt;, we need to do an extra step of joining the strings together, so I&amp;rsquo;ve created two additional corresponding columns, &lt;code&gt;Thai name 2&lt;/code&gt; and &lt;code&gt;Description2&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Need to Flatten Two Columns: &#39;Thai name&#39; and &#39;Description&#39;
# Create two new columns
df_table[&#39;Thai name 2&#39;] = &amp;quot;&amp;quot;
df_table[&#39;Description2&#39;] = &amp;quot;&amp;quot;

# join all words in the list for each of 328 rows and set to thai_dishes[&#39;Description2&#39;] column
# automatically flatten the list
df_table[&#39;Description2&#39;] = [
    &#39; &#39;.join(cell) for cell in df_table[&#39;Description&#39;]]

df_table[&#39;Thai name 2&#39;] = [
    &#39; &#39;.join(cell) for cell in df_table[&#39;Thai name&#39;]]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After we&amp;rsquo;ve scrapped all the data and converted from &lt;code&gt;dictionary&lt;/code&gt; to &lt;code&gt;data frame&lt;/code&gt;, we&amp;rsquo;ll write to CSV to prepare for data cleaning in R (&lt;strong&gt;note&lt;/strong&gt;: I saved the csv as thai_dishes.csv, but you can choose a different name).&lt;/p&gt;
&lt;h3 id=&#34;data_cleaning&#34;&gt;Data_Cleaning&lt;/h3&gt;
&lt;p&gt;Data cleaning is typically non-linear.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll manipulate the data to explore, learn &lt;em&gt;about&lt;/em&gt; the data and see that certain things need cleaning or, in some cases, going back to Python to re-scrape. The columns &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt; were scraped differently from other columns due to &lt;strong&gt;missing data&lt;/strong&gt; found during exploration and cleaning.&lt;/p&gt;
&lt;p&gt;For certain links, using &lt;code&gt;.find(text=True)&lt;/code&gt; did not work as intended, so a slight adjustment was made.&lt;/p&gt;
&lt;p&gt;For this post, &lt;code&gt;R&lt;/code&gt; is the tool of choice for cleaning the data.&lt;/p&gt;
&lt;p&gt;Here are other data cleaning tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Changing column names (snake case)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# read data
df &amp;lt;- read_csv(&amp;quot;thai_dishes.csv&amp;quot;)

# change column name
df &amp;lt;- df %&amp;gt;%
    rename(
        Thai_name = `Thai name`,
        Thai_name_2 = `Thai name 2`,
        Thai_script = `Thai script`,
        English_name = `English name`
    )

&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Remove newline escape sequence (\n)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# remove  \n from all columns ----
df$Thai_name &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_name)
df$Thai_name_2 &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_name_2)
df$Thai_script &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Thai_script)
df$English_name &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$English_name)
df$Image &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Image)
df$Region &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Region)
df$Description &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Description)
df$Description2 &amp;lt;- gsub(&amp;quot;[\n]&amp;quot;, &amp;quot;&amp;quot;, df$Description2)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Add/Mutate new columns (major_groupings, minor_groupings):&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Add Major AND Minor Groupings ----
df &amp;lt;- df %&amp;gt;%
    mutate(
        major_grouping = as.character(NA),
        minor_grouping = as.character(NA)
        )
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Edit rows for missing data in Thai_name column: 26, 110, 157, 234-238, 240, 241, 246&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: This was only necessary the first time round, after the changes are made to how I scraped &lt;code&gt;a1&lt;/code&gt; and &lt;code&gt;a6&lt;/code&gt;, this step is &lt;strong&gt;no longer necessary&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# If necessary; may not need to do this after scraping a1 and a6 - see above
# Edit Rows for missing Thai_name
df[26,]$Thai_name &amp;lt;- &amp;quot;Khanom chin nam ngiao&amp;quot;
df[110,]$Thai_name &amp;lt;- &amp;quot;Lap Lanna&amp;quot;
df[157,]$Thai_name &amp;lt;- &amp;quot;Kai phat khing&amp;quot;
df[234,]$Thai_name &amp;lt;- &amp;quot;Nam chim chaeo&amp;quot;
df[235,]$Thai_name &amp;lt;- &amp;quot;Nam chim kai&amp;quot;
df[236,]$Thai_name &amp;lt;- &amp;quot;Nam chim paesa&amp;quot;
df[237,]$Thai_name &amp;lt;- &amp;quot;Nam chim sate&amp;quot;
df[238,]$Thai_name &amp;lt;- &amp;quot;Nam phrik i-ke&amp;quot;
df[240,]$Thai_name &amp;lt;- &amp;quot;Nam phrik kha&amp;quot;
df[241,]$Thai_name &amp;lt;- &amp;quot;Nam phrik khaep mu&amp;quot;
df[246,]$Thai_name &amp;lt;- &amp;quot;Nam phrik pla chi&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;save to &amp;ldquo;edit_thai_dishes.csv&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Write new csv to save edits made to data frame
write_csv(df, &amp;quot;edit_thai_dishes.csv&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;data_visualization&#34;&gt;Data_Visualization&lt;/h3&gt;
&lt;p&gt;There are several ways to visualize the data. Because we want to communicate the diversity of Thai dishes, &lt;em&gt;aside&lt;/em&gt; from Pad Thai, we want a visualization that captures the many, many options.&lt;/p&gt;
&lt;p&gt;I opted for a &lt;strong&gt;dendrogram&lt;/strong&gt;. This graph assumes hierarchy within the data, which fits our project because we can organize the dishes in grouping and sub-grouping.&lt;/p&gt;
&lt;h4 id=&#34;how-might-we-organized-thai-dishes&#34;&gt;How might we organized Thai dishes?&lt;/h4&gt;
&lt;p&gt;We first make a distinction between &lt;strong&gt;individual&lt;/strong&gt; and &lt;strong&gt;shared&lt;/strong&gt; dishes to show that Pad Thai is not even close to being the best &lt;em&gt;individual&lt;/em&gt; dish. And, in fact, more dishes fall under the &lt;strong&gt;shared&lt;/strong&gt; grouping.&lt;/p&gt;
&lt;p&gt;To avoid cramming too much data into one visual, we&amp;rsquo;ll create two separate visualizations for individual vs. shared dishes.&lt;/p&gt;
&lt;p&gt;Here is the first &lt;strong&gt;dendrogram&lt;/strong&gt; representing 52 individual dish alternatives to Pad Thai.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./indiv_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Creating a dendrogram requires using the &lt;code&gt;ggraph&lt;/code&gt; and &lt;code&gt;igraph&lt;/code&gt; libraries. First, we&amp;rsquo;ll load the libraries and sub-set our data frame by filtering for Individual Dishes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df &amp;lt;- read_csv(&amp;quot;edit_thai_dishes.csv&amp;quot;)

library(ggraph)
library(igraph)

df %&amp;gt;%
    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&amp;gt;%
    filter(major_grouping == &#39;Individual dishes&#39;) %&amp;gt;%
    group_by(minor_grouping) %&amp;gt;%
    count() 

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We create edges and nodes (i.e., from and to) to create the sub-groupings within Individual Dishes (i.e., Rice, Noodles and Misc):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Individual Dishes ----

# data: edge list
d1 &amp;lt;- data.frame(from=&amp;quot;Individual dishes&amp;quot;, to=c(&amp;quot;Misc Indiv&amp;quot;, &amp;quot;Noodle dishes&amp;quot;, &amp;quot;Rice dishes&amp;quot;))

d2 &amp;lt;- df %&amp;gt;%
    select(minor_grouping, Thai_name) %&amp;gt;%
    slice(1:53) %&amp;gt;%
    rename(
        from = minor_grouping,
        to = Thai_name
    ) 

edges &amp;lt;- rbind(d1, d2)

# plot dendrogram (idividual dishes)
indiv_dishes_graph &amp;lt;- graph_from_data_frame(edges)

ggraph(indiv_dishes_graph, layout = &amp;quot;dendrogram&amp;quot;, circular = FALSE) +
    geom_edge_diagonal(aes(edge_colour = edges$from), label_dodge = NULL) +
    geom_node_text(aes(label = name, filter = leaf, color = &#39;red&#39;), hjust = 1.1, size = 3) +
    geom_node_point(color = &amp;quot;whitesmoke&amp;quot;) +
    theme(
        plot.background = element_rect(fill = &#39;#343d46&#39;),
        panel.background = element_rect(fill = &#39;#343d46&#39;),
        legend.position = &#39;none&#39;,
        plot.title = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;, size = 25),
        plot.subtitle = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;),
        plot.caption = element_text(color = &#39;whitesmoke&#39;, face = &#39;italic&#39;)
    ) +
    labs(
        title = &#39;52 Alternatives to Pad Thai&#39;,
        subtitle = &#39;Individual Thai Dishes&#39;,
        caption = &#39;Data: Wikipedia | Graphic: @paulapivat&#39;
    ) +
    expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +
    coord_flip() +
    annotate(&amp;quot;text&amp;quot;, x = 47, y = 1, label = &amp;quot;Miscellaneous (7)&amp;quot;, color = &amp;quot;#7CAE00&amp;quot;)+
    annotate(&amp;quot;text&amp;quot;, x = 31, y = 1, label = &amp;quot;Noodle Dishes (24)&amp;quot;, color = &amp;quot;#00C08B&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 8, y = 1, label = &amp;quot;Rice Dishes (22)&amp;quot;, color = &amp;quot;#C77CFF&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 26, y = 2, label = &amp;quot;Individual\nDishes&amp;quot;, color = &amp;quot;#F8766D&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;what-is-the-best-way-to-organized-the-different-dishes&#34;&gt;What is the best way to organized the different dishes?&lt;/h4&gt;
&lt;p&gt;There are approximately &lt;strong&gt;4X&lt;/strong&gt; as many &lt;em&gt;shared&lt;/em&gt; dishes as individual dishes, so the dendrogram should be &lt;strong&gt;circular&lt;/strong&gt; to fit the names of all dishes in one graphic.&lt;/p&gt;
&lt;p&gt;A wonderful resource I use regularly for these types of visuals is the 
&lt;a href=&#34;https://www.r-graph-gallery.com/339-circular-dendrogram-with-ggraph.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R Graph Gallery&lt;/a&gt;. There was a slight issue in how the &lt;strong&gt;text angles&lt;/strong&gt; were calculated so I submitted a 
&lt;a href=&#34;https://github.com/holtzy/R-graph-gallery/pull/34&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PR to fix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Perhaps distinguishing between individual and shared dishes is too crude, within the dendrogram for 201 shared Thai dishes, we can see further sub-groupings including Curries, Sauces/Pastes, Steamed, Grilled, Deep-Fried, Fried &amp;amp; Stir-Fried, Salads, Soups and other Misc:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./shared_dishes_final.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Shared Dishes ----
df %&amp;gt;%
    select(major_grouping, minor_grouping, Thai_name, Thai_script) %&amp;gt;%
    filter(major_grouping == &#39;Shared dishes&#39;) %&amp;gt;%
    group_by(minor_grouping) %&amp;gt;%
    count() %&amp;gt;%
    arrange(desc(n))

d3 &amp;lt;- data.frame(from=&amp;quot;Shared dishes&amp;quot;, to=c(&amp;quot;Curries&amp;quot;, &amp;quot;Soups&amp;quot;, &amp;quot;Salads&amp;quot;,
                                            &amp;quot;Fried and stir-fried dishes&amp;quot;, &amp;quot;Deep-fried dishes&amp;quot;, &amp;quot;Grilled dishes&amp;quot;,
                                            &amp;quot;Steamed or blanched dishes&amp;quot;, &amp;quot;Stewed dishes&amp;quot;, &amp;quot;Dipping sauces and pastes&amp;quot;, &amp;quot;Misc Shared&amp;quot;))


d4 &amp;lt;- df %&amp;gt;%
    select(minor_grouping, Thai_name) %&amp;gt;%
    slice(54:254) %&amp;gt;%
    rename(
        from = minor_grouping,
        to = Thai_name
    )

edges2 &amp;lt;- rbind(d3, d4)

# create a vertices data.frame. One line per object of hierarchy
vertices = data.frame(
    name = unique(c(as.character(edges2$from), as.character(edges2$to)))
)

# add column with group of each name. Useful to later color points
vertices$group = edges2$from[ match(vertices$name, edges2$to)]

# Add information concerning the label we are going to add: angle, horizontal adjustment and potential flip
# calculate the ANGLE of the labels
vertices$id=NA
myleaves=which(is.na(match(vertices$name, edges2$from)))
nleaves=length(myleaves)
vertices$id[myleaves] = seq(1:nleaves)
vertices$angle = 360 / nleaves * vertices$id + 90    


# calculate the alignment of labels: right or left
vertices$hjust&amp;lt;-ifelse( vertices$angle &amp;lt; 275, 1, 0)



# flip angle BY to make them readable
vertices$angle&amp;lt;-ifelse(vertices$angle &amp;lt; 275, vertices$angle+180, vertices$angle)

# plot dendrogram (shared dishes)
shared_dishes_graph &amp;lt;- graph_from_data_frame(edges2)

ggraph(shared_dishes_graph, layout = &amp;quot;dendrogram&amp;quot;, circular = TRUE) +
    geom_edge_diagonal(aes(edge_colour = edges2$from), label_dodge = NULL) +
    geom_node_text(aes(x = x*1.15, y=y*1.15, filter = leaf, label=name, angle = vertices$angle, hjust= vertices$hjust, colour= vertices$group), size=2.7, alpha=1) +
    geom_node_point(color = &amp;quot;whitesmoke&amp;quot;) +
    theme(
        plot.background = element_rect(fill = &#39;#343d46&#39;),
        panel.background = element_rect(fill = &#39;#343d46&#39;),
        legend.position = &#39;none&#39;,
        plot.title = element_text(colour = &#39;whitesmoke&#39;, face = &#39;bold&#39;, size = 25),
        plot.subtitle = element_text(colour = &#39;whitesmoke&#39;, margin = margin(0,0,30,0), size = 20),
        plot.caption = element_text(color = &#39;whitesmoke&#39;, face = &#39;italic&#39;)
    ) +
    labs(
        title = &#39;Thai Food is Best Shared&#39;,
        subtitle = &#39;201 Ways to Make Friends&#39;,
        caption = &#39;Data: Wikipedia | Graphic: @paulapivat&#39;
    ) +
    #expand_limits(x = c(-1.5, 1.5), y = c(-0.8, 0.8)) +
    expand_limits(x = c(-1.5, 1.5), y = c(-1.5, 1.5)) +
    coord_flip() +
    annotate(&amp;quot;text&amp;quot;, x = 0.4, y = 0.45, label = &amp;quot;Steamed&amp;quot;, color = &amp;quot;#F564E3&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.2, y = 0.5, label = &amp;quot;Grilled&amp;quot;, color = &amp;quot;#00BA38&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.2, y = 0.5, label = &amp;quot;Deep-Fried&amp;quot;, color = &amp;quot;#DE8C00&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.4, y = 0.1, label = &amp;quot;Fried &amp;amp;\n Stir-Fried&amp;quot;, color = &amp;quot;#7CAE00&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.3, y = -0.4, label = &amp;quot;Salads&amp;quot;, color = &amp;quot;#00B4F0&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = -0.05, y = -0.5, label = &amp;quot;Soups&amp;quot;, color = &amp;quot;#C77CFF&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.3, y = -0.5, label = &amp;quot;Curries&amp;quot;, color = &amp;quot;#F8766D&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.5, y = -0.1, label = &amp;quot;Misc&amp;quot;, color = &amp;quot;#00BFC4&amp;quot;) +
    annotate(&amp;quot;text&amp;quot;, x = 0.5, y = 0.1, label = &amp;quot;Sauces\nPastes&amp;quot;, color = &amp;quot;#B79F00&amp;quot;)
    
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;text_mining&#34;&gt;Text_Mining&lt;/h3&gt;
&lt;h4 id=&#34;which-raw-materials-are-most-popular&#34;&gt;Which raw material(s) are most popular?&lt;/h4&gt;
&lt;p&gt;One way to answer this question is to use text mining to &lt;strong&gt;tokenize&lt;/strong&gt; by either word and count the words by frequency as one measure of popularity.&lt;/p&gt;
&lt;p&gt;In the below bar chart, we see frequency of words across all Thai Dishes. &lt;strong&gt;Mu&lt;/strong&gt; (หมู) which means pork in Thai appears most frequently across all dish types and sub-grouping. Next we have &lt;strong&gt;kaeng&lt;/strong&gt; (แกง) which means curry. &lt;strong&gt;Phat&lt;/strong&gt; (ผัด) comings in third suggesting &amp;ldquo;stir-fry&amp;rdquo; is a popular cooking mode.&lt;/p&gt;
&lt;p&gt;As we can see &lt;strong&gt;not&lt;/strong&gt; all words refer to raw materials, so we may not be able to answer this question directly.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./word_freq_barchart.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;library(tidytext)
library(scales)

# new csv file after data cleaning (see above)
df &amp;lt;- read_csv(&amp;quot;../web_scraping/edit_thai_dishes.csv&amp;quot;)

df %&amp;gt;%
    select(Thai_name, Thai_script) %&amp;gt;%
    # can substitute &#39;word&#39; for ngrams, sentences, lines
    unnest_tokens(ngrams, Thai_name) %&amp;gt;%  
    # to reference thai spelling: group_by(Thai_script)
    group_by(ngrams) %&amp;gt;%  
    tally(sort = TRUE) %&amp;gt;%  # alt: count(sort = TRUE)
    filter(n &amp;gt; 9) %&amp;gt;%
# visualize
# pipe directly into ggplot2, because using tidytools
    ggplot(aes(x = n, y = reorder(ngrams, n))) + 
    geom_col(aes(fill = ngrams)) +
    scale_fill_manual(values = c(
        &amp;quot;#c3d66b&amp;quot;,
        &amp;quot;#70290a&amp;quot;,
        &amp;quot;#2f1c0b&amp;quot;,
        &amp;quot;#ba9d8f&amp;quot;,
        &amp;quot;#dda37b&amp;quot;,
        &amp;quot;#8f5e23&amp;quot;,
        &amp;quot;#96b224&amp;quot;,
        &amp;quot;#dbcac9&amp;quot;,
        &amp;quot;#626817&amp;quot;,
        &amp;quot;#a67e5f&amp;quot;,
        &amp;quot;#be7825&amp;quot;,
        &amp;quot;#446206&amp;quot;,
        &amp;quot;#c8910b&amp;quot;,
        &amp;quot;#88821b&amp;quot;,
        &amp;quot;#313d5f&amp;quot;,
        &amp;quot;#73869a&amp;quot;,
        &amp;quot;#6f370f&amp;quot;,
        &amp;quot;#c0580d&amp;quot;,
        &amp;quot;#e0d639&amp;quot;,
        &amp;quot;#c9d0ce&amp;quot;,
        &amp;quot;#ebf1f0&amp;quot;,
        &amp;quot;#50607b&amp;quot;
    )) +
    theme_minimal() +
    theme(legend.position = &amp;quot;none&amp;quot;) +
    labs(
        x = &amp;quot;Frequency&amp;quot;,
        y = &amp;quot;Words&amp;quot;,
        title = &amp;quot;Frequency of Words in Thai Cuisine&amp;quot;,
        subtitle = &amp;quot;Words appearing at least 10 times in Individual or Shared Dishes&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphic: @paulapivat&amp;quot;
    )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also see words common to both Individual and Shared Dishes. We see other words like &lt;strong&gt;nuea&lt;/strong&gt; (beef), &lt;strong&gt;phrik&lt;/strong&gt; (chili) and &lt;strong&gt;kaphrao&lt;/strong&gt; (basil leaves).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./word_freq_indiv_shared_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# frequency for Thai_dishes (Major Grouping) ----

# comparing Individual and Shared Dishes (Major Grouping)
thai_name_freq &amp;lt;- df %&amp;gt;%
    select(Thai_name, Thai_script, major_grouping) %&amp;gt;%
    unnest_tokens(ngrams, Thai_name) %&amp;gt;% 
    count(ngrams, major_grouping) %&amp;gt;%
    group_by(major_grouping) %&amp;gt;%
    mutate(proportion = n / sum(n)) %&amp;gt;%
    select(major_grouping, ngrams, proportion) %&amp;gt;%
    spread(major_grouping, proportion) %&amp;gt;%
    gather(major_grouping, proportion, c(`Shared dishes`)) %&amp;gt;%
    select(ngrams, `Individual dishes`, major_grouping, proportion)


# Expect warming message about missing values
ggplot(thai_name_freq, aes(x = proportion, y = `Individual dishes`,
       color = abs(`Individual dishes` - proportion))) +
    geom_abline(color = &#39;gray40&#39;, lty = 2) +
    geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
    geom_text(aes(label = ngrams), check_overlap = TRUE, vjust = 1.5) +
    scale_x_log10(labels = percent_format()) +
    scale_y_log10(labels = percent_format()) +
    scale_color_gradient(limits = c(0, 0.01), 
                         low = &amp;quot;red&amp;quot;, high = &amp;quot;blue&amp;quot;) +    # low = &amp;quot;darkslategray4&amp;quot;, high = &amp;quot;gray75&amp;quot;
    theme_minimal() +
    theme(legend.position = &amp;quot;none&amp;quot;,
          legend.text = element_text(angle = 45, hjust = 1)) +
    labs(y = &amp;quot;Individual Dishes&amp;quot;,
         x = &amp;quot;Shared Dishes&amp;quot;,
         color = NULL,
         title = &amp;quot;Comparing Word Frequencies in the names Thai Dishes&amp;quot;,
         subtitle = &amp;quot;Individual and Shared Dishes&amp;quot;,
         caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;which-raw-materials-are-most-important&#34;&gt;Which raw materials are most important?&lt;/h4&gt;
&lt;p&gt;We can only learn so much from frequency, so text mining practitioners have created &lt;strong&gt;term frequency - inverse document frequency&lt;/strong&gt; to better reflect how important a word is in a document or corpus (further details 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Again, the words don&amp;rsquo;t necessarily refer to raw materials, so this question can&amp;rsquo;t be fully answered directly here.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./td_idf_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;could-you-learn-about-thai-food-just-from-the-names-of-the-dishes&#34;&gt;Could you learn about Thai food just from the names of the dishes?&lt;/h4&gt;
&lt;p&gt;The short answer is &amp;ldquo;yes&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;We learned just from frequency and &amp;ldquo;term frequency - inverse document frequency&amp;rdquo; not only the most frequent words, but the relative importance within the current set of words that we have tokenized with &lt;code&gt;tidytext&lt;/code&gt;. This informs us of not only popular raw materials (Pork), but also dish types (Curries) and other popular mode of preparation (Stir-Fry).&lt;/p&gt;
&lt;p&gt;We can even examine the &lt;strong&gt;network of relationships&lt;/strong&gt; between words. Darker arrows suggest a stronger relationship between pairs of words, for example &amp;ldquo;nam phrik&amp;rdquo; is a strong pairing. This means &amp;ldquo;chili sauce&amp;rdquo; in Thai and suggests the important role that it plays across many types of dishes.&lt;/p&gt;
&lt;p&gt;We learned above that &amp;ldquo;mu&amp;rdquo; (pork) appears frequently. Now we see that &amp;ldquo;mu&amp;rdquo; and &amp;ldquo;krop&amp;rdquo; are more related than other pairings (note: &amp;ldquo;mu krop&amp;rdquo; means &amp;ldquo;crispy pork&amp;rdquo;). We also saw above that &amp;ldquo;khao&amp;rdquo; appears frequently in Rice dishes. This alone is not surprising as &amp;ldquo;khao&amp;rdquo; means rice in Thai, but we see here &amp;ldquo;khao phat&amp;rdquo; is strongly related suggesting that fried rice (&amp;ldquo;khao phat&amp;rdquo;) is quite popular.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./network_thai_dishes.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Visualizing a network of Bi-grams with {ggraph} ----
library(igraph)
library(ggraph)
set.seed(2021)

thai_dish_bigram_counts &amp;lt;- df %&amp;gt;%
    select(Thai_name, minor_grouping) %&amp;gt;%
    unnest_tokens(bigram, Thai_name, token = &amp;quot;ngrams&amp;quot;, n = 2) %&amp;gt;%
    separate(bigram, c(&amp;quot;word1&amp;quot;, &amp;quot;word2&amp;quot;), sep = &amp;quot; &amp;quot;) %&amp;gt;%
    count(word1, word2, sort = TRUE)


# filter for relatively common combinations (n &amp;gt; 2)
thai_dish_bigram_graph &amp;lt;- thai_dish_bigram_counts %&amp;gt;%
    filter(n &amp;gt; 2) %&amp;gt;%
    graph_from_data_frame()


# polishing operations to make a better looking graph
a &amp;lt;- grid::arrow(type = &amp;quot;closed&amp;quot;, length = unit(.15, &amp;quot;inches&amp;quot;))

set.seed(2021)
ggraph(thai_dish_bigram_graph, layout = &amp;quot;fr&amp;quot;) +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                   arrow = a, end_cap = circle(.07, &#39;inches&#39;)) +
    geom_node_point(color = &amp;quot;dodgerblue&amp;quot;, size = 5, alpha = 0.7) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    labs(
        title = &amp;quot;Network of Relations between Word Pairs&amp;quot;,
        subtitle = &amp;quot;{ggraph}: common nodes in Thai food&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;
    ) +
    theme_void()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we may be interested in word relationships &lt;em&gt;within&lt;/em&gt; individual dishes.&lt;/p&gt;
&lt;p&gt;The below graph shows a network of word pairs with moderate-to-high correlations. We can see certain words clustered near each other with relatively dark lines: kaeng (curry), pet (spicy), wan (sweet), khiao (green curry), phrik (chili) and mu (pork). These words represent a collection of ingredient, mode of cooking and description that are generally combined.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./indiv_dish_corr.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;set.seed(2021)

# Individual Dishes
individual_dish_words &amp;lt;- df %&amp;gt;%
    select(major_grouping, Thai_name) %&amp;gt;%
    filter(major_grouping == &#39;Individual dishes&#39;) %&amp;gt;%
    mutate(section = row_number() %/% 10) %&amp;gt;%
    filter(section &amp;gt; 0) %&amp;gt;%
    unnest_tokens(word, Thai_name)  # assume no stop words

individual_dish_cors &amp;lt;- individual_dish_words %&amp;gt;%
    group_by(word) %&amp;gt;% 
    filter(n() &amp;gt;= 2) %&amp;gt;%     # looking for co-occuring words, so must be 2 or greater
    pairwise_cor(word, section, sort = TRUE) 


individual_dish_cors %&amp;gt;%
    filter(correlation &amp;lt; -0.40) %&amp;gt;%
    graph_from_data_frame() %&amp;gt;%
    ggraph(layout = &amp;quot;fr&amp;quot;) +
    geom_edge_link(aes(edge_alpha = correlation, size = correlation), show.legend = TRUE) +
    geom_node_point(color = &amp;quot;green&amp;quot;, size = 5, alpha = 0.5) +
    geom_node_text(aes(label = name), repel = TRUE) +
    labs(
        title = &amp;quot;Word Pairs in Individual Dishes&amp;quot;,
        subtitle = &amp;quot;{ggraph}: Negatively correlated (r = -0.4)&amp;quot;,
        caption = &amp;quot;Data: Wikipedia | Graphics: @paulapivat&amp;quot;
    ) +
    theme_void()
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;
&lt;p&gt;We have completed an exploratory data project where we scraped, clean, manipulated and visualized data using a combination of Python and R. We also used the &lt;code&gt;tidytext&lt;/code&gt; package for basic text mining task to see if we could gain some insights into Thai cuisine using  words from dish names scraped off Wikipedia.&lt;/p&gt;
&lt;p&gt;For more content on data science, R, Python, SQL and more, 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
