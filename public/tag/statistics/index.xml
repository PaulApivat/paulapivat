<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics | Paul Apivat</title>
    <link>/tag/statistics/</link>
      <atom:link href="/tag/statistics/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020 Paul Apivat Hanvongse. All Rights Reserved.</copyright><lastBuildDate>Sun, 22 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Statistics</title>
      <link>/tag/statistics/</link>
    </image>
    
    <item>
      <title>Data Science from Scratch (ch6) - Probability</title>
      <link>/post/dsfs_6/</link>
      <pubDate>Sun, 22 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/post/dsfs_6/</guid>
      <description>&lt;h3 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;#challenge&#34;&gt;Challenge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#marginal_and_joint_probabilities&#34;&gt;Marginal and Joint Probability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#conditional_probability&#34;&gt;Conditional Probability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;#bayes_theorem&#34;&gt;Bayes&amp;rsquo; Theorem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;h2 id=&#34;challenge&#34;&gt;Challenge&lt;/h2&gt;
&lt;p&gt;The first challenge in this section is distinguishing between &lt;strong&gt;two&lt;/strong&gt; conditional probability statements.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the setup. We have a family with two (unknown) children with two assumptions. First, each child is equally likely to be a boy or a girl. Second, the gender of the second child is &lt;em&gt;independent&lt;/em&gt; of the gender of the first child.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Challenge 1: What is the probability of the event &amp;ldquo;both children are girls&amp;rdquo; (B) conditional on the event &amp;ldquo;the older child is a girl&amp;rdquo; (G)?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The probability for statement one is roughly 50% or (1/2).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Challenge 2: What is the probability of the event &amp;ldquo;both children are girls&amp;rdquo; (B) conditional on the event &amp;ldquo;at least one of the children is a girl&amp;rdquo; (L)?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The probability for statement two is roughly 33% or (1/3).&lt;/p&gt;
&lt;p&gt;But at first glance, they look similar.&lt;/p&gt;
&lt;h2 id=&#34;marginal_and_joint_probabilities&#34;&gt;Marginal_and_Joint_Probabilities&lt;/h2&gt;
&lt;p&gt;The book jumps straight to conditional probabilities, but first, we&amp;rsquo;ll have to look at &lt;strong&gt;marginal&lt;/strong&gt; and &lt;strong&gt;joint&lt;/strong&gt; probabilities. Then we&amp;rsquo;ll create a &lt;strong&gt;joint probabilities table&lt;/strong&gt; and &lt;strong&gt;sum&lt;/strong&gt; probabilities to help us figure out the differences. We&amp;rsquo;ll then &lt;em&gt;resume&lt;/em&gt; with &lt;strong&gt;conditional probabilities&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Before anything, we need to realize the situation we have is one of &lt;strong&gt;independence&lt;/strong&gt;. The gender of one child is &lt;strong&gt;independent&lt;/strong&gt; of a second child.&lt;/p&gt;
&lt;p&gt;The intuition for this scenario will be different from a &lt;strong&gt;dependent&lt;/strong&gt; situation. For example, if we draw two cards from a deck (without replacement), the probabilities are different. The probability of drawing one King ♠️ is (4/52) and the probability of drawing a second King ♣️ is now (3/51); the probability of the second event (a second King) is &lt;em&gt;dependent&lt;/em&gt; on the result of the first draw.&lt;/p&gt;
&lt;p&gt;Ok back to the two unknown children.&lt;/p&gt;
&lt;p&gt;We can say the probability of the first child being either a boy or a girl is 50/50. Moreover, the probability of the second child, which is &lt;strong&gt;independent&lt;/strong&gt; of the first, is &lt;em&gt;also&lt;/em&gt; 50/50. Remember, our first assumption is that &lt;em&gt;each child is equally likely to be a boy or a girl&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s put these numbers in a table. The (1/2) probabilities shown here are called &lt;strong&gt;marginal&lt;/strong&gt; probabilities (note how they&amp;rsquo;re at the margins of the table).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./marginal.png&#34; alt=&#34;marginal&#34;&gt;&lt;/p&gt;
&lt;p&gt;Since we have two gender (much like two sides of a flipped coin), we can intuitively figure out &lt;em&gt;all&lt;/em&gt; possible outcomes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;first child (Boy), second child (Boy)&lt;/li&gt;
&lt;li&gt;first child (Boy), second child (Girl)&lt;/li&gt;
&lt;li&gt;first child (Girl), second child (Boy)&lt;/li&gt;
&lt;li&gt;first child (Girl), second child (Girl)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There are &lt;em&gt;4 possible outcomes&lt;/em&gt; so the probability of getting any one of the four outcomes is (1/4). We can actually write these probabilities in the middle of the table, the &lt;strong&gt;joint probabilities&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./joint.png&#34; alt=&#34;joint&#34;&gt;&lt;/p&gt;
&lt;p&gt;To recap, the probability of the first child being either boy or girl is 50/50, simple enough. The probability of the second child being either boy or girl is also 50/50. When put in a table, this yielded the &lt;strong&gt;marginal probability&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now we want to know the probability of say, &amp;lsquo;first child being a boy and second child being a girl&amp;rsquo;. This is a &lt;strong&gt;joint probability&lt;/strong&gt; because is is the probability that the first child take a specific gender (boy) &lt;strong&gt;AND&lt;/strong&gt; the second child take a specific gender (girl).&lt;/p&gt;
&lt;p&gt;If two event are &lt;strong&gt;independent&lt;/strong&gt;, and in this case they are, their &lt;strong&gt;joint probabilities&lt;/strong&gt; are the &lt;em&gt;product&lt;/em&gt; of the probabilities of &lt;strong&gt;each one happening&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The probability of the first child being a Boy (1/2) &lt;strong&gt;and&lt;/strong&gt; second child being a Girl (1/2); The product of each marginal probability is the joint probability (1/2 * 1/2 = 1/4).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./product_marginal.png&#34; alt=&#34;product_marginal&#34;&gt;&lt;/p&gt;
&lt;p&gt;This can be repeated for the other three joint probabilities.&lt;/p&gt;
&lt;h2 id=&#34;conditional_probability&#34;&gt;Conditional_Probability&lt;/h2&gt;
&lt;p&gt;Now we get into &lt;strong&gt;conditional probability&lt;/strong&gt; which is the probability of one event happening (i.e., second child being a Boy or Girl) &lt;strong&gt;given that&lt;/strong&gt; or &lt;strong&gt;on conditional that&lt;/strong&gt; another event happened (i.e., first child being a Boy).&lt;/p&gt;
&lt;p&gt;At this point, it might be a good idea to get familiar with notation.&lt;/p&gt;
&lt;p&gt;A joint probability is the product of each individual event happening (assuming they are independent events). For example we might have two individual events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Boy): 1/2&lt;/li&gt;
&lt;li&gt;P(2nd Child = Boy): 1/2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is their &lt;strong&gt;joint probability&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Boy, 2nd Child = Boy) =&amp;gt;&lt;/li&gt;
&lt;li&gt;P(1st Child = Boy) * P(2nd Child = Boy) =&amp;gt;&lt;/li&gt;
&lt;li&gt;(1/2 * 1/2 = 1/4)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is a relationship between &lt;strong&gt;conditional&lt;/strong&gt; probabilities and &lt;strong&gt;joint&lt;/strong&gt; probabilities.&lt;/p&gt;
&lt;p&gt;Here is their &lt;strong&gt;conditional probability&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(2nd Child = Boy | 1st Child = Boy) =&amp;gt;&lt;/li&gt;
&lt;li&gt;P(1st Child = Boy, 2nd Child = Boy) / P(1st Child = Boy)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thie works out to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1/4) / (1/2) = 1/2
or&lt;/li&gt;
&lt;li&gt;(1/4) * (2/1) = 1/2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, the probability that the second child is a boy, given that the first child is a boy is still 50% (this implies that with respect to &lt;strong&gt;conditional&lt;/strong&gt; probability, if the events are &lt;strong&gt;independent&lt;/strong&gt; it is not different from a single event).&lt;/p&gt;
&lt;p&gt;Now we&amp;rsquo;re ready to tackle the two challenges posed at the beginning of this post.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Challenge 1: What is the probability of the event &amp;ldquo;both children are girls&amp;rdquo; (B) conditional on the event &amp;ldquo;the older child is a girl&amp;rdquo; (G)?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s break it down. First we want the probability of the event that &amp;ldquo;both children are girls&amp;rdquo;. We&amp;rsquo;ll take the product of two events; the probability that the first child is a girl (1/2) and the probability that the second child is a girl (1/2). So for &lt;strong&gt;both&lt;/strong&gt; child to be girls, 1/2 * 1/2 = 1/4&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Girl, 2nd Child = Girl) = 1/4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Second, we want that to be &lt;strong&gt;given that&lt;/strong&gt; the &amp;ldquo;older child is a girl&amp;rdquo;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Girl) = 1/2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Conditional probability&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Girl, 2nd Child = Girl) / P(1st Child = Girl)&lt;/li&gt;
&lt;li&gt;(1/4) / (1/2) = &lt;strong&gt;1/2&lt;/strong&gt; or roughly &lt;strong&gt;50%&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let&amp;rsquo;s break down the second challenge:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Challenge 2: What is the probability of the event &amp;ldquo;both children are girls&amp;rdquo; (B) conditional on the event &amp;ldquo;at least one of the children is a girl&amp;rdquo; (L)?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Again, we start with &amp;ldquo;both children are girls&amp;rdquo;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Girl, 2nd Child = Girl) = 1/4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, we have &amp;ldquo;on condition that at least one of the children is a girl&amp;rdquo;. We&amp;rsquo;ll reference a &lt;strong&gt;joint probability table&lt;/strong&gt;. We see that when trying to figure out the probability that &amp;ldquo;at least one of the children is a girl&amp;rdquo;, we rule out the scenario where &lt;strong&gt;both&lt;/strong&gt; children are boys. The remaining 3 out of 4 probabilities, fit the condition.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./at_least.png&#34; alt=&#34;at least&#34;&gt;&lt;/p&gt;
&lt;p&gt;The probability of at least one children being a girl is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(1/4) + (1/4) + (1/4) = 3/4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(1st Child = Girl, 2nd Child = Girl) / P(&amp;ldquo;at least one child is a girl&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;(1/4) / (3/4) = (1/4) * (4/3) = &lt;strong&gt;1/3&lt;/strong&gt; or roughly &lt;strong&gt;33%&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;key-take-away&#34;&gt;Key Take-away&lt;/h4&gt;
&lt;p&gt;When two events are &lt;strong&gt;independent&lt;/strong&gt;, their &lt;strong&gt;joint probability&lt;/strong&gt; is the product of each event:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(E,F) = P(E) * P(F)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Their &lt;strong&gt;conditional&lt;/strong&gt; probability is the &lt;strong&gt;joint probability&lt;/strong&gt; divided by the conditional (i.e., P(F)).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(E|F) = P(E,F) / P(F)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And so for our two challenge scenarios, we have:&lt;/p&gt;
&lt;p&gt;Challenge 1:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B = probability that both children are girls&lt;/li&gt;
&lt;li&gt;G = probability that the &lt;em&gt;older&lt;/em&gt; children is a girl&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This can be stated as: P(B|G) = P(B,G) / P(G)&lt;/p&gt;
&lt;p&gt;Challenge 2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B = probability that both children are girls&lt;/li&gt;
&lt;li&gt;L = probability that &lt;em&gt;at least one&lt;/em&gt; children is a girl&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This can be stated as: P(B|L) = P(B,L) / P(L)&lt;/p&gt;
&lt;h4 id=&#34;python-code&#34;&gt;Python Code&lt;/h4&gt;
&lt;p&gt;Now that we have an intuition and have worked out the problem on paper, we can use code to express conditional probability:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import enum, random
class Kid(enum.Enum):
    BOY = 0
    GIRL = 1
    
def random_kid() -&amp;gt; Kid:
    return random.choice([Kid.BOY, Kid.GIRL])
    
both_girls = 0
older_girl = 0
either_girl = 0

random.seed(0)
for _ in range(10000):
    younger = random_kid()
    older = random_kid()
    if older == Kid.GIRL:
        older_girl += 1
    if older == Kid.GIRL and younger == Kid.GIRL:
        both_girls += 1
    if older == Kid.GIRL or younger == Kid.GIRL:
        either_girl += 1
        
print(&amp;quot;P(both | older):&amp;quot;, both_girls / older_girl)   # 0.5007089325501317
print(&amp;quot;P(both | either):&amp;quot;, both_girls / either_girl) # 0.3311897106109325
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that code confirms our intuition.&lt;/p&gt;
&lt;p&gt;We use a &lt;code&gt;for-loop&lt;/code&gt; and &lt;code&gt;range(10000)&lt;/code&gt; to randomly simulate 10,000 scenarios. The &lt;code&gt;random_kid&lt;/code&gt; function randomly picks either a boy or girl (assumption #1). We set the following variables to start a 0, &lt;code&gt;both_girls&lt;/code&gt; (both children are girls); &lt;code&gt;older_girl&lt;/code&gt; (first child is a girl); and &lt;code&gt;either_girl&lt;/code&gt; (at least one child is a girl).&lt;/p&gt;
&lt;p&gt;Then, each of these variables are incremented by 1 through each of the 10,000 loops if it meets certain conditions. After we finish looping, we can call on each of the three variables to see if they match our calculations above:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;either_girl #7,464 / 10,000 ~ roughly 75% or 3/4 probability that there is at least one girl
both_girls  #2,472 / 10,000 ~ roughly 25% or 1/4 probability that both children are girls
older_girl  #4,937 / 10,000 ~ roughly 50% or 1/2 probability that the first child is a girl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will look at Bayes Theorem next.&lt;/p&gt;
&lt;h2 id=&#34;bayes_theorem&#34;&gt;Bayes_Theorem&lt;/h2&gt;
&lt;p&gt;For more content on data science, machine learning, R, Python, SQL and more, 
&lt;a href=&#34;https://twitter.com/paulapivat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;find me on Twitter&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Going beyond summary statistics</title>
      <link>/post/datasaurus/</link>
      <pubDate>Mon, 16 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/post/datasaurus/</guid>
      <description>


&lt;div id=&#34;datasaurus-introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Datasaurus Introduction&lt;/h2&gt;
&lt;p&gt;I recently came across the &lt;strong&gt;Datasaurus&lt;/strong&gt; dataset by Alberto Cairo on &lt;a href=&#34;https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-10-13/readme.md&#34;&gt;#TidyTuesday&lt;/a&gt; and wanted to create a series of charts illustrating the lessons associated with this dataset, primarily to: &lt;a href=&#34;http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html&#34;&gt;never trust summary statistics alone&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, some context. Here’s Alberto’s &lt;a href=&#34;https://twitter.com/albertocairo/status/765167969139765250&#34;&gt;original tweet&lt;/a&gt; from years ago when he created this dataset:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;png/alberto_cairo.png&#34; alt=&#34;png&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;png&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This tweet alone doesn’t communicate why we shouldn’t trust summary statistics alone, so let’s unpack this. First we’ll load the various packages and data we’ll use.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;load-packages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load Packages&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Attaching packages ─────────────────────────── tidyverse 1.3.0 ──&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
## ✓ tibble  3.0.3     ✓ dplyr   1.0.1
## ✓ tidyr   1.1.1     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.5.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Conflicts ────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggcorrplot)
library(ggridges)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;load-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Load Data&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt; : &lt;code&gt;datasaurus&lt;/code&gt; and &lt;code&gt;datasaurus_dozen&lt;/code&gt; are identical. The former is provided via #TidyTuesday, the latter from &lt;a href=&#34;https://www.autodesk.com/research/publications/same-stats-different-graphs&#34;&gt;this research paper&lt;/a&gt; discussing more advanced concepts beyond the scope of this document (i.e., simulated annealing).&lt;/p&gt;
&lt;p&gt;You’ll also note that &lt;code&gt;datasaurus_dozen&lt;/code&gt; and &lt;code&gt;datasaurus_wide&lt;/code&gt; are the same data, organized differently. The former in &lt;em&gt;long&lt;/em&gt; format and the latter, in &lt;em&gt;wide&lt;/em&gt; format - see here for &lt;a href=&#34;http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/&#34;&gt;details&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the most part, we’ll use &lt;code&gt;datasaurus_dozen&lt;/code&gt; throughout this document. We’ll use &lt;code&gt;datasaurus_wide&lt;/code&gt; when we get to the correlation section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus &amp;lt;- readr::read_csv(&amp;#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-13/datasaurus.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   dataset = col_character(),
##   x = col_double(),
##   y = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen &amp;lt;- read_tsv(&amp;#39;./data/DatasaurusDozen.tsv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   dataset = col_character(),
##   x = col_double(),
##   y = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_wide &amp;lt;- read_tsv(&amp;#39;./data/DatasaurusDozen-wide.tsv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Duplicated column names deduplicated: &amp;#39;away&amp;#39; =&amp;gt; &amp;#39;away_1&amp;#39; [2],
## &amp;#39;bullseye&amp;#39; =&amp;gt; &amp;#39;bullseye_1&amp;#39; [4], &amp;#39;circle&amp;#39; =&amp;gt; &amp;#39;circle_1&amp;#39; [6], &amp;#39;dino&amp;#39; =&amp;gt;
## &amp;#39;dino_1&amp;#39; [8], &amp;#39;dots&amp;#39; =&amp;gt; &amp;#39;dots_1&amp;#39; [10], &amp;#39;h_lines&amp;#39; =&amp;gt; &amp;#39;h_lines_1&amp;#39; [12],
## &amp;#39;high_lines&amp;#39; =&amp;gt; &amp;#39;high_lines_1&amp;#39; [14], &amp;#39;slant_down&amp;#39; =&amp;gt; &amp;#39;slant_down_1&amp;#39; [16],
## &amp;#39;slant_up&amp;#39; =&amp;gt; &amp;#39;slant_up_1&amp;#39; [18], &amp;#39;star&amp;#39; =&amp;gt; &amp;#39;star_1&amp;#39; [20], &amp;#39;v_lines&amp;#39;
## =&amp;gt; &amp;#39;v_lines_1&amp;#39; [22], &amp;#39;wide_lines&amp;#39; =&amp;gt; &amp;#39;wide_lines_1&amp;#39; [24], &amp;#39;x_shape&amp;#39; =&amp;gt;
## &amp;#39;x_shape_1&amp;#39; [26]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   .default = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## See spec(...) for full column specifications.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;eyeballing-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Eyeballing the data&lt;/h2&gt;
&lt;p&gt;Here are the first six rows of &lt;code&gt;datasaurus_dozen&lt;/code&gt; (long):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   dataset     x     y
##   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 dino     55.4  97.2
## 2 dino     51.5  96.0
## 3 dino     46.2  94.5
## 4 dino     42.8  91.4
## 5 dino     40.8  88.3
## 6 dino     38.7  84.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the first six rows of &lt;code&gt;datasaurus_wide&lt;/code&gt; (wide):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 26
##   away  away_1 bullseye bullseye_1 circle circle_1 dino  dino_1 dots  dots_1
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; 
## 1 x     y      x        y          x      y        x     y      x     y     
## 2 32.3… 61.41… 51.2038… 83.339776… 55.99… 79.2772… 55.3… 97.17… 51.1… 90.86…
## 3 53.4… 26.18… 58.9744… 85.499817… 50.03… 79.0130… 51.5… 96.02… 50.5… 89.10…
## 4 63.9… 30.83… 51.8720… 85.829737… 51.28… 82.4359… 46.1… 94.48… 50.2… 85.46…
## 5 70.2… 82.53… 48.1799… 85.045116… 51.17… 79.1652… 42.8… 91.41… 50.0… 83.05…
## 6 34.1… 45.73… 41.6832… 84.017940… 44.37… 78.1646… 40.7… 88.33… 50.5… 82.93…
## # … with 16 more variables: h_lines &amp;lt;chr&amp;gt;, h_lines_1 &amp;lt;chr&amp;gt;, high_lines &amp;lt;chr&amp;gt;,
## #   high_lines_1 &amp;lt;chr&amp;gt;, slant_down &amp;lt;chr&amp;gt;, slant_down_1 &amp;lt;chr&amp;gt;, slant_up &amp;lt;chr&amp;gt;,
## #   slant_up_1 &amp;lt;chr&amp;gt;, star &amp;lt;chr&amp;gt;, star_1 &amp;lt;chr&amp;gt;, v_lines &amp;lt;chr&amp;gt;, v_lines_1 &amp;lt;chr&amp;gt;,
## #   wide_lines &amp;lt;chr&amp;gt;, wide_lines_1 &amp;lt;chr&amp;gt;, x_shape &amp;lt;chr&amp;gt;, x_shape_1 &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 13 variables, each with X- and Y- axes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-statistics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary Statistics&lt;/h2&gt;
&lt;p&gt;First, we’ll note that if we just look at summary statistics (i.e., &lt;strong&gt;mean&lt;/strong&gt; and &lt;strong&gt;standard deviation&lt;/strong&gt;), we might conclude that these variables are all the &lt;em&gt;same&lt;/em&gt;. Moreover, within each variable, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; values have very &lt;strong&gt;similarly low correlations&lt;/strong&gt; at ranging from -0.06 to -0.07.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    group_by(dataset) %&amp;gt;%
    summarize(
        x_mean = mean(x),
        x_sd = sd(x),
        y_mean = mean(y),
        y_sd = sd(y),
        corr = cor(x,y)
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 13 x 6
##    dataset    x_mean  x_sd y_mean  y_sd    corr
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 away         54.3  16.8   47.8  26.9 -0.0641
##  2 bullseye     54.3  16.8   47.8  26.9 -0.0686
##  3 circle       54.3  16.8   47.8  26.9 -0.0683
##  4 dino         54.3  16.8   47.8  26.9 -0.0645
##  5 dots         54.3  16.8   47.8  26.9 -0.0603
##  6 h_lines      54.3  16.8   47.8  26.9 -0.0617
##  7 high_lines   54.3  16.8   47.8  26.9 -0.0685
##  8 slant_down   54.3  16.8   47.8  26.9 -0.0690
##  9 slant_up     54.3  16.8   47.8  26.9 -0.0686
## 10 star         54.3  16.8   47.8  26.9 -0.0630
## 11 v_lines      54.3  16.8   47.8  26.9 -0.0694
## 12 wide_lines   54.3  16.8   47.8  26.9 -0.0666
## 13 x_shape      54.3  16.8   47.8  26.9 -0.0656&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Boxplots&lt;/h2&gt;
&lt;p&gt;You could use &lt;code&gt;boxplots&lt;/code&gt; to show &lt;em&gt;slight&lt;/em&gt; variation in the distribution and &lt;strong&gt;median&lt;/strong&gt; values of these 13 variables. However, the &lt;strong&gt;mean&lt;/strong&gt; values, indicated with the red circles, are identical.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    ggplot(aes(x = dataset, y = x, fill = dataset)) +
    geom_boxplot(alpha = 0.6) +
    stat_summary(fun = mean, geom = &amp;quot;point&amp;quot;, shape = 20, size = 6, color = &amp;quot;red&amp;quot;, fill = &amp;quot;red&amp;quot;) +
    scale_fill_brewer(palette = &amp;quot;Set3&amp;quot;) +
    theme_classic() +
    theme(legend.position = &amp;#39;none&amp;#39;) +
    labs(
        y = &amp;#39;13 variables&amp;#39;,
        x = &amp;#39;X-values&amp;#39;,
        title = &amp;quot;Boxplots: Slight differences in the distribution and median values (X-axis)&amp;quot;,
        subtitle = &amp;quot;Identical mean values&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in RColorBrewer::brewer.pal(n, pal): n too large, allowed maximum for palette Set3 is 12
## Returning the palette you asked for with that many colors&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/boxplot_x-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here’s the same plot for &lt;code&gt;y&lt;/code&gt; values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    ggplot(aes(x = dataset, y = y, fill = dataset)) +
    geom_boxplot(alpha = 0.6) +
    stat_summary(fun = mean, geom = &amp;quot;point&amp;quot;, shape = 20, size = 6, color = &amp;quot;red&amp;quot;, fill = &amp;quot;red&amp;quot;) +
    scale_fill_brewer(palette = &amp;quot;Paired&amp;quot;) +
    theme_classic() +
    theme(legend.position = &amp;#39;none&amp;#39;) +
    labs(
        y = &amp;#39;13 variables&amp;#39;,
        x = &amp;#39;Y-values&amp;#39;,
        title = &amp;quot;Boxplots: Slight differences in the distribution and median values (Y-axis)&amp;quot;,
        subtitle = &amp;quot;Identical mean values&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in RColorBrewer::brewer.pal(n, pal): n too large, allowed maximum for palette Paired is 12
## Returning the palette you asked for with that many colors&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/boxplot_y-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ridgeline-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ridgeline Plot&lt;/h2&gt;
&lt;p&gt;We can begin to get a sense for how these variables are different if we plot the distribution in different ways. The ridgeline plot begins to reveal aspects of the data that were hidden before.&lt;/p&gt;
&lt;p&gt;We can begin to see that certain variables have markedly different distribution shapes (i.e., &lt;code&gt;v_lines&lt;/code&gt;, &lt;code&gt;dots&lt;/code&gt;, &lt;code&gt;x_shape&lt;/code&gt;, &lt;code&gt;wide_lines&lt;/code&gt;), while having the same &lt;strong&gt;mean&lt;/strong&gt; value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    ggplot(aes(x = x, y = dataset, fill = dataset)) +
    geom_density_ridges_gradient(scale = 3, quantile_lines = T, quantile_fun = mean) +
    scale_fill_manual(values = c(&amp;#39;#a6cee3&amp;#39;, &amp;#39;#1f78b4&amp;#39;, &amp;#39;#b2df8a&amp;#39;, &amp;#39;#33a02c&amp;#39;, &amp;#39;#fb9a99&amp;#39;, &amp;#39;#e31a1c&amp;#39;, &amp;#39;#fdbf6f&amp;#39;, &amp;#39;#ff7f00&amp;#39;, &amp;#39;#cab2d6&amp;#39;, &amp;#39;#6a3d9a&amp;#39;, &amp;#39;#ffff99&amp;#39;, &amp;#39;#b15928&amp;#39;, &amp;#39;grey&amp;#39;)) +
    theme_classic() +
    theme(legend.position = &amp;#39;none&amp;#39;) +
    labs(
        x = &amp;quot;X-values&amp;quot;,
        y = &amp;quot;13 variables&amp;quot;,
        title = &amp;quot;Ridgeline Plot: More variation in the distribution (X-axis)&amp;quot;,
        subtitle = &amp;quot;Identical mean values&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 5.46&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/ridgeline_x-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;y&lt;/code&gt; values, &lt;code&gt;high_lines&lt;/code&gt;, &lt;code&gt;dots&lt;/code&gt;, &lt;code&gt;circle&lt;/code&gt; and &lt;code&gt;star&lt;/code&gt; have obviously different distributions from the rest. Again, the &lt;strong&gt;mean&lt;/strong&gt; values are identical across variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    ggplot(aes(x = y, y = dataset, fill = dataset)) +
    geom_density_ridges_gradient(scale = 3, quantile_lines = T, quantile_fun = mean) +
    scale_fill_manual(values = c(&amp;#39;#a6cee3&amp;#39;, &amp;#39;#1f78b4&amp;#39;, &amp;#39;#b2df8a&amp;#39;, &amp;#39;#33a02c&amp;#39;, &amp;#39;#fb9a99&amp;#39;, &amp;#39;#e31a1c&amp;#39;, &amp;#39;#fdbf6f&amp;#39;, &amp;#39;#ff7f00&amp;#39;, &amp;#39;#cab2d6&amp;#39;, &amp;#39;#6a3d9a&amp;#39;, &amp;#39;#ffff99&amp;#39;, &amp;#39;#b15928&amp;#39;, &amp;#39;grey&amp;#39;)) +
    theme_classic() +
    theme(legend.position = &amp;#39;none&amp;#39;) +
    labs(
        x = &amp;quot;Y-values&amp;quot;,
        y = &amp;quot;13 variables&amp;quot;,
        title = &amp;quot;Ridgeline Plot: More variation in the distribution (Y-axis)&amp;quot;,
        subtitle = &amp;quot;Identical mean values&amp;quot;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/ridgeline_y-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlations&lt;/h2&gt;
&lt;p&gt;If you skip visualizing the distribution and central tendencies and go straight to seeing how the variables correlate with each other, you could also miss some fundamental differences in the data.&lt;/p&gt;
&lt;p&gt;In particular, the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; values across all 13 variables are &lt;em&gt;highlight correlated&lt;/em&gt;. With just knowledge of the summary statistics, one could be led to believe that these variables are &lt;em&gt;highly similar&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Below is an abbreviated &lt;strong&gt;correlation matrix&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggcorrplot)

# X-values
# selecting rows 2-143 
# turning all values from character to numeric
datasaurus_wide_x &amp;lt;- datasaurus_wide %&amp;gt;%
    slice(2:143) %&amp;gt;%
    select(away, bullseye, circle, dino, dots, h_lines, high_lines, slant_down, slant_up, star, v_lines, wide_lines, x_shape) %&amp;gt;%
    mutate_if(is.character, as.numeric)
    
# Y-values
# selecting rows 2-143 
# turning all values from character to numeric
datasaurus_wide_y &amp;lt;- datasaurus_wide %&amp;gt;%
    slice(2:143) %&amp;gt;%
    select(away_1, bullseye_1, circle_1, dino_1, dots_1, h_lines_1, high_lines_1, slant_down_1, slant_up_1, star_1, v_lines_1, wide_lines_1, x_shape_1) %&amp;gt;%
    mutate_if(is.character, as.numeric)


# correlation matrix for X values
corr_x &amp;lt;- round(cor(datasaurus_wide_x), 1)

# correlation matrix for Y values
corr_y &amp;lt;- round(cor(datasaurus_wide_y), 1)

head(corr_x[, 1:6])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          away bullseye circle dino dots h_lines
## away      1.0     -0.3   -0.3 -0.3 -0.3    -0.3
## bullseye -0.3      1.0    0.9  0.9  0.9     0.9
## circle   -0.3      0.9    1.0  0.9  0.8     0.9
## dino     -0.3      0.9    0.9  1.0  0.9     1.0
## dots     -0.3      0.9    0.8  0.9  1.0     0.9
## h_lines  -0.3      0.9    0.9  1.0  0.9     1.0&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;visualizing-the-correlation-matrix&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualizing the correlation matrix&lt;/h3&gt;
&lt;p&gt;Here is a correlation between the &lt;code&gt;x-values&lt;/code&gt; between all 13 variables. You can see that all variables, aside from &lt;code&gt;away&lt;/code&gt;, are highly correlated with each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# correlation between X-values
ggcorrplot(corr_x, hc.order = TRUE, 
           type=&amp;quot;lower&amp;quot;, 
           outline.color = &amp;quot;white&amp;quot;,
           ggtheme = ggplot2::theme_gray,
           colors = c(&amp;quot;#d8b365&amp;quot;, &amp;quot;#f5f5f5&amp;quot;, &amp;quot;#5ab4ac&amp;quot;),
           lab = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/corr_x_viz-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is a correlation between the ‘y-values’ between all 13 variables. Again, aside from &lt;code&gt;away&lt;/code&gt;, all the variables are highly correlated with each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# correlation between Y-values
ggcorrplot(corr_y, hc.order = TRUE, 
           type=&amp;quot;lower&amp;quot;, 
           outline.color = &amp;quot;white&amp;quot;,
           ggtheme = ggplot2::theme_gray,
           colors = c(&amp;quot;#ef8a62&amp;quot;, &amp;quot;#f7f7f7&amp;quot;, &amp;quot;#67a9cf&amp;quot;),
           lab = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/corr_y_viz-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;facets&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Facets&lt;/h2&gt;
&lt;p&gt;At this point, the &lt;strong&gt;boxplots&lt;/strong&gt; show us variables with &lt;em&gt;similar median&lt;/em&gt; and &lt;em&gt;identical mean&lt;/em&gt;; the &lt;strong&gt;ridgelines&lt;/strong&gt; begin to show us that some variables have different distributions. And the &lt;strong&gt;correlation matrix&lt;/strong&gt; suggests the variables are more similar than not.&lt;/p&gt;
&lt;p&gt;To really see their differences, we’ll need to use &lt;code&gt;facet_wrap&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here we’ll use &lt;code&gt;facet_wrap&lt;/code&gt; to examine the histogram for &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; values of all 13 variables. We started to see the differences in distribution between variables from the &lt;code&gt;ridgeline&lt;/code&gt; plots, but overlapping histograms provide another perspective.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# facet histogram (both-values)
datasaurus_dozen %&amp;gt;%
    group_by(dataset) %&amp;gt;%
    ggplot() +
    geom_histogram(aes(x=x, fill=&amp;#39;red&amp;#39;), alpha = 0.5, bins = 30) +
    geom_histogram(aes(x=y, fill=&amp;#39;green&amp;#39;), alpha = 0.5, bins = 30) +
    facet_wrap(~dataset) +
    scale_fill_discrete(labels = c(&amp;#39;y&amp;#39;, &amp;#39;x&amp;#39;)) +
    theme_classic() +
    labs(
        fill = &amp;#39;Axes&amp;#39;,
        x = &amp;#39;&amp;#39;,
        y = &amp;#39;Count&amp;#39;,
        title = &amp;#39;Faceted Histogram: x- and y-values&amp;#39;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/facet_histo-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scatter-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scatter Plot&lt;/h2&gt;
&lt;p&gt;However, if there’s one thing this dataset is trying to communicate its that there’s no subtitute for plotting the actual data points. No amount of summary statistics, central tendency or distribution is going to replace &lt;strong&gt;plotting actually data points&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Once we create the scatter plot with &lt;code&gt;geom_point&lt;/code&gt;, we see the big reveal with this dataset. That despite the similarities in central measures, for the most part similar distributions and high correlations, the 13 variables are &lt;strong&gt;wildly different&lt;/strong&gt; from each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasaurus_dozen %&amp;gt;%
    group_by(dataset) %&amp;gt;%
    ggplot(aes(x=x, y=y, color=dataset)) +
    geom_point(alpha = 0.5) +
    facet_wrap(~dataset) +
    scale_color_manual(values = c(&amp;#39;#a6cee3&amp;#39;, &amp;#39;#1f78b4&amp;#39;, &amp;#39;#b2df8a&amp;#39;, &amp;#39;#33a02c&amp;#39;, &amp;#39;#fb9a99&amp;#39;, &amp;#39;#e31a1c&amp;#39;, &amp;#39;#fdbf6f&amp;#39;, &amp;#39;#ff7f00&amp;#39;, &amp;#39;#cab2d6&amp;#39;, &amp;#39;#6a3d9a&amp;#39;, &amp;#39;#ffff99&amp;#39;, &amp;#39;#b15928&amp;#39;, &amp;#39;grey&amp;#39;)) +
    theme_classic() +
    theme(legend.position = &amp;quot;none&amp;quot;) +
    labs(
        x = &amp;#39;X-axis&amp;#39;,
        y = &amp;#39;Y-axis&amp;#39;,
        title = &amp;#39;Faceted Scatter Plot&amp;#39;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/facet_scatter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are other less common alternatives to the &lt;strong&gt;scatter plot&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;geom-density-2d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Geom Density 2D&lt;/h2&gt;
&lt;p&gt;While not as clear as the &lt;strong&gt;scatter plot&lt;/strong&gt;, plotting the &lt;strong&gt;contours&lt;/strong&gt; of a 2D density estimate does show how very different the variables are from each other, despite similar summary statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# contours of a 2D Density estimate
datasaurus_dozen %&amp;gt;%
    ggplot(aes(x=x, y=y)) +
    geom_density_2d() +
    theme_classic() +
    facet_wrap(~dataset) +
    labs(
        x = &amp;#39;X-axis&amp;#39;,
        y = &amp;#39;Y-axis&amp;#39;,
        title = &amp;#39;Contours of a 2D density estimate&amp;#39;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/geom_density_contour-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is a slight variation using &lt;code&gt;stat_density_2d&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# stat density 2d
datasaurus_dozen %&amp;gt;%
    ggplot(aes(x=x, y=y)) +
    stat_density_2d(aes(fill=y), geom = &amp;quot;polygon&amp;quot;, colour = &amp;#39;white&amp;#39;) +
    theme_classic() +
    facet_wrap(~dataset) +
    labs(
        x = &amp;#39;X-axis&amp;#39;,
        y = &amp;#39;Y-axis&amp;#39;,
        title = &amp;#39;Stat Density 2D estimate&amp;#39;
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-11-16-datasaurus_files/figure-html/stat_density-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;density_2d&lt;/code&gt; plots are quite effective in showing how different the variables are and serve as a nice alternative to the more familiar scatter plot.&lt;/p&gt;
&lt;p&gt;Hopefully this vignette illustrates the importance of never trusting summary statistics (alone). Moreover, when visualizing, we should go beyond simply visualizing the data’s distribution or central tendency, but plotting the actually data points.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
