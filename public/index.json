[{"authors":["admin"],"categories":null,"content":"I help people and organizations make data-driven decisions. My services include data cleaning, data analysis and data visualization. Pre-services include understanding business and organizational OKRs.\nOrganizational psychologist turned data scientist.\n","date":1603411200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1603929600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/paul-apivat-hanvongse/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/paul-apivat-hanvongse/","section":"authors","summary":"I help people and organizations make data-driven decisions. My services include data cleaning, data analysis and data visualization. Pre-services include understanding business and organizational OKRs.\nOrganizational psychologist turned data scientist.","tags":null,"title":"Paul Apivat Hanvongse","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":1461110400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1555459200,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Courses Overview","type":"docs"},{"authors":null,"categories":null,"content":"Flexibility Add Technical Notes.\nThis feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"c432be3f6e1e5e026e053659322b73ca","permalink":"/technical_notes/example_tech/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/technical_notes/example_tech/","section":"technical_notes","summary":"Learn how to use Academic's docs layout for publishing technical notes and tutorials.","tags":null,"title":"Technical Notes Overview","type":"docs"},{"authors":null,"categories":null,"content":"Virtual Environment Best Practices NOTE: This is from chapter 2 of Joel Grus\u0026rsquo; \u0026lsquo;Data Science from Scratch\u0026rsquo;.\nJoel\u0026rsquo;s a known opponent of notebooks and recommends operating in IPython instead.\nI was pleasantly surprised that the process of setting up a virtual environment and IPython was relatively painless. Here\u0026rsquo;s my process, taken from the book with some tweaks:\n# create a Python 3.6 environment named 'dsfs' conda create -n dsfs python=3.6 # update conda to latest version (4.9.0) conda update -n base -c defaults conda # to activate virtual environment (named it 'dsfs' to keep it simple) source activate dsfs # install pip (note: currently using Python 3.8.5) python3 get-pip.py # install IPython python3 -m pip install ipython # save IPython session # save lines 1-21 in session to file initial_ipython_session.py %save initial_ipython_session 1-21 # exit IPython ctrl + D # exit conda virtual environment conda deactivate  Pulling up a saved IPython session in VSCode note: I am using VSCode as my main python IDE outside of jupyter notebooks.\nAfter you\u0026rsquo;ve saved an IPython session (see above), you may want to pull up the .py file for further edits at a later time. To do this, you\u0026rsquo;ll need to ensure that the code command for VSCode is installed.\nAssuming you\u0026rsquo;re already in VSCode, press (I\u0026rsquo;m using macOS):\nCommand + Shift + P  Then select Shell Command: Install code in PATH. That\u0026rsquo;s it.\nTo open a previously saved IPython session in VSCode from the VSCode terminal, type:\n% code name_of_file.py  Note that this can be done from (base) or from a previously configured virtual environment session, for example:\n(base) paulapivat@Pauls-MacBook dsfs % code function_session.py (base) paulapivat@Pauls-MacBook dsfs % source activate dsfs (dsfs) paulapivat@Pauls-MacBook dsfs % code function_session.py  ","date":1603321200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603321200,"objectID":"fbd245bc481bd9e0d8985298f919118a","permalink":"/technical_notes/example_tech/python_virtualenv/","publishdate":"2020-10-22T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/python_virtualenv/","section":"technical_notes","summary":"Virtual Environment Best Practices NOTE: This is from chapter 2 of Joel Grus\u0026rsquo; \u0026lsquo;Data Science from Scratch\u0026rsquo;.\nJoel\u0026rsquo;s a known opponent of notebooks and recommends operating in IPython instead.\nI was pleasantly surprised that the process of setting up a virtual environment and IPython was relatively painless.","tags":null,"title":"Setting up Conda Virtual Env and IPython","type":"docs"},{"authors":null,"categories":null,"content":"Creating and Looping through List of Tuples If you come to Python from R, it\u0026rsquo;s not immediately obvious how Lists, Dictionaries, Tuples, Series, then Loops help you do the things you can do in R.\nYou can begin to connect the dots when you see that Lists of Tuples are the building blocks of DataFrames - available in both languages to handle tidy (tabular) data.\nLists Lists are ordered and mutable collection of data. Below are lists of strings and integers.\nname_list = ['paul', 'apivat', 'marvin', 'pim', 'milin'] int_list = [3,4,5,2,5,6,7,5]  Tuples Tuples, also collections, are ordered and immutable. But more related to the handling of data, tuples can be converted to DataFrames (using the Pandas library). Below, the List of Tuples (data) is converted into a DataFrame.\nimport pandas as pd data = [ ('r1', 'c1', 11, 11), ('r1', 'c2', 12, 12), ('r2', 'c1', 21, 21), ('r2', 'c2', 22, 22) ] df = pd.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std'])  Loops You can loop through lists of strings and integers.\nint_list = [3,4,5,2,5,6,7,5] for num in int_list: print(num) name_list = ['paul', 'apivat', 'marvin', 'pim', 'milin'] for name in name_list: print(name)  Looping through List of Tuples (DataFrame) Just like you can loop through any collection, you can loop through a list of tuples - which means you can loop through DataFrames.\n# Looping through column names df = pd.DataFrame(data, columns=['R_Number', 'C_Number', 'Avg', 'Std']) for col_names in df: print(col_names) # Looping through a specific column for items in df['R_Number']: print(items) # Looping through a specific row for items in df.iloc[1]: print(items)  That\u0026rsquo;s the basic connection between python fundamental data structures and for-loop operations and data science.\n","date":1600815600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600815600,"objectID":"10f37798ee6e8eb8161738f38853e3d8","permalink":"/technical_notes/example_tech/python_tip2/","publishdate":"2020-09-23T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/python_tip2/","section":"technical_notes","summary":"Creating and Looping through List of Tuples If you come to Python from R, it\u0026rsquo;s not immediately obvious how Lists, Dictionaries, Tuples, Series, then Loops help you do the things you can do in R.","tags":null,"title":"Creating and Looping through DataFrames","type":"docs"},{"authors":null,"categories":null,"content":"Random Numbers with Numpy Numpy has a sub-module called random. Technically both are of the \u0026lsquo;module\u0026rsquo; class. numpy.random contains other methods like: seed, set_state, standard_t etc.\n# Submodules import numpy print(\u0026quot;numpy.random is a\u0026quot;, type(numpy.random)) print(\u0026quot;numpy is a\u0026quot;, type(numpy)) print(\u0026quot;it contains names such as...\u0026quot;, dir(numpy.random)[-15:])  Reproducibility When using numpy.random, you can ensure reproducibility by accessing numpy.random.seed(30), which mirrors #Rstats\u0026rsquo; set.seed(30) behavior.\nimport random numpy.random.seed(30) rolls = numpy.random.randint(low=1, high=6, size=10) rolls  ","date":1599692400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599692400,"objectID":"684176c32c2cfcd15b0d67ffcf04af31","permalink":"/technical_notes/example_tech/python_reproducibility/","publishdate":"2020-09-10T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/python_reproducibility/","section":"technical_notes","summary":"Random Numbers with Numpy Numpy has a sub-module called random. Technically both are of the \u0026lsquo;module\u0026rsquo; class. numpy.random contains other methods like: seed, set_state, standard_t etc.\n# Submodules import numpy print(\u0026quot;numpy.","tags":null,"title":"Random Numbers \u0026 Reproducibility in Python","type":"docs"},{"authors":null,"categories":null,"content":"Steps for Connecting BigQuery to Data Studio This note outlines the basic steps required to generate charts in Google Data Studio, specifically pulling data from BigQuery.\nBigQuery  The starting point is to generate a query in BigQuery Once a query is created, click Save Results In the pop-up window, a prompt: \u0026ldquo;choose where to save the results data from the query\u0026rdquo;, save result as BigQuery Table Set project name (i.e., jobsbot) Set dataset name (i.e., internalmongo) Create table name, for the specific query (i.e., jobfieldname_ranking)  Google Data Studio Click Add Data Find BigQuery in Google Connectors Locate saved query table (see above) (i.e., My Projects \u0026gt; jobsbot (project) \u0026gt; internalmongo (dataset) \u0026gt; jobfieldname_ranking (table/specific query)) Click Add Select \u0026lsquo;Add a Chart\u0026rsquo; (note: could be Table or Chart style) Optional: copy/paste Table to create a companion Chart for table Select Table; in Data Menu, select Metric, \u0026lsquo;Add Metric\u0026rsquo; to swap out generic default Report Count (for more informative data generated from the query)  ","date":1599260400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599260400,"objectID":"3aadd358dc22bab05cb5eaf1acd29262","permalink":"/technical_notes/example_tech/google_cloud_tip1/","publishdate":"2020-09-05T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/google_cloud_tip1/","section":"technical_notes","summary":"Steps for Connecting BigQuery to Data Studio This note outlines the basic steps required to generate charts in Google Data Studio, specifically pulling data from BigQuery.\nBigQuery  The starting point is to generate a query in BigQuery Once a query is created, click Save Results In the pop-up window, a prompt: \u0026ldquo;choose where to save the results data from the query\u0026rdquo;, save result as BigQuery Table Set project name (i.","tags":null,"title":"Connecting BigQuery to Google Data Studio [Basic Setup]","type":"docs"},{"authors":null,"categories":null,"content":"Setting up Python for R Users I\u0026rsquo;ve recently started #66DaysOfData and will be using this opportunity to make some headway into the world of Python. It\u0026rsquo;s reputation for having a complex, at times frustrating, setup process precedes itself and is probably warranted. That said, here are some tips to minimize that.\nHere\u0026rsquo;s my current OS environment. Mac users will have an older version of Python that comes with the computer, you can type python --version into your terminal to find out. Here\u0026rsquo;s mine:\nmacOS Catalina version 10.15.5 Python 2.7.16  Python 2 vs Python 3 There appears to be general consensus for anyone starting out in Python that you\u0026rsquo;ll want Python 3. There\u0026rsquo;s no debate here. Just get Python 3. I found the easiest way to go to Python Release for Mac OS X, which as of this writing is Python 3.8.5 and use the macOS 64-bit installer.\nOnce installed, you\u0026rsquo;ll want to check.\nInstead of python --version, which checks Python 2, you\u0026rsquo;ll use python3 --version. This implies that Python 3 isn\u0026rsquo;t merely a \u0026ldquo;newer\u0026rdquo; version of Python, but that they are completely different categories.\nAnaconda While this isn\u0026rsquo;t my first choice of development environment, it is the first option that allowed me to get coding in Python the fastest.\nYou\u0026rsquo;ll download the Individual Edition of the Anaconda, open-source platform. You\u0026rsquo;ll download the application for your desktop and you\u0026rsquo;ll find Anaconda-Navigator in your list of applications (or where ever you chose to place your newly installed application).\nNOTE: Shortly after installing and using, the Desktop version of Anaconda froze and I had a difficult time even \u0026ldquo;Force Quitting\u0026rdquo; it, so my preferred method of launching Anaconda Navigator is to open the mac terminal and type in the command anaconda-navigator.\nThe navigator supports Jupyter Notebooks, PyCharm and even RStudio among other environments.\nI will be using Jupyter Notebooks while I get acclimated to Python, but ultimately i\u0026rsquo;m looking for interoperability with #Rstats.\nReticulate This is an R package that allows you to run Python code in R environments. The feature I am looking forward to using is the R Markdown document that allows me to run chunks of python code.\nWork-in-Progress: TBD\nVSCode This is another popular IDE with widely used Python Extension.\nWork-in-Progress: TBD\nPyCharm I\u0026rsquo;ve heard this IDE most closely resembles RStudio in ease of use.\nWork-in-Progress: TBD\nSpyder This appears to be close approximation of the functionality in RStudio.\nWork-in-Progress: TBD\n","date":1599174000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599174000,"objectID":"7e9e9cc140ad4f3aa593032d2899ac12","permalink":"/technical_notes/example_tech/python_tip1/","publishdate":"2020-09-04T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/python_tip1/","section":"technical_notes","summary":"Setting up Python for R Users I\u0026rsquo;ve recently started #66DaysOfData and will be using this opportunity to make some headway into the world of Python. It\u0026rsquo;s reputation for having a complex, at times frustrating, setup process precedes itself and is probably warranted.","tags":null,"title":"Python Setup Options","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTechnical Tip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTechnical Tip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"14dcb8c9da95e5d25a957b90a714d7bd","permalink":"/technical_notes/example_tech/technical_notes1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/technical_notes1/","section":"technical_notes","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTechnical Tip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat.","tags":null,"title":"Technical Notes Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Ways of handling nested data Recently, I downloaded JSON data from BigQuery and had to make sense of the data. This starts with getting the data into tabular form.\nHere are the libraries I used:\nlibrary(jsonlite) library(tidyverse)  First, read in JSON data. Once read in, we check its class type to see that its a list. We\u0026rsquo;ll want to get it into a data frame.\n# read data out into Large list (321 elements, 2.4 Mb) # each row is *another* list funnel \u0026lt;- lapply(readLines(\u0026quot;bq-mixpanel-funnel.json\u0026quot;), fromJSON) # \u0026quot;list\u0026quot; class class(funnel)  After searching online, three approaches continually resurfaced.\nFirst, using unlist() and converting into matrix() before wrapping that in a data.frame():\n# Approach 1: convert to matrix, array unlist_funnel \u0026lt;- matrix(unlist(funnel), byrow = TRUE, ncol = length(funnel[[1]])) rownames(unlist_funnel) \u0026lt;- names(funnel) as.data.frame(unlist_funnel) %\u0026gt;% view()  These next approaches get us closer (note: I know from interacting with the data in BigQuery that there should be 321 rows):\n# Approach 2: Convert list to data frame df \u0026lt;- data.frame(matrix(unlist(funnel), nrow = length(funnel), byrow = TRUE)) df2 \u0026lt;- data.frame(matrix(unlist(funnel), nrow = length(funnel), byrow = FALSE)) df3 \u0026lt;- data.frame(matrix(unlist(funnel), nrow = 321, byrow = TRUE), stringsAsFactors = FALSE)  The next approach is to use lapply()\n#works but everything is on one column unlist(lapply(funnel, c)) %\u0026gt;% view() # this makes everything a list, but we want everything into a vector t(lapply(funnel, c)) %\u0026gt;% view()  Finally, the approach that worked best, in this particular case was sapply(). This functions turns things into vector, which can then be converted into a dataframe:\n#still the ideal, this works because 'c' is used ot combine lists t(sapply(funnel, c)) %\u0026gt;% view()  ","date":1602370800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602370800,"objectID":"3dfa4cd1a73e03115bfb119a69ccbcbf","permalink":"/technical_notes/example_tech/rstats_unnest/","publishdate":"2020-10-11T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_unnest/","section":"technical_notes","summary":"Ways of handling nested data Recently, I downloaded JSON data from BigQuery and had to make sense of the data. This starts with getting the data into tabular form.\nHere are the libraries I used:","tags":null,"title":"Reading and manipulating nested data","type":"docs"},{"authors":null,"categories":null,"content":"Setting up a barebones table with {reactable} There are several packages to style your tables. This note will help you get setup with a basic table using the reactable package. With just a few lines of code, you can have a table with pagination and column sorting.\nThe data for this note comes from TidyTuesday 2020-09-22, \u0026ldquo;Himalayan Climbers\u0026rdquo;.\nThis note assumes that data has been wrangled and in tibble form, ready to be styled into a table.\nSample Tibble Here, I\u0026rsquo;ve saved my tibble of 20 rows and 3 columns in df.\n\u0026gt; df # A tibble: 20 x 3 peak attempts fail_rate \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; 1 Everest 21813 0.54 2 Cho Oyu 8890 0.570 3 Ama Dablam 8406 0.479 4 Manaslu 4593 0.621 5 Dhaulagiri I 2592 0.789 6 Makalu 2405 0.764 7 Lhotse 2379 0.638 8 Baruntse 2190 0.708 9 Pumori 1780 0.706 10 Annapurna I 1669 0.821 11 Kangchenjunga 1385 0.682 12 Himlung Himal 1308 0.573 13 Annapurna IV 812 0.845 14 Putha Hiunchuli 738 0.599 15 Tilicho 670 0.781 16 Tukuche 462 0.753 17 Jannu 339 0.782 18 Langtang Lirung 338 0.84 19 Makalu II 322 0.758 20 Nuptse 303 0.934  Load Libraries library(tidyverse) library(reactable) library(htmltools)  Basic Table The amazing thing is, with just this one line, you have a barebones table with pagination (with 20 rows, it shows 10 at a time; this can be adjusted) and sorting for both columns.\nYou can check out the rest of the repo here\nreactable(df)  Adding Bar Charts for Each Row Of course, bare bones is not much to look at, so adding bar charts is essential for visually communicating quantities and percentages. However, you\u0026rsquo;ll need to use the htmltools package to begin adding div to your chart.\n# Bar Charts can be added with a function bar_chart \u0026lt;- function(label, width = \u0026quot;100%\u0026quot;, height = \u0026quot;14px\u0026quot;, fill = \u0026quot;#00bfc4\u0026quot;, background = NULL){ bar \u0026lt;- div(style = list(background = fill, width = width, height = height)) chart \u0026lt;- div(style = list(flexGrow = 1, marginLeft = \u0026quot;6px\u0026quot;, background = background), bar) div(style = list(display = \u0026quot;flex\u0026quot;, alignItems = \u0026quot;center\u0026quot;), label, chart) } # The bar_chart function is then inserted into the numeric columns reactable( df, defaultSorted = \u0026quot;attempts\u0026quot;, columns = list( peak = colDef( name = \u0026quot;Peaks\u0026quot; ), attempts = colDef( name = \u0026quot;Attempts (#)\u0026quot;, defaultSortOrder = \u0026quot;desc\u0026quot;, #format = colFormat(separators = TRUE), # Render Bar charts using a custom cell render function cell = function(value){ width \u0026lt;- paste0(value * 100 / max(df$attempts), \u0026quot;%\u0026quot;) # Add thousands separators value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) # Fix each label using the width of the widest number (incl. thousands separators) value \u0026lt;- format(value, width = 9, justify = 'right') bar_chart(value, width = width, fill = \u0026quot;#3fc1c9\u0026quot;) }, # And left-align the columns align = \u0026quot;left\u0026quot;, # Use the operating system's default monospace font, and # preserve the white space to prevent it from being collapsed by default style = list(fontFamily = \u0026quot;monospace\u0026quot;, whiteSpace = \u0026quot;pre\u0026quot;) ), fail_rate = colDef( name = \u0026quot;Fail (%)\u0026quot;, defaultSortOrder = \u0026quot;desc\u0026quot;, #format = colFormat(percent = TRUE, digits = 1) # Render Bar charts using a custom cell render function cell = function(value){ # Format as percentage with 1 decimal place value \u0026lt;- paste0(format(value * 100, nsmall = 1), \u0026quot;%\u0026quot;) # Fix width here to align single and double-digit percentages value \u0026lt;- format(value, width = 5, justify = \u0026quot;right\u0026quot;) bar_chart(value, width = value, fill = \u0026quot;#fc5185\u0026quot;, background = \u0026quot;#e1e1e1\u0026quot;) }, # And left-align the columns align = \u0026quot;left\u0026quot;, style = list(fontFamily = \u0026quot;monospace\u0026quot;, whiteSpace = \u0026quot;pre\u0026quot;) ) ) )  ","date":1600988400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600988400,"objectID":"755be6aa7da017af419014c999ef276a","permalink":"/technical_notes/example_tech/rstats_viz_reactable/","publishdate":"2020-09-25T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_viz_reactable/","section":"technical_notes","summary":"Setting up a barebones table with {reactable} There are several packages to style your tables. This note will help you get setup with a basic table using the reactable package. With just a few lines of code, you can have a table with pagination and column sorting.","tags":null,"title":"Styling tables with reactable","type":"docs"},{"authors":null,"categories":null,"content":"Changing the x-axis from decimals to integers When creating plots in ggplot2 you\u0026rsquo;ll often want to customize the x-axis so that values appear on a certain interval. In the example below, I wanted to change the intervals from 0.25, 0.50, 0.75 to 1,2,3,4 and so on. In this specific instance, I wanted each season of the show Friends to have its down tick on the x-axis (note: the show had ten seasons).\nThis operation changes the x-axis ticks from having decimals to being integers.\nlibrary(ggplot) ggplot(total_data, aes(x = season, y = episode, fill=imdb_rating)) + geom_tile() + scale_fill_gradient(low = '#FFF580', high = '#FF4238') + ## the seq() function defines the start and end numbers ## 'by =' indicates the desired interval scale_x_continuous(breaks = seq(1,10, by = 1)) + theme_classic()  ","date":1600124400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600124400,"objectID":"e92bd85ddda5cee358e10fe7c90aff40","permalink":"/technical_notes/example_tech/rstats_viz_scale_x/","publishdate":"2020-09-15T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_viz_scale_x/","section":"technical_notes","summary":"Changing the x-axis from decimals to integers When creating plots in ggplot2 you\u0026rsquo;ll often want to customize the x-axis so that values appear on a certain interval. In the example below, I wanted to change the intervals from 0.","tags":null,"title":"Decimals to Integers","type":"docs"},{"authors":null,"categories":null,"content":"Treemapify There are several options for visualizing treemaps in R. This note focuses on Treemapify, a package maintained by David Wilkins.\nI favor this approach over the treemap package because it is compatible with ggplot2 and allows users to access its\u0026rsquo; functionality.\nHere\u0026rsquo;s an example Treemap I created to visualize the dominant emotions displayed for the iconic 90\u0026rsquo;s sitcom, Friends. You can find out more about the Friends dataset here.\nOther visualizations I created for the Friends project can also be found here.\nBelow, we can see that geom_treemap, geom_treemap_subgroup_border and geom_treemap_subgroup_text are layers that works seamlessly with other layers like scale_fill_manual, theme, and labs that are staples of the ggplot2 package.\nBottom line, it\u0026rsquo;s easier to customize treemaps from the treemapify package than the treemap package.\nlibrary(treemapify) ggplot(friends_emo_tree, aes(area = n, label = speaker, subgroup = emotion)) + geom_treemap(aes(fill = emotion, alpha = n)) + geom_treemap_subgroup_border(color = 'white') + geom_treemap_subgroup_text(place = 'bottom', grow = T, alpha = 0.3, color = 'black', min.size = 0) + geom_treemap_text(color = 'white', fontface = 'italic', place = 'centre', reflow = T) + scale_fill_manual(values = c('#FF4238', '#FFDC00', '#42A2D6', '#9A0006', '#FFF580', '#00009E')) + theme( plot.background = element_rect(fill = '#36454F'), legend.position = 'none', title = element_text(colour = 'white', family = 'Friends') ) + labs( title = 'The One with the Dominant Emotions', caption = 'Viz: @paulapivat | Data: #TidyTuesday' )  ","date":1600124400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600124400,"objectID":"b9d7ec81504df4de64455ab116182243","permalink":"/technical_notes/example_tech/rstats_viz_treemapify/","publishdate":"2020-09-15T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_viz_treemapify/","section":"technical_notes","summary":"Treemapify There are several options for visualizing treemaps in R. This note focuses on Treemapify, a package maintained by David Wilkins.\nI favor this approach over the treemap package because it is compatible with ggplot2 and allows users to access its\u0026rsquo; functionality.","tags":null,"title":"GGPlot Flavored Treemaps","type":"docs"},{"authors":null,"categories":null,"content":"Marginal Distribution with ggplot2 and ggExtra The data in this example is from the UN Statistics Division Sustainable Development Goal, Indicator 4.4.1.\nAlso check out the r-graph-gallery.com for inspiration.\nHere\u0026rsquo;s the breakdown:\n Load Packages and Libraries  The key here is the ggExtra package.\ninstall.packages('ggExtra') library(ggExtra) library(tidyverse)  Create a basic scatter plot  The key here is using pivot_wider to give all Type of skill their own columns. We\u0026rsquo;ll then pick out specific columns (i.e., COPA, EMAIL, PCPR) to summarize, then plot on the x- and y- axes.\n# Basic Scatter Plot (color cluster by Gender) p \u0026lt;- data %\u0026gt;% select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% pivot_wider(names_from = `Type of skill`, values_from = Value) %\u0026gt;% mutate( COPA = as.numeric(COPA), EMAIL = as.numeric(EMAIL), PCPR = as.numeric(PCPR) ) %\u0026gt;% # Group by GeoAreaName, across TimePeriod, Sex group_by(GeoAreaName, Sex) %\u0026gt;% summarize( avg_COPA = mean(COPA, na.rm = TRUE), avg_EMAIL = mean(EMAIL, na.rm = TRUE), avg_PCPR = mean(PCPR, na.rm = TRUE) ) %\u0026gt;% ungroup() %\u0026gt;% ggplot(aes(x = avg_PCPR, y = avg_EMAIL, color = Sex)) + geom_point()  Use ggMarginal() to create the marginal distribution along the side of the scatter plots. This is a function from the ggExtra package.  # Scatter Plot with Marginal Distribution ggMarginal(p, type = 'histogram')  This particular chart is especially useful to highlight different distributions.\n","date":1599001200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599001200,"objectID":"9b951ca5d2ded69beeec9c9bddcbaf55","permalink":"/technical_notes/example_tech/data_viz_tip2/","publishdate":"2020-09-02T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/data_viz_tip2/","section":"technical_notes","summary":"Marginal Distribution with ggplot2 and ggExtra The data in this example is from the UN Statistics Division Sustainable Development Goal, Indicator 4.4.1.\nAlso check out the r-graph-gallery.com for inspiration.\nHere\u0026rsquo;s the breakdown:","tags":null,"title":"Visualize Scatterplots with Marginal Distribution using ggExtra","type":"docs"},{"authors":null,"categories":null,"content":"Calculating Percentiles When we have a list of values in a column, how can we determine which values are under/over the 25th percentile, 50th percentile or 75th percentile?\nHere the example are countries\u0026rsquo; average percentages of the population with, broadly speaking, ICT Skills as determine by the Sustainable Development Goals, Indicator 4.4.1.\nThere are three methods. First, manually calculating values for the 25th, 50th and 75th percentile with the quantile() function.\n# Country mean_values at 25th, 50th and 75th percentile data %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate(Value = as.numeric(Value)) %\u0026gt;% group_by(GeoAreaName) %\u0026gt;% summarize( mean_value = mean(Value) ) %\u0026gt;% mutate( min_mean = min(mean_value), iqr_25_percentile = quantile(mean_value, probs = c(0.25)), iqr_50_percentile = quantile(mean_value, probs = c(0.50)), iqr_75_percentile = quantile(mean_value, probs = c(0.75)), max_mean = max(mean_value) ) %\u0026gt;% arrange(desc(mean_value))  The second approach is to use the ntile() function:\n# Creating bins using ntile() data %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate(Value = as.numeric(Value)) %\u0026gt;% group_by(GeoAreaName) %\u0026gt;% summarize( mean_value = mean(Value) ) %\u0026gt;% mutate( mean_value_binned = ntile(mean_value, 4) ) %\u0026gt;% arrange(desc(mean_value))  The third approach uses the purrr package and the partial function that can be used with dplyr's summarize_at() function. Check out the source\n ## Using purrr library(purrr) p \u0026lt;- c(0.25, 0.50, 0.75) p_names \u0026lt;- map_chr(p, ~paste0(.x*100, \u0026quot;%\u0026quot;)) p_funs \u0026lt;- map(p, ~partial(quantile, probs = .x, na.rm = TRUE)) %\u0026gt;% set_names(nm = p_names) p_funs data %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod, Units) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate(Value = as.numeric(Value)) %\u0026gt;% group_by(GeoAreaName) %\u0026gt;% summarize( mean_value = mean(Value) ) %\u0026gt;% summarize_at(vars(mean_value), funs(!!!p_funs))  ","date":1598482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598482800,"objectID":"c9640b108f821e003f9ce51a09f19de2","permalink":"/technical_notes/example_tech/rstats_tip4/","publishdate":"2020-08-27T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_tip4/","section":"technical_notes","summary":"Calculating Percentiles When we have a list of values in a column, how can we determine which values are under/over the 25th percentile, 50th percentile or 75th percentile?\nHere the example are countries\u0026rsquo; average percentages of the population with, broadly speaking, ICT Skills as determine by the Sustainable Development Goals, Indicator 4.","tags":null,"title":"Calculating 25th, 50th and 75th Percentile of Column Values","type":"docs"},{"authors":null,"categories":null,"content":"Data Wrangling: Does Order matter? In short, yes, it matters. But when and where?\nBelow are examples to highlight when function order matters and when it doesn\u0026rsquo;t. The source for the raw data used in this illustration are from the United Nations\u0026rsquo; Statistics Division for Sustainable Development Goals (SDG) Indicators (Goal 4, Target 4.4).\nSee also UN Statistics Wiki on Indicator 4.4.1.\n# Example chain of functions to determine proportion of Thailand's population to have certain ICT skills in 2018 data %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate( Value = as.double(Value) ) %\u0026gt;% filter(GeoAreaName == 'Thailand') %\u0026gt;% filter(TimePeriod == 2018) %\u0026gt;% group_by(type_of_skill) %\u0026gt;% summarize( mean_value = mean(Value), median_value = median(Value) ) %\u0026gt;% ungroup() %\u0026gt;% arrange(desc(mean_value))  Here, the filter functions are moved up to be before rename and mutate. The ordering here does not matter.\ndata %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %\u0026gt;% # putting filter before rename, mutate is fine filter(GeoAreaName == 'Thailand') %\u0026gt;% filter(TimePeriod == 2018) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate( Value = as.double(Value) ) %\u0026gt;% group_by(type_of_skill) %\u0026gt;% summarize( mean_value = mean(Value), median_value = median(Value) ) %\u0026gt;% ungroup() %\u0026gt;% arrange(desc(mean_value))  Furthermore, we could even experiment with the filter function being before or after select. Here, ordering also does not matter.\ndata %\u0026gt;% filter(GeoAreaName == 'Thailand') %\u0026gt;% filter(TimePeriod == 2018) %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate( Value = as.double(Value) ) %\u0026gt;% group_by(type_of_skill) %\u0026gt;% summarize( mean_value = mean(Value), median_value = median(Value) ) %\u0026gt;% ungroup() %\u0026gt;% arrange(desc(mean_value))  Here is there order does matter. When we try to move the two filter functions below group_by, summarize and ungroup, the filtering does not work. By the time we get to filter(GeoAreaName == 'Thailand') in this example, GeoAreaName has been removed because we did not group_by GeoAreaName, so we get an error.\n# Running this code, we'll get the ERROR: Problem with `filter()` input `..1`. x object 'GeoAreaName' not found ℹ Input `..1` is # `GeoAreaName == \u0026quot;Thailand\u0026quot;`. data %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %\u0026gt;% relocate(Sex, Value, GeoAreaName) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate( Value = as.double(Value) ) %\u0026gt;% # filter was previously here group_by(type_of_skill) %\u0026gt;% summarize( mean_value = mean(Value), median_value = median(Value) ) %\u0026gt;% ungroup() %\u0026gt;% # moving filter down below group_by \u0026amp; summarize() does not work filter(GeoAreaName == 'Thailand') %\u0026gt;% filter(TimePeriod == 2018) %\u0026gt;% arrange(desc(mean_value))  Finally, if we want to use filter on the results of the mutate function, we see that order does matter. By the time we get to the final filter(Value \u0026lt; 10), the Value variable is no longer available to us because we did not group_by and summarize by Value (instead we created mean_value and median_value).\n data %\u0026gt;% filter(GeoAreaName == 'Thailand') %\u0026gt;% filter(TimePeriod == 2018) %\u0026gt;% select(GeoAreaName, Value, Sex, `Type of skill`, TimePeriod) %\u0026gt;% rename(type_of_skill = `Type of skill`) %\u0026gt;% mutate( Value = as.double(Value) ) %\u0026gt;% # filtering for Values less than 10 does work here filter(Value \u0026lt; 10) %\u0026gt;% group_by(type_of_skill) %\u0026gt;% summarize( mean_value = mean(Value), median_value = median(Value) ) %\u0026gt;% ungroup() %\u0026gt;% arrange(desc(mean_value)) %\u0026gt;% # filter for Values less than 10 does not work down here filter(Value \u0026lt; 10)  ","date":1598482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598482800,"objectID":"1c27e97755595f70e8977c11b286d8c0","permalink":"/technical_notes/example_tech/rstats_tip5/","publishdate":"2020-08-27T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_tip5/","section":"technical_notes","summary":"Data Wrangling: Does Order matter? In short, yes, it matters. But when and where?\nBelow are examples to highlight when function order matters and when it doesn\u0026rsquo;t. The source for the raw data used in this illustration are from the United Nations\u0026rsquo; Statistics Division for Sustainable Development Goals (SDG) Indicators (Goal 4, Target 4.","tags":null,"title":"Does order of operation matter among dplyr functions?","type":"docs"},{"authors":null,"categories":null,"content":"Nested and Hierarchical Data When you have data with multiple subgroups, one option is to treat them as nested and/or hierarchical data.\nIn this technical note, I\u0026rsquo;ll outline how to create a dendrogram.\nThe data used is from the Extinct Plants data set from TidyTuesday.\nHere\u0026rsquo;s the breakdown:\n Load Packages and Libraries  install.packages(\u0026quot;ggraph\u0026quot;) install.packages(\u0026quot;igraph\u0026quot;) library(ggraph) library(igraph)  Create a data frame with three levels  Taking the plants data frame, I do some wrangling to get the desired columns.\nplants_data \u0026lt;- plants %\u0026gt;% select(group, binomial_name) %\u0026gt;% group_by(group) %\u0026gt;% arrange(group) %\u0026gt;% mutate( level1 = 'center', level2 = group, level3 = binomial_name ) %\u0026gt;% # important to ungroup here ungroup() %\u0026gt;% select(level1:level3)  Create an edge list  # transform it to an edge list plants_edges_level1_2 \u0026lt;- plants_data %\u0026gt;% select(level1, level2) %\u0026gt;% unique %\u0026gt;% rename(from=level1, to=level2) plants_edges_level2_3 \u0026lt;- plants_data %\u0026gt;% select(level2, level3) %\u0026gt;% unique %\u0026gt;% rename(from=level2, to=level3) plants_edge_list=rbind(plants_edges_level1_2, plants_edges_level2_3)  Plot a basic chart  Because I have many observations, I\u0026rsquo;m optiing to use a \u0026ldquo;circular\u0026rdquo; dendrogram.\n# plot plant dendogram plantgraph \u0026lt;- graph_from_data_frame(plants_edge_list) ggraph(plantgraph, layout = \u0026quot;dendrogram\u0026quot;, circular = TRUE) + geom_edge_diagonal() + geom_node_point() + theme_void()  Add text to the end of the edges  # add text \u0026amp; color(leaf) ggraph(plantgraph, layout = \u0026quot;dendrogram\u0026quot;, circular = TRUE) + geom_edge_diagonal() + geom_node_text(aes(label = name, filter=leaf), hjust = 1, size = 1) + geom_node_point()  NOTE: The breakdown of plant groupings are listed below. We can see the Flowering Plants disproportionately out number other groups like Ferns \u0026amp; Allies, Cycad, Mosses, Algae and Conifer.\nWhen visualizing, we\u0026rsquo;re better off separating Flowering Plants from the other groups.\nplants %\u0026gt;% group_by(group) %\u0026gt;% tally(sort = TRUE) # A tibble: 6 x 2 group n \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; 1 Flowering Plant 471 2 Ferns and Allies 13 3 Cycad 8 4 Mosses 4 5 Algae 3 6 Conifer 1  Here\u0026rsquo;s a sample picture of the plants\n  Dendrogram.   ","date":1598482800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598482800,"objectID":"6223f32efc8983e145b906f2ba2cd15b","permalink":"/technical_notes/example_tech/data_viz_tip1/","publishdate":"2020-08-27T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/data_viz_tip1/","section":"technical_notes","summary":"Nested and Hierarchical Data When you have data with multiple subgroups, one option is to treat them as nested and/or hierarchical data.\nIn this technical note, I\u0026rsquo;ll outline how to create a dendrogram.","tags":null,"title":"Creating a dendrogram with R and ggraph","type":"docs"},{"authors":null,"categories":null,"content":"With tidyr 1.0.0, there are several enhancements, one of which are pivot_wider() and pivot_longer().\nUsing pivot_wider() In another post, the spread() function was introduced as a way to observe the \u0026ldquo;tidy\u0026rdquo; principle of data formatting for analysis.\nThe pivot_wider() function is an updated of spread() and is much more intuitive. Here\u0026rsquo;s how it works:\n# PIVOT_WIDER - even better than Spread data %\u0026gt;% filter(GeoAreaName==\u0026quot;Morocco\u0026quot; | GeoAreaName==\u0026quot;Qatar\u0026quot;) %\u0026gt;% select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% pivot_wider(names_from = `Type of skill`, values_from = Value)  In this data set, Type of skill represents, broadly speaking, ICT Skills broken down into eight categories in this column. By using pivot_wider() each sub-category of ICT Skills gets it\u0026rsquo;s own column, thus making the overall data frame wider.\nUsing pivot_longer() Conversely, there\u0026rsquo;s also pivot_longer for the opposite effect. This next code chunk is part of my attempt for TidyTuesday (\u0026lsquo;Extinct Plants\u0026rsquo; for the week of 2020-08-18)\nThe cols parameter determines the range of columns to be changed from wide to long. The names_to parameter sets the new column name and values_to indicates the value of the new columns.\n# PIVOT_LONGER - better than Gather plants %\u0026gt;% select(binomial_name, threat_AA:action_NA) %\u0026gt;% pivot_longer(cols = threat_AA:action_NA, names_to = \u0026quot;action\u0026quot;, values_to = \u0026quot;count\u0026quot;) %\u0026gt;% ggplot(aes(x = binomial_name, y = action, fill = count)) + geom_tile() + theme(axis.text.x = element_text(angle = 90, hjust = 1))  ","date":1598396400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598396400,"objectID":"182f35a6a1bdc5bf30fd2f7628c58e38","permalink":"/technical_notes/example_tech/rstats_tip3/","publishdate":"2020-08-26T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_tip3/","section":"technical_notes","summary":"With tidyr 1.0.0, there are several enhancements, one of which are pivot_wider() and pivot_longer().\nUsing pivot_wider() In another post, the spread() function was introduced as a way to observe the \u0026ldquo;tidy\u0026rdquo; principle of data formatting for analysis.","tags":null,"title":"Using the pivot_wider() function","type":"docs"},{"authors":null,"categories":null,"content":"One principle of tidy data is to change from wide to long; and conversely, long to wide.\nHere\u0026rsquo;s a concrete example:\nUsing spread() The first part of the below pre-processing steps include subsetting the original data frame (data) by selecting two countries for comparison (Morocco and Qatar) on specific variables such as: GeoAreaName, TimePeriod, Sex, Type of skill and Value.\nThen employing group_by to ensure all rows are unique. The next line is key as it addresses an error that each row must be marked by a unique id key.\nFinally, the spread() function allows us to see each countries\u0026rsquo; relative performance on various ICT skills. Please consult meta-data for more details.\ndata %\u0026gt;% filter(GeoAreaName==\u0026quot;Morocco\u0026quot; | GeoAreaName==\u0026quot;Qatar\u0026quot;) %\u0026gt;% select(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% group_by(GeoAreaName, TimePeriod, Sex, `Type of skill`, Value) %\u0026gt;% # Error: Each row of output must be identified by a unique combination of keys. # rowid_to_column() address this error tibble::rowid_to_column() %\u0026gt;% spread(key = `Type of skill`, value = Value)  ","date":1598310000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598310000,"objectID":"3a8d20bf9e6f96b168329d46fd40ce86","permalink":"/technical_notes/example_tech/rstats_tip2/","publishdate":"2020-08-25T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_tip2/","section":"technical_notes","summary":"One principle of tidy data is to change from wide to long; and conversely, long to wide.\nHere\u0026rsquo;s a concrete example:\nUsing spread() The first part of the below pre-processing steps include subsetting the original data frame (data) by selecting two countries for comparison (Morocco and Qatar) on specific variables such as: GeoAreaName, TimePeriod, Sex, Type of skill and Value.","tags":null,"title":"Use the spread() function","type":"docs"},{"authors":null,"categories":null,"content":"Understanding reproducibility and the set.seed() function in R is best achieved through generating various random numbers. Here are some more tips for making your work reproducible:\nUsing set.seed() Example of reproducibility in fitting ML models using set.seed()\n#First Line set.seed(1234) #Second Line model_05_rand_forest_ranger \u0026lt;- rand_forest( mode = \u0026quot;regression\u0026quot;, mtry = 4, trees = 1000, min_n = 10 ) %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;, splitrule = \u0026quot;extratrees\u0026quot;, importance = \u0026quot;impurity\u0026quot;) %\u0026gt;% fit(price ~ ., data = train_tbl %\u0026gt;% select(-id, -model, -model_tier)) #Third Line model_05_rand_forest_ranger %\u0026gt;% calc_metrics(test_tbl)  Random Numbers Here are several ways to get random numbers. These examples are informed by the R Cookbook, see here\n# get one random number using runif() from base-R, stats package # default 0 to 1 runif(1) # get two random numbers runif(2) # get a vector of three random numbers # increase range beyond the default, -10 to 110 runif(3, min = -10, max = 110) # ensure three random numbers do *not* have decimals # use floor() function to round down floor(runif(3, min = -10, max = 110)) # sample() function does the same thing - using just one function # replace parameter: should sampling be with or without replacement? sample(-10:110, 3, replace = TRUE) # Reproducibility # use set.seed() before any of the aforementioned random number generators set.seed(123) sample(-10:110, 3, replace = FALSE)  Random Numbers from a Normal Distribution # Get five random numbers from a normal distribution # Here the default is mean = 0, standard deviation = 1. rnorm(5) # Change mean and standard deviation away from default rnorm(5, mean = 66, sd = 12) # Ensure reproducibility with set.seed() set.seed(123) rnorm(5, mean = 66, sd = 12) # Ensure normal distribution by setting sufficiently large number with rnorm() # Ensure reproducibility # Plot a histogram set.seed(123) x \u0026lt;- rnorm(500, mean = 66, sd = 12) hist(x)  ","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"2f98573b9b610f1d3926df768ccda2dd","permalink":"/technical_notes/example_tech/rstats_tip1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/rstats_tip1/","section":"technical_notes","summary":"Understanding reproducibility and the set.seed() function in R is best achieved through generating various random numbers. Here are some more tips for making your work reproducible:\nUsing set.seed() Example of reproducibility in fitting ML models using set.","tags":null,"title":"Make your work reproducible","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTechnical Tip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTechnical Tip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"88f0a6e6ab74e40f15b0be6609fd5342","permalink":"/technical_notes/example_tech/technical_notes2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/technical_notes/example_tech/technical_notes2/","section":"technical_notes","summary":"Here are some more tips for getting started with Academic:\nTechnical Tip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Technical Notes Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"Table of Content:\n  Set Up  Functions  Strings  Exceptions  Lists  Tuples  Dictionaries  defaultdict  Chapter 2: A Crash Course in Python This is the first of many chapters i\u0026rsquo;ll be covering from Joel Grus\u0026rsquo; Data Science from Scratch book (2nd edition). This chapter provides a quick survey of python features needed for \u0026ldquo;doing\u0026rdquo; data science from scratch, including essential setup of virtual environments and other tooling.\nWhile the chapter is not meant to be comprehensive, I may supplement certain sections with external content for greater detail in certain parts.\nMy goal is twofold. First, to go through this book and, as a byproduct, learn python. Second, to look out for and highlight the areas where the pythonic way of doing things is necessary to accomplish something in the data science process.\nAt several sections throughout this chapter, the author emphasises how much a particular feature will be used later in the book (e.g., functions, dictionaries, list, list comprehensions (and for-loops), assert, iterables and generators, randomness, type annotations). Things not used as much (e.g., sets, automated test, subclasses that inherit functionality from a parent class, zip and argument unpacking, args, kwargs).\nAdditional code can be found in this repo\nSetup Installation, Virtual Environment and Modules These section takes the reader through installing a virtual environment using Anaconda Python distribution. The author points out a best practice, \u0026ldquo;you should always work in a virtual environment and never use \u0026lsquo;base\u0026rsquo; Python installation\u0026rdquo;. Moreover, the author favors IPython over jupyter notebooks (he\u0026rsquo;s a noted critic of the notebook)\nThe first time I installed Python, it took me awhile to get things right and eventually I relied on jupyter notebooks through Anaconda. As we go through this book, I\u0026rsquo;ll be using virtual environments and IPython as much as I can (although I may sprinkle in a notebook here and there). My IDE for interacting with the conda virtual environment and IPython will be VSCode.\nFortunately, I had a relatively painless process setting up a virtual environment and IPython, although I had to take a slight detour to setup the code command for VSCode.\nHere\u0026rsquo;s a summary of the commands I used for setup:\nFunctions Three things are emphasized here: passing functions as arguments for other functions, lambda functions and default parameter values.\nThe illustration of functions being passed as arguments is demonstrated below. A function double is created. A function apply_to_one is created. The double function is pointed at my_double. We pass my_double into the apply_to_one function and set that to x.\nWhatever function is passed to apply_to_one, its argument is 1. So passing my_double means we are doubling 1, so x is 2.\nBut the important thing is that a function got passed to another function (aka higher order functions).\ndef double(x): \u0026quot;\u0026quot;\u0026quot; this function doubles and returns the argument \u0026quot;\u0026quot;\u0026quot; return x * 2 def apply_to_one(f): \u0026quot;\u0026quot;\u0026quot;Calls the function f with 1 as its argument\u0026quot;\u0026quot;\u0026quot; return f(1) my_double = double # x is 2 here x = apply_to_one(my_double) # extending this example def apply_five_to(e): \u0026quot;\u0026quot;\u0026quot;returns the function e with 5 as its argument\u0026quot;\u0026quot;\u0026quot; return e(5) # doubling 5 is 10 w = apply_five_to(my_double)  Since functions are going to be used extensively, here\u0026rsquo;s another more complicated example. I found this from Trey Hunner\u0026rsquo;s site. Two functions are defined - square and cube. Both functions are saved to a list called operations. Another list, numbers is created.\nFinally, a for-loop is used to iterate through numbers, and the enumerate property allows access to both index and item in numbers. That\u0026rsquo;s used to find whether the action is a square or cube (operations[0] is square, operations[1] is cube), which is then given as its argument, the items inside the numbers list.\n# create two functions def square(n): return n**2 def cube(n): return n**3 # store those functions inside a list, operations, to reference later operations = [square, cube] # create a list of numbers numbers = [2,1,3,4,7,11,18,29] # loop through the numbers list # using enumerate the identify index and items # [i % 2] results in either 0 or 1, that's pointed at action # using the dunder, name, retrieves the name of the function - either square or cube - from the operations list # print __name__ along with the item from the numbers list # action is either a square or cube for i, n in enumerate(numbers): action = operations[i % 2] print(f\u0026quot;{action.__name__}({n}):\u0026quot;, action(n)) # print square(2): 4 cube(1): 1 square(3): 9 cube(4): 64 square(7): 49 cube(11): 1331 square(18): 324 cube(29): 24389 # more explicit, yet verbose way to write the for-loop for index, num in enumerate(numbers): action = operations[index % 2] print(f\u0026quot;{action.__name__}({num}):\u0026quot;, action(num))  This section also introduces lambda functions (aka anonymous functions) to demonstrate how functions, being first-class in Python, can, like any variable, be passed into the argument of another function. However, with lambda instead of defining functions with def, it is defined inside another function. Here\u0026rsquo;s an illustration:\n# we'll reuse apply_five_to, which takes in a function and provides '5' as the argument def apply_five_to(e): \u0026quot;\u0026quot;\u0026quot;returns the function e with 5 as its argument\u0026quot;\u0026quot;\u0026quot; return e(5) # this lambda function adds '4' to any argument # when passing this lambda function to apply_five_to # you get y = 5 + 4 y = apply_five_to(lambda x: x + 4) # we can also change what the lambda function does without defining a separate function # here the lambda function multiplies the argument by 4 # y = 20 y = apply_five_to(lambda x: x * 4)  Lambda functions are convenient in that you can pass it into another function immediately without having to define it separately, but the consensus seems to be that you should just use def.\nHere\u0026rsquo;s an external example of lambda functions from Trey Hunner. In this example, a lambda function is used within a filter function that takes in two arguments.\n# calling help(filter) displays an explanation class filter(object) | filter(function or None, iterable) --\u0026gt; filter object # create a list of numbers numbers = [2,1,3,4,7,11,18,29] # the lambda function will return n if it is an even number # we filter the numbers list using the lambda function # wrapped in a list, this returns [2,4,18] list(filter(lambda n: n % 2 == 0, numbers))  There are whole books, or at least whole chapters, that can be written about Python functions, but we\u0026rsquo;ll limit our discussion for now to the idea that functions can be passed as arguments to other functions. I\u0026rsquo;ll report back on this section as we progress through the book.\nStrings Strings may not be terribly exciting for data science or machine learning, unless you\u0026rsquo;re getting into natural language processing, so we\u0026rsquo;ll keep it brief here. The key take aways are that backslashes encode special characters and that f-strings is the most updated way to do string interpolation. Here are some examples:\n# point strings to variables (we'll use my name) first_name = \u0026quot;Paul\u0026quot; last_name = \u0026quot;Apivat\u0026quot; # f-string (recommended), 'Paul Apivat' f_string = f\u0026quot;{first_name} {last_name}\u0026quot; # string addition, 'Paul Apivat' string_addition = first_name + \u0026quot; \u0026quot; + last_name # string format, 'Paul Apivat' string_format = \u0026quot;{0} {1}\u0026quot;.format(first_name, last_name) # percent format (NOT recommended), 'Paul Apivat' pct_format = \u0026quot;%s %s\u0026quot; %('Paul','Apivat')  Exceptions The author covers exceptions to make the point that they\u0026rsquo;re not all that bad in Python and it\u0026rsquo;s worth handling exceptions yourself to make code more readable. Here\u0026rsquo;s my own example that\u0026rsquo;s slightly different from the book:\ninteger_list = [1,2,3] heterogeneous_list = [\u0026quot;string\u0026quot;, 0.1, True] # you can sum a list of integers, here 1 + 2 + 3 = 6 sum(integer_list) # but you cannot sum a list of heterogeneous data types # doing so raises a TypeError sum(heterogeneous_list) # the error crashes your program and is not fun to look at --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-12-3287dd0c6c22\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 sum(heterogeneous_list) TypeError: unsupported operand type(s) for +: 'int' and 'str' # so the idea is to handle the exceptions with your own messages try: sum(heterogeneous_list) except TypeError: print(\u0026quot;cannot add objects of different data types\u0026quot;)  At this point, the primary benefits to handling exceptions yourself is for code readability, so we\u0026rsquo;ll come back to this section if we see more useful examples.\nLists Lists are fundamental to Python so I\u0026rsquo;m going to spend some time exploring their features. For data science, NumPy arrays are used frequently, so I thought it\u0026rsquo;d be good to implement all list operations covered in this section in Numpy arrays to tease apart their similarities and differences.\nBelow are the similarities.\nThis implies that whatever can be done in python lists can also be done in numpy arrays, including: getting the nth element in the list/array with square brackets, slicing the list/array, iterating through the list/array with start, stop, step, using the in operator to find list/array membership, checking length and unpacking list/arrays.\n# setup import numpy as np # create comparables python_list = [1,2,3,4,5,6,7,8,9] numpy_array = np.array([1,2,3,4,5,6,7,8,9]) # bracket operations # get nth element with square bracket python_list[0] # 1 numpy_array[0] # 1 python_list[8] # 9 numpy_array[8] # 9 python_list[-1] # 9 numpy_array[-1] # 9 # square bracket to slice python_list[:3] # [1, 2, 3] numpy_array[:3] # array([1, 2, 3]) python_list[1:5] # [2, 3, 4, 5] numpy_array[1:5] # array([2, 3, 4, 5]) # start, stop, step python_list[1:8:2] # [2, 4, 6, 8] numpy_array[1:8:2] # array([2, 4, 6, 8]) # use in operator to check membership 1 in python_list # true 1 in numpy_array # true 0 in python_list # false 0 in numpy_array # false # finding length len(python_list) # 9 len(numpy_array) # 9 # unpacking x,y = [1,2] # now x is 1, y is 2 w,z = np.array([1,2]) # now w is 1, z is 2  Now, here are the differences.\nThese tasks can be done in python lists, but require a different approach for NumPy array including: modification (extend in list, append for array). Finally, lists can store mixed data types, while NumPy array will convert to string.\n# python lists can store mixed data types heterogeneous_list = ['string', 0.1, True] type(heterogeneous_list[0]) # str type(heterogeneous_list[1]) # float type(heterogeneous_list[2]) # bool # numpy arrays cannot store mixed data types # numpy arrays turn all data types into strings homogeneous_numpy_array = np.array(['string', 0.1, True]) # saved with mixed data types type(homogeneous_numpy_array[0]) # numpy.str_ type(homogeneous_numpy_array[1]) # numpy.str_ type(homogeneous_numpy_array[2]) # numpy.str_ # modifying list vs numpy array # lists can use extend to modify list in place python_list.extend([10,12,13]) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] numpy_array.extend([10,12,13]) # AttributeError: 'numpy.ndarray' # numpy array must use append, instead of extend numpy_array = np.append(numpy_array,[10,12,13]) # python lists can be added with other lists new_python_list = python_list + [14,15] # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15] numpy_array + [14,15] # ValueError # numpy array cannot be added (use append instead) # array([ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15]) new_numpy_array = np.append(numpy_array, [14,15]) # python lists have the append attribute python_list.append(0) # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 0] # the append attribute for numpy array is used differently numpy_array = np.append(numpy_array, [0])  Python lists and NumPy arrays have much in common, but there are meaningful differences as well.\nPython Lists vs NumPy Arrays: What\u0026rsquo;s the difference Now that we know that there are meaningful differences, what can we attribute these differences to? This explainer from UCF highlights performance differences including:\n Size Performance Functionality  I\u0026rsquo;m tempted to go down this 🐇 🕳️ of further lists vs array comparisons, but we\u0026rsquo;ll hold off for now.\nTuples Similar to lists, but tuples are immutable.\nmy_list = [1,2] # check type(my_list) my_tuple = (1,2) # check type(my_tuple) other_tuple = 3,4 # tuples don't require parentheses my_list[1] = 3 # lists ARE mutable, my_list is now [1,3] # exception handling when trying to change tuple try: my_tuple[1] = 3 except TypeError: print(\u0026quot;tuples are immutable\u0026quot;)  Tuples are good at returning multiple values from functions:\n# use tuple to return multiple values def sum_and_product(x,y): \u0026quot;\u0026quot;\u0026quot;you can return multiple values from functions using tuples\u0026quot;\u0026quot;\u0026quot; return (x + y), (x * y) sp = sum_and_product(4,5) # sp is (9,20), a tuple  However, lists can also be used to return multiple values:\ndef sum_and_product_list(x,y): return [(x + y), (x * y)] spl = sum_and_product_list(5,6) # [11, 30] type(spl) # list  Finally, both tuples and lists can be used for multiple assignments, here\u0026rsquo;s a pythonic way to swap variables:\nx, y = 1,2 x,y = y,x  Tuples, for the most part, seem to be redundant with lists, but we\u0026rsquo;ll see if there are special use-cases for immutability down the line.\nDictionaries Dictionaries are good for storing structured data. They have a key/value pair so you can look up values of certain keys. The author provides some ways to initialize a dictionary, with comments about what is more or less pythonic (I\u0026rsquo;ll take the author\u0026rsquo;s word for it, but open to other perspectives).\nSome of the things you can do with dictionaries are query keys, values, assign new key/value pairs, check for existence of keys or retrieve certain values.\nempty_dict = {} # most pythonic empty_dict2 = dict() # less pythonic grades = {\u0026quot;Joel\u0026quot;: 80, \u0026quot;Grus\u0026quot;: 99} # dictionary literal type(grades) # type check, dict # use bracket to look up values grades[\u0026quot;Grus\u0026quot;] # 99 grades[\u0026quot;Joel\u0026quot;] # 80 # KeyError for looking up non-existent keys try: kate_grades = grades[\u0026quot;Kate\u0026quot;] except KeyError: print(\u0026quot;That key doesn't exist\u0026quot;) # use in operator to check existence of key joe_has_grade = \u0026quot;Joel\u0026quot; in grades joe_has_grade # true kate_does_not = \u0026quot;Kate\u0026quot; in grades kate_does_not # false # use 'get' method to get values in dictionaries grades.get(\u0026quot;Joel\u0026quot;) # 80 grades.get(\u0026quot;Grus\u0026quot;) # 99 grades.get(\u0026quot;Kate\u0026quot;) # default: None # assign new key/value pair using brackets grades[\u0026quot;Tim\u0026quot;] = 93 grades # {'Joel': 80, 'Grus': 99, 'Tim': 93}  Dictionaries are good for representing structured data that can be queries. The key take-away here is that in order to iterate through dictionaries to get either keys, values or both, we\u0026rsquo;ll need to use specific methods likes keys(), values() or items().\ntweet = { \u0026quot;user\u0026quot;: \u0026quot;paulapivat\u0026quot;, \u0026quot;text\u0026quot;: \u0026quot;Reading Data Science from Scratch\u0026quot;, \u0026quot;retweet_count\u0026quot;: 100, \u0026quot;hashtags\u0026quot;: [\u0026quot;#66daysofdata\u0026quot;, \u0026quot;datascience\u0026quot;, \u0026quot;machinelearning\u0026quot;, \u0026quot;python\u0026quot;, \u0026quot;R\u0026quot;] } # query specific values tweet[\u0026quot;retweet_count\u0026quot;] # 100 # query values within a list tweet[\u0026quot;hashtags\u0026quot;] # ['#66daysofdata', 'datascience', 'machinelearning', 'python', 'R'] tweet[\u0026quot;hashtags\u0026quot;][2] # 'machinelearning' # retrieve ALL keys tweet_keys = tweet.keys() tweet_keys # dict_keys(['user', 'text', 'retweet_count', 'hashtags']) type(tweet_keys) # different data type: dict != dict_keys # retrieve ALL values tweet_values = tweet.values() tweet_values # dict_values(['paulapivat', 'Reading Data Science from Scratch', 100, ['#66daysofdata', 'datascience', 'machinelearning', 'python', 'R']]) type(tweet_values) # different data type: dict != dict_values # create iterable for Key-Value pairs (in tuple) tweet_items = tweet.items() # iterate through tweet_items() for key,value in tweet_items: print(\u0026quot;These are the keys:\u0026quot;, key) print(\u0026quot;These are the values:\u0026quot;, value) # cannot iterate through original tweet dictionary # ValueError: too many values to unpack (expected 2) for key, value in tweet: print(key) # cannot use 'enumerate' because that only provides index and key (no value) for key, value in enumerate(tweet): print(key) # print 0 1 2 3 - index values print(value) # user text retweet_count hashtags (incorrectly print keys)  Just like in lists and tuples, you can use the in operator to find membership. The one caveat is you cannot look up values that are in lists, unless you use bracket notation to help.\n# search keys \u0026quot;user\u0026quot; in tweet # true \u0026quot;bball\u0026quot; in tweet # false \u0026quot;paulapivat\u0026quot; in tweet_values # true 'python' in tweet_values # false (python is nested in 'hashtags') \u0026quot;hashtags\u0026quot; in tweet # true # finding values inside a list requires brackets to help 'python' in tweet['hashtags'] # true  What is or is not hashable?\nDictionary keys must be hashable.\nStrings are hashable. So we can use strings as dictionary keys, but we cannot use lists because they are not hashable.\npaul = \u0026quot;paul\u0026quot; type(paul) # check type, str hash(paul) # -3897810863245179227 ; strings are hashable paul.__hash__() # -3897810863245179227 ; another way to find the hash jake = ['jake'] # this is a list type(jake) # check type, list # lists are not hashable - cannot be used as dictionary keys try: hash(jake) except TypeError: print('lists are not hashable')  defaultdict defaultdict is a subclass of dictionaries (dict, see previous post), so it inherits most of its behavior from dict with additional features. To understand how those features make it different, and more convenient in some cases, we\u0026rsquo;ll need to run into some errors.\nIf we try to count words in a document, the general approach is to create a dictionary where the dictionary keys are words and the dictionary values are counts of those words.\nLet\u0026rsquo;s try do do this with a regular dictionary.\nFirst, to setup, we\u0026rsquo;ll take a list of words and split() into individual words. I took this paragraph from another project i\u0026rsquo;m working on and artificially added some extra words to ensure that certain words appeared more than once (it\u0026rsquo;ll be apparent why soon).\n# paragraph lines = [\u0026quot;This table highlights 538's new NBA statistic, RAPTOR, in addition to the more established Wins Above Replacement (WAR). An extra column, Playoff (P/O) War, is provided to highlight stars performers in the post-season, when the stakes are higher. The table is limited to the top-100 players who have played at least 1,000 minutes minutes the table Wins NBA NBA RAPTOR more players\u0026quot;] # split paragraphy into individual words lines = \u0026quot; \u0026quot;.join(lines).split() type(lines) # list  Now that we have our lines list, we\u0026rsquo;ll create an empty dict called word_counts and have each word be the key and each value be the count of that word.\n# empty list word_counts = {} # loop through lines to count each word for word in lines: word_counts[word] += 1 # KeyError: 'This'  We received a KeyError for the very first word in lines (i.e. \u0026lsquo;This\u0026rsquo;) because the list tried to count a key that didn\u0026rsquo;t exist. We\u0026rsquo;ve learned to handle exceptions so we can use try and except.\nHere, we\u0026rsquo;re looping through lines and when we try to count a key that doesn\u0026rsquo;t exist, like we did previously, we\u0026rsquo;re now anticipating a KeyError and will set the initial count to 1, then it can continue to loop-through and count the word, which now exists, so it can be incremented up.\n# empty list word_counts = {} # exception handling for word in lines: try: word_counts[word] += 1 except KeyError: word_counts[word] = 1 # call word_counts # abbreviated for space word_counts {'This': 1, 'table': 3, 'highlights': 1, \u0026quot;538's\u0026quot;: 1, 'new': 1, 'NBA': 3, 'statistic,': 1, 'RAPTOR,': 1, 'in': 2, 'addition': 1, 'to': 3, 'the': 5, 'more': 2, ... 'top-100': 1, 'players': 2, 'who': 1, 'have': 1, 'played': 1, 'at': 1, 'least': 1, '1,000': 1, 'minutes': 2, 'RAPTOR': 1}  Now, there are other ways to achieve the above:\n# use conditional flow word_counts = {} for word in lines: if word in word_counts: word_counts[word] += 1 else: word_counts[word] = 1 # use get for word in lines: previous_count = word_counts.get(word, 0) word_counts[word] = previous_count + 1  Here\u0026rsquo;s where the author makes the case for defaultdict, arguing that the two aforementioned approaches are unweildy. We\u0026rsquo;ll come back full circle to try our first approach, using defaultdict instead of the traditional dict.\ndefaultdict is a subclass of dict and must be imported from collections:\nfrom collections import defaultdict word_counts = defaultdict(int) for word in lines: word_counts[word] += 1 # we no longer get a KeyError # abbreviated for space defaultdict(int, {'This': 1, 'table': 3, 'highlights': 1, \u0026quot;538's\u0026quot;: 1, 'new': 1, 'NBA': 3, 'statistic,': 1, 'RAPTOR,': 1, 'in': 2, 'addition': 1, 'to': 3, 'the': 5, 'more': 2, ... 'top-100': 1, 'players': 2, 'who': 1, 'have': 1, 'played': 1, 'at': 1, 'least': 1, '1,000': 1, 'minutes': 2, 'RAPTOR': 1})  Unlike a regular dictionary, when defaultdict tries to look up a key it doesn\u0026rsquo;t contain, it\u0026rsquo;ll automatically add a value for it using the argument we provided when we first created the defaultdict. If you see above, we entered an int as the argument, which allows it to automatically add a value.\nCounters Sets Control Flow Truthiness Sorting List Comprehensions Automated Testing and assert Object-Oriented Programming Iterables and Generators Randomness Regular Expressions zip and Argument Unpacking args and kwargs Type Annotations How to Write Type Annotations  ","date":1603411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603929600,"objectID":"fe52d559d8278a6cef401ac4e9c1f24f","permalink":"/post/dsfs_2/","publishdate":"2020-10-23T00:00:00Z","relpermalink":"/post/dsfs_2/","section":"post","summary":"Survey of python features relevant for Data Science","tags":[],"title":"Data Science from Scratch (ch2)","type":"post"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"Preparing API endpoints in Python with Flask In this post, we\u0026rsquo;ll create a minimal API endpoint that allows users to make request to calculate the area of a rectangle. The following code sets up an API endpoint locally. We\u0026rsquo;ll import Flask, a lightweight web application framework and CORS (cross-origin resource sharing) which allows for various HTTP requests.\nWe have two endpoints, one basic \u0026ldquo;hello world\u0026rdquo; and the other calculate the area (i.e., width x height).\nThis is saved in App.py. The command to run this file is $ python3 App.py. The last line ensures the API is running locally on localhost:5000.\nfrom flask import Flask, request from flask_cors import CORS, cross_origin import joblib import numpy as np app = Flask(__name__) CORS(app) @app.route('/') def helloworld(): return 'Helloworld' # Example request: http://localhost:5000/area?w=50\u0026amp;h=3 @app.route('/area', methods=['GET']) @cross_origin() def area(): w = float(request.values['w']) h = float(request.values['h']) return str(w * h) if __name__ == '__main__': app.run(host='0.0.0.0', port=5000, debug=True)  You can just run localhost:5000 and get Helloworld or make a request to get the area, for example: http://localhost:5000/area?w=20\u0026amp;h=33 (this yeilds 660)\nTraining a Logistic Regression classification model After setting up some API endpoints, it\u0026rsquo;s time to create a basic machine learning model. We\u0026rsquo;ll create a logistic regression model to classify flowers from the Iris dataset. This will be created in one jupyter notebook.\nWe\u0026rsquo;ll load all required libraries.\nfrom sklearn.datasets import load_iris from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import joblib import numpy as np import pandas as pd  Then, we\u0026rsquo;ll load the Iris dataset that comes with scikit learn, sklearn.\niris = load_iris() # assign two variables at once X, y = iris['data'], iris['target']  We\u0026rsquo;ll reshape the data using numpy, then split the data into training and validation sets.\n# reshape data for logistic regression dataset = np.hstack((X, y.reshape(-1,1))) np.random.shuffle(dataset) # split data into training, validation sets X_train, X_test, y_train, y_test = train_test_split(dataset[:, :4], dataset[:, 4], test_size=0.2)  We\u0026rsquo;ll then fit a logistic regression model by fitting the training set to the validation set.\nmodel = LogisticRegression() model.fit(X_train, y_train)  Then, we\u0026rsquo;ll use the model to predict on the validation data (note: in a real project a distinction is made between validation and testing sets, but we\u0026rsquo;ll blur that distinction for this demo). You can also test the model to make a prediction on a single observation.\nIt\u0026rsquo;s also a good idea to get the accuracy_score(), although it may not be ideal for classification models.\n# make a prediction y_pred = model.predict(X_test) # get accuracy score accuracy_score(y_test, y_pred) # make prediction on single Iris obervation model.predict([[5.1, 3.5, 1.4, 0.2]])  Finally, we need to use joblib to save an iris.model to our directory, this will be used to connect to the API.\njoblib.dump(model, 'iris.model')  Creating an API endpoint for the Logistic Regression model Back in the App.py file, we\u0026rsquo;ll add this section to create an endpoint, the predict_species() function that loads the iris.model, then sends a Post request of the four parameter values from iris['data']. The predict_species() function will then return one of three flower species.\n@app.route('/iris', methods=['POST']) @cross_origin() def predict_species(): model = joblib.load('iris.model') #needs to be the correct path req = request.values['param'] inputs = np.array(req.split(','), dtype=np.float32).reshape(1,-1) predict_target = model.predict(inputs) if predict_target == 0: return 'Setosa' elif predict_target == 1: return 'Versicolor' else: return 'Virginica'  Testing the API endpoint on Postman Finally, we\u0026rsquo;ll use Postman, a platform for API development. We will post four parameters (i.e., sepal length, sepal width, petal length and petal width) to the API endpoint and expect to receive a name back, either Setosa, Versicolor or Virginica. In Postman, we\u0026rsquo;ll create a new collection and a new request:\nThe next step from here is to go beyond localhost and deploy the model. We\u0026rsquo;ll explore that in another post.\n","date":1602288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602288000,"objectID":"3e324bdd4365e43d8e215c6ff3eaacf1","permalink":"/post/mlaas/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/post/mlaas/","section":"post","summary":"Connecting models to an API","tags":[],"title":"Machine learning as a service","type":"post"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"Data Science Literature Review I saw an intriguing question posed on Twitter and some of the responses were illuminating.\nHere\u0026rsquo;s another variant of the question:\nAlthough Data Science has a long history, it\u0026rsquo;s considered a relatively young field.\nThis space will be used to document recommended reading for new entrants:\n  Downey, Allen (2016) There is only one test. source\n  Wickham, Hadley (2014) Tidy Data. The Journal of Statistical Software, vol 59. original, update\n  James, G., Witten, D., Hastie, T. \u0026amp; Tibshirani, R. (2014) An Introduction to Statistical Learning with Applications in R. source\n  Shmueli, G. (2010) To explain or to predict? Statistical Science, 25(3), 289-310. source\n  Hernan, M.A., Hsu, J. \u0026amp; Healy, B. (2019) A second chance to get causal inference right: A classification of Data Science tasks. Chance, vol 32(1). source\n  Gelman, A., Pasarica, C. \u0026amp; Dodhia, R. (2002) Let\u0026rsquo;s practice what we preach: Turning tables into graphs. The American Statistician, vol 56(2). source\n  Scott Formann-Roe (June, 2012) Understanding the Bias-Variance Tradeoff. source\n  Donoho, D (2017) 50 Years of Data Science. Journal of Computational and Graphical Statistics, vol 26(4). source\n  Wilson, G., Bryan, J., Cranston, K., Kitzes, J., Nederbragt, L. \u0026amp; Teal, T.K. (2017) Good enough practices in scientific computing. Plos Computational Biology. source\n  Kevin Markham (2019) 100 pandas tricks to save you time and energy. source\n  Chris Albon\u0026rsquo;s code snippets. source\n  Howard, J. \u0026amp; Gugger, S. (Aug 4, 2020) Deep Learning for Coders with fastai and PyTorch: AI Applications without a PhD 1st Ed. source\n  Brandon Rohrer (Jan, 2020) End-to-End Machine Learning: Complete Course Catalog. source; second source\n  John Rauser (Dec, 2016) How Humans See Data youtube\n  Broman, K.W. \u0026amp; Woo, K.H. (2018) Data Organization in Spreadsheets. The American Statistician, vol 72(1). source\n  Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., Chaudhary, V., \u0026amp; Young, M. (2014) Machine Learning: The High Interest Credit Card of Technical Debt. source\n  3Blue1Brown for Linear Algebra youtube\n  Jenny Bryan. Stat 545: Data Wrangling, Exploration and Analysis with R. source\n  ","date":1599696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599696000,"objectID":"dd5da896834a7a9098bf7fba0cee62e1","permalink":"/post/data_science_canon/","publishdate":"2020-09-10T00:00:00Z","relpermalink":"/post/data_science_canon/","section":"post","summary":"What is Data Science canon?","tags":[],"title":"Essential Readings in Data Science","type":"post"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"TidyTuesday 2020-08-18 (week 34) In the process of exploring dendrograms, I create jheri curls :)\nAnother plot with less hair:\nI call this Disco Fire:\n","date":1599091200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599091200,"objectID":"6261ecf04eb95d1221396c4abdf09c2e","permalink":"/post/ggplot_art/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/post/ggplot_art/","section":"post","summary":"TidyTuesday Outtakes","tags":[],"title":"A collection of weird pretty plots","type":"post"},{"authors":[],"categories":[],"content":" Context In web development, functions are everywhere and are written to get even the smallest tasks done like allowing users to click on a button or controlling where and how a pop-up modal appears. In data analysis, you can go without using functions as long as you’re working on small scale projects and do not need to share your code with others.\nMoreover, they can make your life a lot easier if you want to avoid copying and pasting your code in a bunch of different places (it also makes your code less error prone and easier to update).\nFunctions may require a slight perspective shift for those who aren’t familiar. In this post, I want to share how I snuck functions into my workflow for a specific project.\n Slipping Custom Functions into the Workflow The most intuitive way, in my opinion, to introduce functions is to take a certain data pre-processing sequence and turn it into a function. Below, I have a newly created dataframe called net_sales_year_month that is a dataframe with three columns (net_sales, Year, Month).\nSuppose my objective is to add a Day and month_year column, that combines Year, Month and Day (yyyy-mm-dd) into a date type. The pre-processing task would be to take net_sales_year_month and use the mutate function to create some new columns.\nThis is fine and well if you’re doing this one time, but what if you need to repeat this operation on multiple columns?\nThat’s where a custom function comes in.\nFor example, the function below called create_ymd_function simply replaces net_sales_year_month with a generic data, serving as the function parameter. Now any dataframe can be used as a parameter for the create_ymd_function.\nNote the BEFORE and AFTER sections below - they have the same output, but one is a more general function that can be used with other data frames.\n# Selecting columns to work with (net_sales) net_sales_year_month \u0026lt;- retail_sales2 %\u0026gt;% select(`Net Sales`, Year, Month) %\u0026gt;% rename(net_sales = `Net Sales`) # BEFORE net_sales_year_month %\u0026gt;% mutate( Day = 1, month_year = paste(Year, Month, Day), month_year = month_year %\u0026gt;% ymd(), month = month(month_year) ) ## # A tibble: 36 x 6 ## net_sales Year Month Day month_year month ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; ## 1 8284. 2017 January 1 2017-01-01 1 ## 2 6388. 2017 February 1 2017-02-01 2 ## 3 4589. 2017 March 1 2017-03-01 3 ## 4 8533. 2017 April 1 2017-04-01 4 ## 5 6237. 2017 May 1 2017-05-01 5 ## 6 9370. 2017 June 1 2017-06-01 6 ## 7 5959. 2017 July 1 2017-07-01 7 ## 8 7740. 2017 August 1 2017-08-01 8 ## 9 6732. 2017 September 1 2017-09-01 9 ## 10 5327 2017 October 1 2017-10-01 10 ## # … with 26 more rows # AFTER # Function takes in dataframe to add columns for further analysis create_ymd_function \u0026lt;- function(data) { data %\u0026gt;% mutate( Day = 1, month_year = paste(Year, Month, Day), month_year = month_year %\u0026gt;% ymd(), month = month(month_year) ) } create_ymd_function(net_sales_year_month) ## # A tibble: 36 x 6 ## net_sales Year Month Day month_year month ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; ## 1 8284. 2017 January 1 2017-01-01 1 ## 2 6388. 2017 February 1 2017-02-01 2 ## 3 4589. 2017 March 1 2017-03-01 3 ## 4 8533. 2017 April 1 2017-04-01 4 ## 5 6237. 2017 May 1 2017-05-01 5 ## 6 9370. 2017 June 1 2017-06-01 6 ## 7 5959. 2017 July 1 2017-07-01 7 ## 8 7740. 2017 August 1 2017-08-01 8 ## 9 6732. 2017 September 1 2017-09-01 9 ## 10 5327 2017 October 1 2017-10-01 10 ## # … with 26 more rows net_sales_year_month_2 \u0026lt;- create_ymd_function(net_sales_year_month)  Generalizing Functions Here’s another example of moving from specific to general functions.\nWith the create_line_chart function, i’m taking in a dataframe, piping into ggplot and visualizing a simple line graph with geom_line. You’ll note it is specific because it requires the dataframe to have a column named net_sales in order to work.\nBut what if I wanted to repeat this operation with total_orders or total_sales or some other metric?\nRight below, I create a more general function, create_line_chart_general that takes in any dataset and two columns as the function parameter.\nThis makes the function much more re-usable. However, it also introduces some R-specific commands like enquo() and !! to quote and unquote parameters for use in the function. We are entering lazy evaluation territory, which I’ll save for another post!\n# BEFORE: # This function only works for net_sales # It\u0026#39;s easy to just slip \u0026#39;data\u0026#39; as an argument # But the aesthetic mapping is done only one a specific column create_line_chart \u0026lt;- function(data){ data %\u0026gt;% ggplot(aes(x = month_year, y = net_sales)) + geom_line() } # AFTER: # This is a more generalizable function using enquo() and \u0026#39;!!\u0026#39; # note columns as function parameters create_line_chart_general \u0026lt;- function(dataset, col_name_1, col_name_2){ col_name_1 \u0026lt;- enquo(col_name_1) col_name_2 \u0026lt;- enquo(col_name_2) dataset %\u0026gt;% ggplot(aes(x = !!(col_name_1), y = !!(col_name_2))) + geom_line() } # Call the function with data and necessary parameters create_line_chart_general(net_sales_year_month_2, month_year, net_sales)  More Generalized Function This next function is slightly more complicated as it involves creating several more columns. But it can still be generalized using the tools discussed above.\ncreate_bpc_columns_general \u0026lt;- function(dataset, col_name){ col_name \u0026lt;- enquo(col_name) bpc_data \u0026lt;- dataset %\u0026gt;% mutate( avg_orders = mean(!!(col_name)), # calculate lagging difference moving_range = diff(as.zoo(!!(col_name)), na.pad=TRUE), # get absolute value moving_range = abs(moving_range), # change NA to 0 moving_range = ifelse(row_number()==1, 0, moving_range), avg_moving_range = mean(moving_range), lnpl = avg_orders - (2.66*avg_moving_range), lower_25 = avg_orders - (1.33*avg_moving_range), upper_25 = avg_orders + (1.33*avg_moving_range), unpl = avg_orders + (2.66*avg_moving_range) ) return(bpc_data) } create_bpc_columns_general(net_sales_year_month_2, net_sales) ## # A tibble: 36 x 13 ## net_sales Year Month Day month_year month avg_orders moving_range ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;date\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 8284. 2017 Janu… 1 2017-01-01 1 9058. 0 ## 2 6388. 2017 Febr… 1 2017-02-01 2 9058. 1896. ## 3 4589. 2017 March 1 2017-03-01 3 9058. 1798. ## 4 8533. 2017 April 1 2017-04-01 4 9058. 3944. ## 5 6237. 2017 May 1 2017-05-01 5 9058. 2295. ## 6 9370. 2017 June 1 2017-06-01 6 9058. 3132. ## 7 5959. 2017 July 1 2017-07-01 7 9058. 3410. ## 8 7740. 2017 Augu… 1 2017-08-01 8 9058. 1781. ## 9 6732. 2017 Sept… 1 2017-09-01 9 9058. 1008. ## 10 5327 2017 Octo… 1 2017-10-01 10 9058. 1405. ## # … with 26 more rows, and 5 more variables: avg_moving_range \u0026lt;dbl\u0026gt;, ## # lnpl \u0026lt;dbl\u0026gt;, lower_25 \u0026lt;dbl\u0026gt;, upper_25 \u0026lt;dbl\u0026gt;, unpl \u0026lt;dbl\u0026gt; net_sales_bpc_data \u0026lt;- create_bpc_columns_general(net_sales_year_month_2, net_sales)  Generalized Functions for Visualization This was the trickiest to convert into a general function and I’m still on the fence as to whether this is generalizable. In one sense, it is generalizable as I tested this create_bpc_visualization_general function on another column aside from net_sales, but it did require that I know that other columns in the dataset are: avg_orders, unpl, lnpl, upper_25 and lower_25.\nI have more exploring to do around quoting and unquoting enquo(), quos() for various ggplot geometries like geom_hline. Will report back with another post once I get those details down.\ncreate_bpc_visualization_general \u0026lt;- function(dataset, col_x, col_y, col_avg, col_unpl, col_lnpl, col_upper_25, col_lower_25){ col_x \u0026lt;- enquo(col_x) # month_year col_y \u0026lt;- enquo(col_y) # net_sales col_avg \u0026lt;- dataset$avg_orders col_unpl \u0026lt;- dataset$unpl col_lnpl \u0026lt;- dataset$lnpl col_upper_25 \u0026lt;- dataset$upper_25 col_lower_25 \u0026lt;- dataset$lower_25 dataset %\u0026gt;% ggplot(aes(x = !!(col_x), y = !!(col_y))) + geom_line() + geom_hline(yintercept = col_avg, color = \u0026#39;green\u0026#39;) + geom_hline(yintercept = col_unpl, color = \u0026#39;red\u0026#39;, linetype = \u0026#39;dashed\u0026#39;) + geom_hline(yintercept = col_lnpl, color = \u0026#39;red\u0026#39;, linetype = \u0026#39;dashed\u0026#39;) + geom_hline(yintercept = col_upper_25, color = \u0026#39;orange\u0026#39;) + geom_hline(yintercept = col_lower_25, color = \u0026#39;orange\u0026#39;) + # break x-axis into quarters scale_x_date(breaks = \u0026#39;3 month\u0026#39;) + # note: place before theme() theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + labs( title = glue(\u0026#39;{names(dataset[,1])}: Business Process Chart\u0026#39;), subtitle = \u0026quot;2017 - 2019\u0026quot;, x = \u0026quot;\u0026quot;, y = glue(\u0026#39;{names(dataset[,1])}\u0026#39;), caption = \u0026quot;----\u0026quot; ) + annotate(\u0026quot;text\u0026quot;, x = as.Date(\u0026quot;2017-02-01\u0026quot;), y = col_unpl, color = \u0026#39;red\u0026#39;, label = \u0026quot;UNLP\u0026quot;) + annotate(\u0026quot;text\u0026quot;, x = as.Date(\u0026quot;2017-02-01\u0026quot;), y = col_lnpl, color = \u0026#39;red\u0026#39;, label = \u0026quot;LNLP\u0026quot;) + annotate(\u0026quot;text\u0026quot;, x = as.Date(\u0026quot;2017-02-01\u0026quot;), y = col_upper_25, color = \u0026#39;orange\u0026#39;, label = \u0026quot;Upper 25%\u0026quot;) + annotate(\u0026quot;text\u0026quot;, x = as.Date(\u0026quot;2017-02-01\u0026quot;), y = col_avg, color = \u0026#39;green\u0026#39;, label = \u0026quot;Avg = 97\u0026quot;) } create_bpc_visualization_general(net_sales_bpc_data, month_year, net_sales, avg_orders, unpl, lnpl, upper_25, lower_25)  Summary It’s possible to do a fair amount of data analysis without using functions, but functions help you avoid endless copying and pasting and make your code less error prone.\nThere are many different types functions you could use. In this post, I share functions that take columns of data as arguments. These types of functions are well-suited for streamlining your data pre-processing and visualization tasks.\nShout out to Bruno Rodrigues for writing Modern R with the Tidyverse which has helped me get my head around writing custom functions.\n ","date":1596067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593091452,"objectID":"5e255caaa66f013d921626e5335a4768","permalink":"/post/custom-functions/","publishdate":"2020-07-30T00:00:00Z","relpermalink":"/post/custom-functions/","section":"post","summary":"Writing custom functions to automate data manipulation and visualization tasks","tags":[],"title":"Introducing Custom Functions into the Workflow","type":"post"},{"authors":[],"categories":[],"content":" Data Wrangling I’ve had experiencing using several of the functions in this portion of #DS4B 101, like select(), filter(), distinct(), group_by(), summarize() and so on, but this course is making me realize i’ve only skimmed the surface of dplyr.\nRecommended for anyone learning R who wants to level-up.\n Select \u0026amp; Arrange I’ve used the select function before, but I haven’t used it, really.\nI had previously selected by column name, never by numeric vector; and I had never used select_helpers (starts_with, contains, matches, num_range). I had never re-arranged columns using select(). Select_if() also comes in handy as well. Knowing data types allow for efficient selection (integer vs double).\nI’ve used arrange() and desc(), so I don’t go into too much detail here.\nlibrary(tidyverse) ## ── Attaching packages ──────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.1 ✓ purrr 0.3.3 ## ✓ tibble 3.0.1 ✓ dplyr 0.8.5 ## ✓ tidyr 1.0.0 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.4.0 ## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() # select first three columns using numeric vector USArrests %\u0026gt;% select(1:3) # re-arrange columns using select; place UrbanPop first USArrests %\u0026gt;% select(UrbanPop, everything()) # select if integer USArrests %\u0026gt;% select_if(is.integer) USArrests %\u0026gt;% select_if(~ !is.double(.)) # select if double USArrests %\u0026gt;% select_if(is.double) USArrests %\u0026gt;% select_if(~ !is.integer(.)) # swithing to IRIS dataframe # select helpers: starts_with, contains iris %\u0026gt;% select(starts_with(\u0026quot;petal\u0026quot;)) iris %\u0026gt;% select(contains(\u0026quot;length\u0026quot;)) %\u0026gt;% head() # using pull() instead of select() to pull out contents of a column iris %\u0026gt;% pull(Sepal.Width) %\u0026gt;% head() iris %\u0026gt;% select_if(is.factor) %\u0026gt;% head() # arrange Species in descending order by Petal.Length iris %\u0026gt;% select(Petal.Length, Species) %\u0026gt;% arrange(desc(Petal.Length))  Slice: Highlighting a Distinction between Base and Tidyverse Using slice() to grab portions of rows is another function I had not used prior. I might have used base R to grab specific rows. But looking back all my Base R operations were one-offs. Below is an example, I may use Base-R to grab the first five rows of a dataframe. If I wanted to sort by a particular column, then grab the first give rows, it turns into two operations. First sorting by column, decreasing and assigning to ‘x’, then grabing first five rows of ‘x’.\nWith dplyr, particularly patterns taught in the class, you can more seamlessly arrange, in descending order by a particular column (Solar.R), then slice the first five rows.\n# tidyverse to grab first five rows with slice(), but this allows pre-arranging it first. airquality %\u0026gt;% arrange(desc(Solar.R)) %\u0026gt;% slice(1:5) # base R to grab first five rows airquality[1:5,] # base R to first sort by Solar.R, then assign to variable \u0026#39;x\u0026#39;, then grab first five values x \u0026lt;- sort(airquality$Solar.R, decreasing = TRUE) x[1:5] # fastest way to grab Solar.R sort(airquality$Solar.R, decreasing = TRUE)[1:5]  Spread and Gather Here demonstrating gather() and spread() using the built-in iris dataset. The\n# gather (before spread) iris %\u0026gt;% # create unique ID for each row mutate(ID=row_number(Species)) %\u0026gt;% # put ID in first column select(ID, everything()) %\u0026gt;% # use values from columns 2-5 as value gather(key = Measure_Type, value = Values,2:5) %\u0026gt;% # can spread by either Measure_Type or Species spread(key = Species, value = Values)  Filter and Mutate with nested pipes Using both airquality and USArrests to demonstrate various data wrangling operations involving filter and mutate with nested pipes. I can’t believe I’ve only filtered one column at a time.\n# filter airquality for beginning and end of the month airquality %\u0026gt;% filter(Day \u0026lt; 5 | Day \u0026gt; 25) airquality %\u0026gt;% filter(Temp \u0026lt; 71 \u0026amp; Temp \u0026gt; 64) # Filter states that start with a certain alphabet USArrests # convert row name to column USArrest_rownames \u0026lt;- tibble::rownames_to_column(USArrests, \u0026quot;States\u0026quot;) # Descriptive statistics of Violence_Type by all States that start with \u0026quot;New\u0026quot; USArrest_rownames %\u0026gt;% select(States, UrbanPop, everything()) %\u0026gt;% filter(States %\u0026gt;% str_detect(\u0026quot;New\u0026quot;)) %\u0026gt;% # good to define which columns will be gather() in new column gather(`Murder`, `Assault`, `Rape`, key = \u0026quot;Violence_Type\u0026quot;, value = \u0026quot;cases\u0026quot; ) %\u0026gt;% group_by(Violence_Type) %\u0026gt;% summarize( avg = mean(cases), min = min(cases), max = max(cases) ) %\u0026gt;% ungroup() %\u0026gt;% mutate(avg = round(avg,1)) # Filter by states starting with \u0026quot;A\u0026quot; and murder higher than 10 USArrest_rownames %\u0026gt;% filter(Murder \u0026gt; 10, States %\u0026gt;% str_detect(\u0026quot;A\u0026quot;)) # filter for all states beginning with \u0026quot;New\u0026quot; USArrest_rownames %\u0026gt;% filter(States %\u0026gt;% str_detect(\u0026quot;New\u0026quot;)) %\u0026gt;% arrange(desc(Assault)) USArrest_rownames %\u0026gt;% filter(Murder \u0026gt; 5, States %\u0026gt;% str_detect(\u0026quot;M\u0026quot;)) %\u0026gt;% arrange(desc(Murder))  Handling Missing Values: Replace NA summarize_all() and replace_na() are a joy to use for handling missing values.\n# Quickly get number of \u0026quot;missing values\u0026quot; for all columns airquality %\u0026gt;% summarize_all(~sum(is.na(.))) # Get proportion of missing values for each column airquality %\u0026gt;% summarize_all(~ sum(is.na(.)) / length(.)) # Quickly replace missing values in columns Ozone and Solar.R with \u0026#39;0\u0026#39; airquality %\u0026gt;% replace_na(list(Ozone = 0, Solar.R = 0))  Chaining Multiple Pipes The coding patterns covered in this course is my biggest take-away thus far.\nPreviously, I had not used longer patterns of piping to explore data. Much of my code involved maybe 2-3 pipes, saving a new dataframe, then continuing to explore. Here i’m piping seven operations without creating a new dataframe and it allows for more efficient exploration, without having to save extra data frames.\nMaking me re-think my approach to data wrangling.\n# Chaining multiple pipes to more efficiently explore data iris %\u0026gt;% group_by(Species) %\u0026gt;% summarize( count = n(), mean = mean(Petal.Length), median = median(Petal.Length), sd = sd(Petal.Length), min = min(Petal.Length), max = max(Petal.Length) ) %\u0026gt;% ungroup() %\u0026gt;% mutate(Range = max - min) %\u0026gt;% rename( `Standard Deviation` = sd, `Average` = mean, `Mininum` = min, `Maximum` = max ) %\u0026gt;% arrange(desc(Average))  ","date":1593475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593523452,"objectID":"72fbb2a0cd22040eeddcf45c449bc240","permalink":"/post/ds4b-data-wrangling/","publishdate":"2020-06-30T00:00:00Z","relpermalink":"/post/ds4b-data-wrangling/","section":"post","summary":"Cover data wrangling foundations in dplyr","tags":[],"title":"Data Wrangling Foundations","type":"post"},{"authors":[],"categories":[],"content":" Packages and Libraries library(maps) library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.1 ✓ purrr 0.3.3 ## ✓ tibble 3.0.1 ✓ dplyr 0.8.5 ## ✓ tidyr 1.0.0 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.4.0 ## ── Conflicts ───────────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() ## x purrr::map() masks maps::map() library(sp) library(rmarkdown) library(knitr) opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)  World and Thai Maps First, we’ll use map_data function from ggplot2 to turn any map from the maps package into a data frame. This provides longitude and lattitude data. Then, we’ll filter for Thailand to get Thai longtitude and lattitude data.\nworld.map \u0026lt;- map_data(\u0026quot;world\u0026quot;) head(world.map) ## long lat group order region subregion ## 1 -69.89912 12.45200 1 1 Aruba \u0026lt;NA\u0026gt; ## 2 -69.89571 12.42300 1 2 Aruba \u0026lt;NA\u0026gt; ## 3 -69.94219 12.43853 1 3 Aruba \u0026lt;NA\u0026gt; ## 4 -70.00415 12.50049 1 4 Aruba \u0026lt;NA\u0026gt; ## 5 -70.06612 12.54697 1 5 Aruba \u0026lt;NA\u0026gt; ## 6 -70.05088 12.59707 1 6 Aruba \u0026lt;NA\u0026gt; THAI.map \u0026lt;- world.map %\u0026gt;% filter(region == \u0026quot;Thailand\u0026quot;) head(THAI.map) ## long lat group order region subregion ## 1 99.66309 6.521924 1404 87912 Thailand Ko Tarutao ## 2 99.64404 6.516113 1404 87913 Thailand Ko Tarutao ## 3 99.60664 6.596827 1404 87914 Thailand Ko Tarutao ## 4 99.65401 6.714111 1404 87915 Thailand Ko Tarutao ## 5 99.70136 6.570557 1404 87916 Thailand Ko Tarutao ## 6 99.66309 6.521924 1404 87917 Thailand Ko Tarutao  Longitude and Lattitude Value Ranges Before converting UTM to longitude/lattitude data, we should know the range of both Longitudes and Lattitudes for Thailand.\nsummary(THAI.map$long) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 97.37 99.08 100.26 100.71 102.27 105.64 summary(THAI.map$lat) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 5.637 9.084 13.213 13.249 17.820 20.424  Jobpost Data Frame Our objective is to visualize utm_x and utm_y in the jobpost data frame by turning them into lattitude and longitude data first. The jobpost data frame is retrieved from PostgreSQL.\nPreparation includes writing it to CSV before loading into Rmarkdown.\njobpost \u0026lt;- read.csv(\u0026quot;jobpost.csv\u0026quot;) glimpse(jobpost) ## Rows: 50 ## Columns: 25 ## $ X \u0026lt;int\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, … ## $ jobpost_id \u0026lt;int\u0026gt; 54, 66, 33, 34, 35, 36, 28, 32, 30, 55, 67, 68, 37,… ## $ job_name \u0026lt;fct\u0026gt; \u0026quot;Facebook Marketing\u0026quot;, \u0026quot;แอดมิน\u0026quot;, \u0026quot;Accountant\u0026quot;, \u0026quot;แคชเ… ## $ job_qty \u0026lt;int\u0026gt; 3, 1, 1, 2, 2, 5, 3, 1, 5, 1, 22, 10, 1, 1, 2, 2, 1… ## $ age_min \u0026lt;int\u0026gt; 22, 25, 29, 20, 20, 19, 28, 28, 20, 25, 30, 21, 18,… ## $ age_max \u0026lt;int\u0026gt; 26, 32, 35, 35, 35, 40, 120, 40, 40, 45, 45, 30, 50… ## $ study_field \u0026lt;fct\u0026gt; \u0026quot;-\u0026quot;, \u0026quot;แฟชั่น\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;-\u0026quot;, \u0026quot;จัดการผักผ… ## $ job_qualification \u0026lt;fct\u0026gt; \u0026quot;อ่าน เขียน ภาษาอังกฤษ ได้ดี\u0026quot;, \u0026quot;ตอบคำถาม ภาษาอังกฤษ… ## $ min_salary \u0026lt;int\u0026gt; 30000, 12000, 20000, 13000, 10000, 15000, 15000, 12… ## $ job_description \u0026lt;fct\u0026gt; \u0026quot;ทำการตลาดทางช่องทาง facebook\u0026quot;, \u0026quot;แอดมินดูแล เพจ เสื… ## $ manychat_id \u0026lt;dbl\u0026gt; 3.961592e+15, 2.984969e+15, 2.941175e+15, 3.416291e… ## $ job_sex \u0026lt;int\u0026gt; 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 1, 3, … ## $ study_level \u0026lt;int\u0026gt; 5, 5, 5, 0, 2, 2, 3, 4, 4, 5, 5, 4, 0, 2, 2, 5, 5, … ## $ work_exp \u0026lt;int\u0026gt; 1, 0, 3, 1, 0, 0, 0, 3, 0, 3, 3, 0, 0, 1, 1, 3, 6, … ## $ created \u0026lt;fct\u0026gt; 2020-06-07 09:00:36, 2020-06-14 23:12:35, 2020-05-2… ## $ updated \u0026lt;fct\u0026gt; 2020-06-08 09:05:23, 2020-06-14 23:12:35, 2020-05-2… ## $ confirmed \u0026lt;fct\u0026gt; 2020-06-07 09:00:36, 2020-06-14 23:12:35, 2020-05-2… ## $ batch \u0026lt;lgl\u0026gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA… ## $ location \u0026lt;fct\u0026gt; บางนา, รามอินทรา 65, พระรามเก้า ซอย 60, ห้าง ริเวอร… ## $ utm_x \u0026lt;dbl\u0026gt; 674486.5, 678167.2, 676504.5, 661251.7, 714943.7, 6… ## $ utm_y \u0026lt;dbl\u0026gt; 1511131, 1532008, 1519745, 1515611, 1477934, 152128… ## $ utm_zone_number \u0026lt;int\u0026gt; 47, 47, 47, 47, 47, 47, 48, 47, 47, 47, 35, 48, 47,… ## $ utm_zone_letter \u0026lt;fct\u0026gt; P, P, P, P, P, P, Q, P, P, P, L, P, P, P, P, P, P, … ## $ job_type \u0026lt;int\u0026gt; NA, NA, 0, 0, 0, 0, 0, 0, 0, NA, NA, NA, 0, 0, 0, 0… ## $ online \u0026lt;lgl\u0026gt; NA, NA, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…  Subset Data Frame called UTM We’ll select only utm_x and utm_y columns from jobpost because we’re interested in these two columns.\nutm \u0026lt;- data.frame(jobpost$utm_x, jobpost$utm_y) str(utm) ## \u0026#39;data.frame\u0026#39;: 50 obs. of 2 variables: ## $ jobpost.utm_x: num 674486 678167 676504 661252 714944 ... ## $ jobpost.utm_y: num 1511131 1532008 1519745 1515611 1477934 ...  Handle Missing Values and Outliers Row 50 in jobpost and also utm is missing so we’ll delete that. Then we’ll also delete row 11 because it’s location is Zambia, Africa and its longitude and lattitude numbers are very different from Thailand - which will distort the map.\nutm \u0026lt;- utm[-50, ] utm \u0026lt;- utm[-11, ] jobpost \u0026lt;- jobpost[-50, ] jobpost \u0026lt;- jobpost[-11, ] str(utm) ## \u0026#39;data.frame\u0026#39;: 48 obs. of 2 variables: ## $ jobpost.utm_x: num 674486 678167 676504 661252 714944 ... ## $ jobpost.utm_y: num 1511131 1532008 1519745 1515611 1477934 ... str(jobpost) ## \u0026#39;data.frame\u0026#39;: 48 obs. of 25 variables: ## $ X : int 1 2 3 4 5 6 7 8 9 10 ... ## $ jobpost_id : int 54 66 33 34 35 36 28 32 30 55 ... ## $ job_name : Factor w/ 48 levels \u0026quot;.Net Developer\u0026quot;,..: 6 48 2 21 19 39 11 35 4 42 ... ## $ job_qty : int 3 1 1 2 2 5 3 1 5 1 ... ## $ age_min : int 22 25 29 20 20 19 28 28 20 25 ... ## $ age_max : int 26 32 35 35 35 40 120 40 40 45 ... ## $ study_field : Factor w/ 19 levels \u0026quot;-\u0026quot;,\u0026quot;Food science\u0026quot;,..: 1 12 1 1 1 1 1 6 1 5 ... ## $ job_qualification: Factor w/ 41 levels \u0026quot;-\u0026quot;,\u0026quot;- มีใบขับขี่รถยนต์\\n- ผ่านการเกณฑ์ทหาร\u0026quot;,..: 41 16 9 38 37 32 33 30 15 23 ... ## $ min_salary : int 30000 12000 20000 13000 10000 15000 15000 12000 11500 25000 ... ## $ job_description : Factor w/ 50 levels \u0026quot;- Develops, modifies application software according to specifications and requirements.\\n- Develops application\u0026quot;| __truncated__,..: 30 50 27 4 16 14 15 23 7 47 ... ## $ manychat_id : num 3.96e+15 2.98e+15 2.94e+15 3.42e+15 3.00e+15 ... ## $ job_sex : int 3 3 2 2 3 3 3 3 3 3 ... ## $ study_level : int 5 5 5 0 2 2 3 4 4 5 ... ## $ work_exp : int 1 0 3 1 0 0 0 3 0 3 ... ## $ created : Factor w/ 26 levels \u0026quot;2020-05-29 14:21:22\u0026quot;,..: 12 24 1 1 1 1 1 1 1 13 ... ## $ updated : Factor w/ 33 levels \u0026quot;2020-05-29 14:21:22\u0026quot;,..: 19 30 1 7 1 8 1 1 6 22 ... ## $ confirmed : Factor w/ 26 levels \u0026quot;2020-05-29 14:21:22\u0026quot;,..: 12 24 1 1 1 1 1 1 1 13 ... ## $ batch : logi FALSE FALSE FALSE FALSE FALSE FALSE ... ## $ location : Factor w/ 50 levels \u0026quot;112/3 หมู่ 7 ต.บางโฉลง อ.บางพลี จ.สมุทรปราการ 10540\u0026quot;,..: 25 35 29 47 30 9 38 11 49 39 ... ## $ utm_x : num 674486 678167 676504 661252 714944 ... ## $ utm_y : num 1511131 1532008 1519745 1515611 1477934 ... ## $ utm_zone_number : int 47 47 47 47 47 47 48 47 47 47 ... ## $ utm_zone_letter : Factor w/ 4 levels \u0026quot;L\u0026quot;,\u0026quot;N\u0026quot;,\u0026quot;P\u0026quot;,\u0026quot;Q\u0026quot;: 3 3 3 3 3 3 4 3 3 3 ... ## $ job_type : int NA NA 0 0 0 0 0 0 0 NA ... ## $ online : logi NA NA FALSE FALSE FALSE FALSE ...  Conversion of UTM into Lat/Long After some research, we find out that Thailand’s UTM zone is 47N. The stack overflow source I used to find the conversion code is here.\nWe’ll create two SpatialPoints object classes. Then transform them into a data frame containing lat and long data.\nRemember to load sp library for this operation.\nsputm \u0026lt;- SpatialPoints(utm, proj4string = CRS(\u0026quot;+proj=utm +zone=47N +datum=WGS84\u0026quot;)) spgeo \u0026lt;- spTransform(sputm, CRS(\u0026quot;+proj=longlat +datum=WGS84\u0026quot;)) thai.map2 \u0026lt;- data.frame(Location = jobpost$location, lat = spgeo$jobpost.utm_y, long = spgeo$jobpost.utm_x) head(thai.map2) ## Location lat long ## 1 บางนา 13.66385 100.6132 ## 2 รามอินทรา 65 13.85233 100.6486 ## 3 พระรามเก้า ซอย 60 13.74159 100.6324 ## 4 ห้าง ริเวอร์ไซด์ พลาซ่า เจริญนคร ชั้น 1 ใน้ บันไดเลื่อน 13.70512 100.4912 ## 5 เมืองชลบุรี 13.36114 100.9847 ## 6 กรุงเทพ 13.75633 100.5018  Visualize with GGPLOT2 Here we’ll visualize the THAI.map we created previously and overlay the new Lat/Long data points (from UTM).\nWe can see a concentration of utm data points from jobpost were made in Bangkok and the greater Bangkok areas with some jobs also posted outside Bangkok.\nTHAI.map %\u0026gt;% ggplot() + geom_map(map = THAI.map, aes(x = long, y = lat, map_id = region), fill = \u0026quot;white\u0026quot;, color = \u0026quot;black\u0026quot;) + geom_point(data = thai.map2, aes(x = long, y = lat, color = \u0026quot;red\u0026quot;, alpha = 0.9)) ## Warning: Ignoring unknown aesthetics: x, y  ","date":1593043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593091452,"objectID":"2a58547e9de6e1dd4ed674eed3755b5e","permalink":"/post/r-markdown-utm/","publishdate":"2020-06-25T00:00:00Z","relpermalink":"/post/r-markdown-utm/","section":"post","summary":"Convert UTM to lat/long","tags":[],"title":"Converting Universal Transverse Mercator (UTM) to lattitude/longitude data","type":"post"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"                                     ","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592956800,"objectID":"27bcfc28d6d93cfc757f920b67727409","permalink":"/slides/wpa/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/slides/wpa/","section":"slides","summary":"Wharton People Analytics Conf Data Visualizaton Competition 2020","tags":["People Analytics","Data Viz"],"title":"Data Visualization Competition 2020 - Wharton People Analytics Conf","type":"slides"},{"authors":null,"categories":null,"content":"This Data Visualization competition was hosted by the Wharton People Analytics conference. They partnered with Doctors Without Borders, a medical humanitarian organization that delivers emergency aid to people affected by conflict, epidemics and natural disasters. Our task was to analyze data dating back to 2 decades on their global workforce comprising over 45,000 people to understand the career paths of Medical Coordinators (a top-level position within the organization).\nVery excited to have won 2nd place in this competition! See details here.\n","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592956800,"objectID":"1e15b1f5b1330df00068aa5d60b8e2f6","permalink":"/project/wharton-people-analytics/","publishdate":"2020-06-24T00:00:00Z","relpermalink":"/project/wharton-people-analytics/","section":"project","summary":"An example of using the in-built project page.","tags":["Data Viz","People Analytics"],"title":"Wharton People Analytics Data Visualization Competition 2020","type":"project"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Paul Apivat Hanvongse"],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Paul Apivat Hanvongse"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["Paul Apivat Hanvongse","吳恩達"],"categories":["Demo","教程"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤️ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic","开源"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Paul Apivat Hanvongse","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["Paul Apivat Hanvongse","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]